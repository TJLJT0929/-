\begin{document}


\section{Spectral Ranking Inferences based on General Multiway
Comparisons*}\label{spectral-ranking-inferences-based-on-general-multiway-comparisons}

Jianqing Fan Zhipeng Lou Weichen Wang Mengxin Yu

March 4, 2024

\section{Abstract}\label{abstract}

This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a general and more realistic setup. Specifically, the comparison graph consists of hyper-edges of possible heterogeneous sizes, and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in scenarios where the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptotic distributions of the estimated preference scores, we also introduce a comprehensive framework to carry out both one-sample and two-sample ranking inferences, applicable to both fixed and random graph settings. It is noteworthy that this is the first time effective two-sample rank testing methods have been proposed. Finally, we substantiate our findings via comprehensive numerical simulations and subsequently apply our developed methodologies to perform statistical inferences for statistical journals and movie rankings.

\section{1 Introduction}\label{introduction}

Rank aggregation is crucial in various applications, including web search (Dwork et al., 2001; Wang et al., 2016), primate intelligence experiments (Johnson et al., 2002), assortment optimization (Aouad et al., 2018; Chen et al., 2020), recommendation systems (Baltrunas et al., 2010; Li et al., 2019), sports ranking (Massey, 1997; Turner and Firth, 2012), education (Avery et al., 2013; Caron et al., 2014), voting (Plackett, 1975; Mattei and Walsh, 2013), and instruction tuning used in the recent popular large language model ChatGPT (Ouyang et al., 2022). Therefore, it becomes an essential problem in many fields, such as psychology, econometrics, education, operation research, statistics, machine learning, artificial intelligence, etc.

Luce (Luce, 1959) introduced the celebrated Luce's axiom of choice. Let \(p(i\mid A)\) be the probability of selecting item \(i\) over all other items in the set of alternatives \(A\). According to the axiom, when comparing two items \(i\) and \(j\) in any sets of alternatives \(A\) containing both \(i\) and \(j\), the probability of choosing \(i\) over \(j\) is unaffected by the presence of other alternatives in the set. In specific, the axiom postulates that
\[
\frac{\mathbb{P}(i\mathrm{~is~preferred~in~}A)}{\mathbb{P}(j\mathrm{~is~preferred~in~}A)} = \frac{\mathbb{P}(i\mathrm{~is~preferred~in~}\{i,j\})}{\mathbb{P}(j\mathrm{~is~preferred~in~}\{i,j\})}.
\]
This assumption gives rise to a unique parametric choice model, the Bradley-Terry-Luce (BTL) model for pairwise comparisons, and the Plackett-Luce (PL) model for \(M\)-way rankings \(M\geq 2\).

In this paper, we consider a collection of \(n\) items whose true ranking is determined by some unobserved preference scores \(\theta_{i}^{*}\) for \(i = 1,\dots ,n\). In this scenario, the BTL model assumes that an individual or a random event ranks item \(i\) over \(j\) with probability \(\mathbb{P}(\mathrm{item}~i\) is preferred over item \(j) = e^{\theta_i^*} / (e^{\theta_i^*} + e^{\theta_j^*})\). The Plackett-Luce model is an expanded version of pairwise comparison, which allows for a more comprehensive \(M\)-way full ranking, as initially described in Plackett (1975). This model takes individual preferences into account when ranking a selected subset of items with size \(M< \infty\) (among all \(n\) items), which we represent as \(i_{1}\succ \dots \succ i_{M}\). Think of this full ranking as \(M - 1\) distinct events where \(i_{1}\) is favored over the set \(i_{1},\ldots ,i_{M}\), followed by \(i_{2}\) being favored over the set \(i_{2},\ldots ,i_{M}\), and so on. The PL model calculates the probability of a full ranking \(i_{1}\succ \dots \succ i_{M}\) using the formula:
\[
\mathbb{P}(i_1\succ \dots \succ i_M) = \prod_{j = 1}^{M - 1}\left[e^{\theta_{ij}^*} / \sum_{k = j}^{M}e^{\theta_{ik}^*}\right].
\]
Next, we will give a brief introduction to the literature that has made progress on model estimation and uncertainty quantification for the BTL and the PL models over the parametric model.

\section{1.1 Related literature}\label{related-literature}

A series of papers studied model estimation or inference based on the BTL or PL models. In the case of the Bradley-Terry-Luce model, its theoretical characteristics were solidified through a minorization-maximization algorithm, as outlined by Hunter (2004). Additionally, Negahban et al.~(2012) developed an iterative rank aggregation algorithm called Rank Centrality (spectral method), which can recover the BTL model's underlying scores at an optimal \(\ell_2\)-statistical rate. Subsequently, Chen and Suh (2015) used a two-step methodology (spectral method followed by MLE) to examine the BTL model in a context where the comparison graph is based on the Erdős-Rényi model, where every item pair is assumed to have a probability \(p\) of being compared, and once a pair is connected, it will be compared for \(L\) times. Subsequently, under a similar setting with Chen and Suh (2015), Chen et al.~(2019) investigated the optimal statistical rates for recovering the underlying scores, demonstrating that regularized maximum likelihood estimation (MLE) and the spectral method are both optimal for retrieving top-\(K\) items when the conditional number is a constant. They derived \(\ell_2\)-as well as \(\ell_\infty\)-rates for the unknown underlying preference scores in their study. Furthermore, Chen et al.~(2022) extended the investigation of Chen et al.~(2019) to the partial recovery scenarios and improved the analysis to un-regularized MLE.

Expanding beyond simple pairwise comparisons, researchers also explored ranking issues through \(M\)-way comparisons, where \(M \geq 2\). The Plackett-Luce model and its variations serve as prominent examples in this line of study, as evidenced by numerous references (Plackett, 1975; Guiver and Snelson, 2009; Cheng et al., 2010; Hajek et al., 2014; Maystre and Grossglauser, 2015; Szorenyi et al., 2015; Jang et al., 2018). In particular, Jang et al.~(2018) investigated the Plackett-Luce model within the context of a uniform hyper-graph, where a tuple with size \(M\) is compared with probability \(p\) and once a tuple is connected or compared in the hyper-graph, it will be compared for \(L\) times. By dividing \(M\)-way comparison data into pairs, they employ the spectral method to obtain the \(\ell_\infty\)-statistical rate for the underlying scores. Additionally, they presented a lower bound for sample complexity necessary to identify the top-\(K\) items under the Plackett-Luce model. In a more recent development, under the same model setting, Fan et al.~(2022b) enhanced the findings of Jang et al.~(2018), focusing solely on the top choice. Rather than splitting the comparison data into pairwise comparisons, they applied the Maximum Likelihood Estimation (MLE) and matched the sample complexity lower bound needed to recover the top-\(K\) items. This contrasts with Jang et al.~(2018), which requires a significantly denser comparison graph or a much larger number of comparisons for their results to hold.

The aforementioned literature primarily concentrated on the non-asymptotic statistical consistency for estimating item scores. However, the results of limiting distribution for ranking models remained largely unexplored. Only a limited number of findings on asymptotic distributions of estimated ranking scores exist under the Bradley-Terry-Luce model, whose comparison graphs are sampled from the Erdős-Rényi graph with connection probability \(p\) and each observed pair has the same number of comparisons \(L\). For example, Simons and Yao (1999) established the asymptotic normality of the BTL model's maximum likelihood estimator when all comparison pairs are entirely conducted (i.e., \(p = 1\)). Han et al.~(2020) expanded these findings for dense, but not fully connected, comparison graphs (Erdős-Rényi random graphs) where \(p \gtrsim n^{- 1 / 10}\). Recently, Liu et al.~(2022) introduced a Lagrangian debiasing approach to derive asymptotic distributions for ranking scores, accommodating sparse comparison graphs with \(p \asymp 1 / n\) but necessitating comparison times \(L \gtrsim n^2\). Furthermore, Gao et al.~(2021) employed a ``leave-two-out'' technique to determine asymptotic distributions for ranking scores, achieving optimal sample complexity and allowing \(L = \mathcal{O}(1)\) in the sparse comparison graph setting (i.e., \(p \asymp 1 / n\) up to logarithm terms). Fan et al.~(2022a) extended upon existing research by incorporating covariate information into the BTL model. By introducing an innovative proof, they presented the MLE's asymptotic variance with optimal sample complexity when \(p \asymp 1 / n\) and \(L = \mathcal{O}(1)\). In the sequel, Fan et al.~(2022b) broadened the asymptotic results of the BTL model to encompass Plackett-Luce (PL) models with \(M \geq 2\) again with optimal sample complexity. They also developed a unified framework to construct rank confidence intervals, requiring the number of comparisons \(L \gtrsim \mathrm{poly}(\log n)\). Moreover, recently, Han and Xu (2023) further extended the settings in Fan et al.~(2022b) by investigating the asymptotic distribution of the MLE, where the comparisons are generated from a mixture of Erdos-Renyi graphs with different sizes or a hypergraph stochastic block model.

Finally, we discuss related literature of an important application of our framework: assortment optimization (Talluri and Van Ryzin, 2004; Rusmevichientong and Topaloglu, 2012; Vulcano et al., 2012; Davis et al., 2014; Zhang et al., 2020; Chen et al., 2020, 2023; Shen et al., 2023) which is of great importance in revenue management. Specifically, in their settings, each product (including the no-purchase alternative) is also associated with an unknown customer preference score, which can characterize the customers' choice behavior over a set of offered products. Based on the consistently estimated preference scores and the available profit information of each product, various efficient algorithms have been proposed to determine the optimal assortment under different kinds of practical constraints (Talluri and Van Ryzin, 2004; Rusmevichientong et al., 2010; Gallego and Topaloglu, 2014; Sumida et al., 2021). Moreover, uncertainty quantification of the estimated preference scores also enables statistical inference on the properties of the optimal assortment (Shen et al., 2023).

\section{1.2 Motivations and Contributions}\label{motivations-and-contributions}

In this section, we discuss our motivation and problem settings and compare our results with previous literature in different aspects, namely the comparison graph, the connection between the spectral method and MLE, and ranking inferences.

\section{1.2.1 Comparison graph}\label{comparison-graph}

Previous studies on parametric ranking models mostly require comparison graphs derived from a specific random graph. For example, in the endeavor of understand multiway comparisons (e.g.~Jang et al.~(2016); Fan et al.~(2022b)), it is typically assumed that the comparisons are generated explicitly from a homogeneous graph with a known distribution. This assumption may pose a challenge in certain contexts. Although practical applications with homogeneous comparisons exist, it is sometimes unrealistic to presume that all comparisons are generated from a known homogeneous distribution. In fact, there are more cases where we see heterogeneous comparisons, where some are compared more often than others and the comparison graph generation process is unknown. We will present Example 1.1 as our motivation.

Example 1.1. There is a sequence of customers buying goods. For the \(l\)-th customer, according to her preference, her reviewed products are \(A_{l}\) (a choice set), and she finally chose product \(c_{l}\in A_{l}\) (her top choice). Then the total datasets presented to us is \(\{(A_l,c_l)\}_{l = 1}^D\). If all choice sets are presented to the customers with the same probability and the reviewed number of items are of the same size (such as pairwise comparisons), we say the comparison graph is homogeneous. But if some choice sets, possibly with different sizes, are presented more often to the customers or are chosen arbitrarily based on the customers' preference profiles, then this heterogeneous comparison graph cannot be well approximated by a given random graph model. That is, the comparisons may not follow, say, the BTL or PL models with Erdos-Renyi types of uniform graphs.

The heterogeneous comparison scheme in Example 1.1 above is applicable across a wide range of practical scenarios. For instance, it covers the typical setup of the assortment optimization,
\pandocbounded{\includegraphics[keepaspectratio]{images/166cf6f6b99e4beefb26f15500d7fb45e7a5c1bf6743c6b0bcc83e3bdcb260e6.jpg}}
wherein the no-purchase alternative is also included in the choice set \(A_{l}\). We give a toy example with 5 products in Figure 1, where sizes of \(A_{l}\) are among \(\{2,3,4\}\). Due to the heterogeneity, it is unrealistic to assume \(A_{l}\) is of the same size or sampled from an explicit random graph. However, most of the previous works focused on statistical properties under certain ad-hoc random graphs, most commonly the Erdős-Rényi type of uniform graphs, e.g., Chen and Suh (2015); Chen et al.~(2019); Jang et al.~(2016); Gao et al.~(2021); Liu et al.~(2022); Fan et al.~(2022b); Han and Xu (2023). One interesting piece of research that indeed worked with the fixed comparison graph is Shah et al.~(2015), which explored the optimality of MLE in \(\ell_{2}\) estimation with pairwise comparisons. Following this work, Li et al.~(2022) further discussed the optimality of MLE in \(\ell_{\infty}\) error. Still, little has been known about the inference results for general fixed comparison graphs.

In this paper, we focus on the setting of a general fixed comparison graph, where we circumvent the modeling for the complicated graph-generating process. Specifically, we study statistical estimation and uncertainty quantification of the preference scores over a general, heterogeneous choice set via the spectral method. In addition, we also study the theoretical performance of the spectral method when we do have a homogeneous random comparison graph, and compare the results. Our results require slightly stronger conditions to handle fixed graph settings since we need to make sure each item has enough information to be ranked.

For the general setting, we denote the choice preference for the \(l\)-th comparison as \((c_{l},A_{l})\), wherein \(A_{l}\) signifies the set of choices with heterogeneous size, which can be either fixed or random, and \(c_{l}\in A_{l}\) represents the most preferred item in \(A_{l}\). Hence, in the \(l\)-th comparison, we understand that \(c_{l}\) outranks all other elements within \(A_{l}\). As such, our broadest comparison data is symbolized as \(\mathcal{D} = \{l|(c_{l},A_{l})\}\). The associated collection of choice sets is denoted as \(\mathcal{G} = \{A_{l}|l\in \mathcal{D}\}\). This framework also contains the Plackett-Luce model as a special case, if we treat the PL model as \(M - 1\) selections over \(M - 1\) choice sets. Under mild conditions, we manage to obtain optimal statistical rates for our spectral estimator conditional on the comparison graphs and specify the explicit form of its asymptotic distribution. This gives an efficient solution when one encounters heterogeneous comparison graphs. In addition, since the graph is fixed or conditioned upon, it is not necessary for us to repeat each comparison for \(L\geq 1\) times. We can even accommodate situations where a choice set is chosen and compared for just a single time, which is true in many practical applications.

\section{1.2.2 Connection between the spectral estimator and the MLE}\label{connection-between-the-spectral-estimator-and-the-mle}

Our general setting, as introduced in Section 1.2.1, encompasses homogeneous random comparison graphs as a particular instance. The bulk of prior research has centered around the evaluation of the Maximum Likelihood Estimator (MLE) or the spectral method when applied to homogeneous comparisons (Chen and Suh, 2015; Chen et al., 2019, 2022; Fan et al., 2022a,b). Both are effective methods for examining ranking issues within the context of the BTL or PL model. Hence, an interesting question arises: What is the relationship between the MLE and the spectral method?

A handful of studies have offered insights into this question. For instance, Maystre and Gross-glauser (2015) identified a link between the MLE and spectral method in multiway comparisons, where the spectral estimator aligns with the MLE through the iterative updating of specific weighting functions in constructing the spectral estimator. This connection was only limited to the first order in the sense that the paper only concerns the convergence property. Furthermore, Gao et al.~(2021) demonstrated that the asymptotic variance of the spectral method exceeds that of the MLE in pairwise comparisons using the BTL model. However, this discrepancy arises from their choice of a suboptimal weighting function for the spectral estimator.

In our paper, we leverage the homogeneous random comparison graph case (as it is the most popularly studied setting in many previous articles) to illustrate that by employing certain optimally estimated information weighting functions, the asymptotic variance of the spectral estimator matches that of the MLE with multiway comparisons in the PL model. Therefore, the MLE could be considered a ``two-step'' spectral method, where in the first step we consistently estimate the unobserved preference scores, and in the second step we use the proper weighting in the spectral method to achieve an efficient estimator. It is also noteworthy that we achieve the optimal sample complexity over the sparsest sampling graph up to logarithmic terms.

\section{1.2.3 Ranking inferences: one sample vs two samples}\label{ranking-inferences-one-sample-vs-two-samples}

As another contribution, we also study several rank-related inference problems. We have the following motivating example:

Example 1.2. First, we consider the one-sample inference problem. Consider a group of candidate items \(\{1,\dots ,n\}\) and one observed dataset on their comparisons; we are interested in
\begin{itemize}
\tightlist
\item
  Building the confidence intervals for the ranks of certain items \(\{r_1,\dots ,r_m\}\) of our interest.
\item
  Testing whether a given item \(m\) is in the top-\(K\) set, which includes \(K\) best items.
\end{itemize}
Second, we consider the two-sample inference problem. For two groups of datasets of the same list of items \(\{1,\dots ,n\}\), we are interested in
\begin{itemize}
\tightlist
\item
  Testing whether the rank of a certain item \(m\) is preserved across these two samples (e.g.~groups or time periods).
\item
  Testing whether the top-\(K\) sets have changed or not.
\end{itemize}

Rankings are ubiquitous in real-world applications, for instance, in the evaluation of universities, sports teams, or web pages. However, most of these rankings provide only first-order information, presenting the results without offering any measure of uncertainty. For example, under the BTL model, when two items have equivalent underlying scores, there's a \(50\%\) probability of one being ranked higher than the other. Thus, rankings between these two items could be unreliable due to their indistinguishable underlying scores, emphasizing the necessity for confidence intervals in rankings.

Given these critical considerations, our study offers a comprehensive framework that efficiently solves the problems outlined in Example 1.2 over heterogeneous comparison graphs. Additionally, our approach enhances the sample complexity of several previous works. For instance, when restricting our general framework to homogeneous random comparison graphs, regarding the one-sample inference, Liu et al.~(2022) required \(L \gtrsim n^2\) to carry out the statistical inference, while Fan et al.~(2022b) further improved this requirement to \(L \gtrsim \mathrm{poly}(\log n)\). In our paper, our framework can allow \(L = \mathcal{O}(1)\) and even \(L = 1\). Furthermore, two-sample ranking inference, which can be widely applied in real-world scenarios like policy evaluation, treatment effect comparison, change point detection, etc., has not been previously studied. Our paper also introduces a general framework for studying the two-sample ranking inference problems, again offering optimal sample complexity.

\section{1.2.4 Theoretical contributions}\label{theoretical-contributions}

We build up our theoretical analyses based on some previously developed techniques from Gao et al.~(2021) and Chen et al.~(2019). However, our proofs have the following novelty: In those two papers and other papers with a random comparison graph, graph randomness and ranking outcome randomness are typically intertwined in the analysis. We will separate them and reveal the proper quantities of interest to summarize the information in a fixed comparison graph. We study the connection between these quantities and the spectral ranking performance, and provide sufficient conditions under the fixed graph for valid ranking inference. This theoretical attempt has not previously been seen in the literature. In addition, all our analyses allow varying comparison sizes and an arbitrary number of repetitions of each comparison set. This significantly broadens the applicability of our proposed methodology, as in practice, a lot of ranking problems contain non-repeating comparisons of different numbers of items. We also work on the theory when we also have graph randomness. We realize that the homogeneity of sampling each comparison tuple can lead to more relaxed assumptions. With more relaxed conditions, we clearly show where and how we can achieve an improved performance guarantee (see the assumption and proof of Theorem 4.4). This part highlights the difference between fixed and random graphs and provides more theoretical insights into the role of graph randomness in spectral ranking.

\section{1.3 Roadmap and notations}\label{roadmap-and-notations}

In Section 2, we set up the model and introduce the spectral ranking method. Section 3 is dedicated to the examination of the asymptotic distribution of the spectral estimator, based on fixed comparison graphs and random graphs with the PL model, respectively. Within the same section, we also introduce the framework designed for the construction of rank confidence intervals and rank testing statistics for both one-sample and two-sample analysis. Section 4 details the theoretical guarantees for all proposed methodologies. Sections 5 and 6 contain comprehensive numerical studies to verify theoretical results and two real data examples to illustrate the usefulness of our ranking inference methods. Finally, we conclude the paper with some discussions in Section 7. All the proofs are deferred to the appendix.

Throughout this work, we use \([n]\) to denote the index set \(\{1,2,\dots ,n\}\). For any given vector \(\mathbf{x} \in \mathbb{R}^n\) and \(q \geq 0\), we use \(\| \mathbf{x}\| _q = (\sum_{i = 1}^{n} |x_i|^q)^{1 / q}\) to represent the vector \(\ell_q\) norm. For any given matrix \(\mathbf{X} \in \mathbb{R}^{d_1 \times d_2}\), we use \(\| \cdot \|\) to denote the spectral norm of \(\mathbf{X}\) and write \(\mathbf{X} \succcurlyeq 0\) or \(\mathbf{X} \preccurlyeq 0\) if \(\mathbf{X}\) or \(- \mathbf{X}\) is positive semidefinite. For event \(A\), \(1(A)\) denotes an indicator which equals 1 if \(A\) is true and 0 otherwise. For two positive sequences \(\{a_n\}_{n \geq 1}\), \(\{b_n\}_{n \geq 1}\), we write \(a_n = \mathcal{O}(b_n)\) or \(a_{n} \lesssim b_{n}\) if there exists a positive constant \(C\) such that \(a_{n} / b_{n} \leq C\) and we write \(a_{n} = o(b_{n})\) if \(a_{n} / b_{n} \to 0\). In addition, \(\mathcal{O}_{p}(\cdot)\) and \(o_{p}(\cdot)\) share similar meanings as \(\mathcal{O}(\cdot)\) and \(o(\cdot)\), respectively, but these relations hold asymptotically with probability tending to 1. Similarly we have \(a_{n} = \Omega (b_{n})\) or \(a_{n} \gtrsim b_{n}\) if \(a_{n} / b_{n} \geq c\) with some constant \(c > 0\). We use \(a_{n} = \Theta (b_{n})\) or \(a_{n} \asymp b_{n}\) if \(a_{n} = \mathcal{O}(b_{n})\) and \(a_{n} = \Omega (b_{n})\). For two random variables \(A_{n}, B_{n}\), if we write \(A_{n} \approx B_{n}\), it holds that \(A_{n} - B_{n} = o(1)\) with probability goes to 1. Given \(n\) items, we use \(\theta_{i}^{*}\) to indicate the underlying preference score of the \(i\)-th item. Define \(r: [n] \to [n]\) as the rank operator on the \(n\) items, which maps each item to its population rank based on the preference scores. We write the rank of the \(i\)-th item as \(r_{i}\) or \(r(i)\). By default, we consider ranking from the largest score to the smallest score.

\section{2 Multiway Comparison Model and Spectral Ranking}\label{multiway-comparison-model-and-spectral-ranking}

We first introduce a general discrete choice model, which encompasses the classical Plackett-Luce model as well as fixed comparison graph scenario.

\section{2.1 Discrete choice model}\label{discrete-choice-model}

We assume there are \(n\) items to be ranked. According to Luce's choice axiom (Luce, 1959), the preference scores of a given group of \(n\) items can be parameterized as a vector \((\theta_{1}^{*}, \ldots , \theta_{n}^{*})^{\top}\) such that \(\mathbb{P}(i\) wins among \(A) = e^{\theta_{i}^{*}} / (\sum_{k \in A} e^{\theta_{k}^{*}})\) for any choice set \(A\) and item \(i \in A\). Since the parameters are only identifiable up to a location shift, without loss of generality, we assume \(\sum_{i = 1}^{n} \theta_{i}^{*} = 0\) for identification. We consider the general comparison model, where we are given a collection of comparisons and outcomes \(\{(c_{l}, A_{l})\}_{l \in \mathcal{D}}\). Here \(c_{l}\) denotes the selected item over the choice set \(A_{l}\) with probability \(e^{\theta_{c_{l}}^{*}} / (\sum_{k \in A_{l}} e^{\theta_{k}^{*}})\).

Remark 2.1. This general comparison model contains many well-known special cases.
\begin{itemize}
\item
  For the Bradley-Terry-Luce (BTL) model, it is easy to set \(A_{l}\) as the pair being compared every time. If each pair is compared for \(L\) times independently, we just need to write the outcomes as \((c_{l}, A_{l})\) and re-index \(l\).
\item
  For the Plackett-Luce (PL) model, we have obtained the full ranking of a choice set \(B = \{i_{1}, \dots , i_{B}\}\). The probability of observing a certain ranking becomes
\end{itemize}
\[
\begin{array}{r l} & {\mathbb{P}(i_{1} > i_{2} > \dots >i_{B}) = \mathbb{P}(i_{1}\mathrm{~wins~among~}C_{1}\mid C_{1} = B)\cdot \mathbb{P}(i_{2}\mathrm{~wins~among~}C_{2}\mid C_{2} = B\{-i_{1}\})\cdot[...]}
\end{array}
\]
where \(C_{i}, i \geq 1\) is the \(i\)-th comparison set and \(B\{- i_{1}, \dots , - i_{M}\}\) denotes the set of remained items after removing \(\{i_{1}, \dots , i_{M}\}\). These comparison results can also be decomposed into the comparisons:
\[
\{(i_{1}, B), (i_{2}, B\{-i_{1}\}), \dots , (i_{B - 1}, B\{-i_{1}, \dots , -i_{B - 2}\})\} .
\]
\begin{itemize}
\tightlist
\item
  With fixed comparison graphs, \(\{A_{l},l\in \mathcal{D}\}\) are given and hence have no randomness, so the comparison results in \(c_{l}\) are assumed independent. In contrast, with a random comparison graph, such as in the PL model, \(A_{l}\) may be dependent. For instance, \((\theta_{i_{1}},B)\) and \((\theta_{i_{2}},B\{-i_{1}\})\) are dependent as \(B\{-i_{1}\}\) depends on the winner of the first comparison \(i_{1}\). Therefore, we have to explicitly lay out the random process assumption for comparison generation in order to study the theoretical properties in a case-by-case manner.
\end{itemize}

Recall that the general comparison data is denoted as \(\{(c_{l},A_{l})\}_{l\in \mathcal{D}}\). The corresponding collection of choice sets is \(\mathcal{G} = \{A_{l}|l\in \mathcal{D}\}\). When we only have pairwise comparisons, \(|A_{l}| = 2\) and \(\mathcal{G}\) represents the set of all edges we have compared. But in a general setting, \(A_{l}\) can have different sizes and we denote \(M = \max_{l\in \mathcal{D}}|A_{l}|< \infty\) as the maximal size of the comparison hyper-graph edge. Also if we have \(L\) independent comparisons of the same comparison hyper-edge \(A_{l}\), we use different \(l\) to indicate the comparison. So in \(\mathcal{G}\), the hyper-edge \(A_{l}\) may be compared for multiple times with different outcomes \(c_{l}\).

Throughout this paper, we consider using the spectral method on the preference data based on multiway comparisons. We will first focus on the fixed comparison graph and then consider commonly-used random comparison graph structures. Notice that no matter whether the comparison graph \(\mathcal{G}\) is fixed or random, our spectral ranking methodology will be conditional on \(\mathcal{G}\), which is observed in practice. The underlying model for generating \(\mathcal{G}\) can be very general: it can be given, or random based on the Erdős-Rényi random graph with the same probability \(p\), or more generally induced from some other comparison rules, which could even cause some \(A_{l}\) dependent. For example, if we view each comparison of the PL model as \(M - 1\) pairwise comparisons involving top 1 vs top 2, top 2 vs top 3, \ldots, top \(M - 1\) vs top \(M\). Then the resulting comparison data, denoted as \((c_{l} - i_{k},A_{l} = \{i_{k},i_{k + 1}\})\) for \(k = 1,\ldots ,M - 1\), are dependent (even the definition of \(A_{l}\) depends on the complete comparison result).

\section{2.2 Spectral ranking}\label{spectral-ranking}

In the spectral method, we formally define a Markov chain, denoted as \(M = (S,P)\). Here, \(S\) signifies the collection of \(n\) states corresponding to the \(n\) items to be compared, represented as vertices of a directed comparison graph. And \(P\) constitutes the transition matrix defined below. This matrix oversees transitions amongst the states by representing whether any two particular states within \(S\) are capable of being connected via non-zero transition probabilities.

Define two index sets \(\mathcal{W}_{j},\mathcal{L}_{i}\) for comparisons, with \(j\) as the winner and \(i\) as the loser:
\[
\mathcal{W}_{j} = \{l\in \mathcal{D}|j\in A_{l},c_{l} = j\} ,\qquad \mathcal{L}_{i} = \{l\in \mathcal{D}|i\in A_{l},c_{l}\neq i\} .
\]
So their intersection for \(i\neq j\) gives all situations where \(i,j\) are compared and \(j\) wins, i.e., \(\mathcal{W}_{j}\cap \mathcal{L}_{i} = \{l\in \mathcal{D}|i,j\in A_{l},c_{l} = j\}\). Define the transition matrix \(P\) with transition probability
\[
P_{ij} = \left\{ \begin{array}{ll}\frac{1}{d}\sum_{l\in \mathcal{W}_{j}}\mathcal{L}_{i}\frac{1}{f(A_{l})}, & \text{if} i\neq j, \\ 1 - \sum_{k:k\neq i}P_{ik}, & \text{if} i = j. \end{array} \right.
\]
Here, \(d\) is chosen to be large enough so that the diagonal element is non-negative, but not too large to give enough transition probability. When the comparison graph is random, we choose \(d\) to make non-negative diagonal elements with probability approaching 1 by studying the concentration inequality for \(\sum_{k:k\neq i}P_{i k}\). Here, \(f(A_{l}) > 0\) is a weighting function to encode the total information in the \(l\)-th comparison. A natural choice is \(f(A_{l}) = |A_{l}|\) giving more weight to hyper-edges with a smaller number of compared items. We will discuss later the optimal choice of \(f(\cdot)\). When \(i\neq j\), \(P_{i j}\) can also be written as
\[
P_{i j} = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})1(c_{l} = j)\frac{1}{f(A_{l})}
\]
Conditioning on \(\mathcal{G}\), the population transition is
\[
P_{i j}^{*} = E[P_{i j}|\mathcal{G}] = \left\{ \begin{array}{l l}{\frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\frac{e^{\theta_{j}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\frac{1}{f(A_{l})},} & [...]
\end{array} \right.
\]
Let
\[
\pi^{*} = (e^{\theta_{1}^{*}},\ldots ,e^{\theta_{n}^{*}}) / \sum_{k = 1}^{n}e^{\theta_{k}^{*}}.
\]
Note that both \(\sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) and \(f(A_{l})\) in the denominator are symmetric with respect to \(\theta_{i}^{*},\theta_{j}^{*}\) as long as both \(i,j\) belong to \(A_{l}\). So we have \(P_{i j}^{*}\pi_{i}^{*} = P_{i j}^{*}\pi_{j}^{*}\). This is the so-called detailed balance that leads to \(\pi^{*}\) being the stationary measure of the Markov chain with the above population transition for any \(f(\cdot)\). That is \(\pi^{*}^{\top}P^{*} = \pi^{*}^{\top}\), namely, \(\pi^{*}\) is the top-left eigenvector of \(P^{*}\).

The spectral method estimates \(\pi^{*}\) by using the stationary measure \(\widehat{\pi}\) of the empirical transition \(P\), namely,
\[
\widehat{\pi}^{\top}P = \widehat{\pi}^{\top}.
\]
Note that if we consider the directed graph induced by \(P\) to be strongly connected, this implies that the Markov chain it generates will be ergodic, which ensures the existence of a unique stationary distribution \(\widehat{\pi}\) as defined above. Consider the toy example in Figure 1, if we naively choose \(f(\cdot) = 1\) as a constant weighting function, it is not hard to count the times that \(j\) beats \(i\) and fill the value into the transition matrix \(P_{i j}\) (divided by \(d\)). In the right panel, the transition probabilities are calculated with \(d = 6\) to guarantee the self-loop transition happens with a positive probability. For this \(P\), the stationary distribution is \(\widehat{\pi} = (0.199,0.531,0.796,0.199,0.066)^{\top}\), meaning that the estimated ranking of preference scores of the 5 products are \(3\succ 2\succ 1 = 4\succ 5\).

Finally given the identifiability condition of \(1^{\top}\theta^{*} = 0\), we can estimate \(\theta_{i}^{*}\) by
\[
\widehat{\theta}_{i}\coloneqq \log \widehat{\pi}_{i} - \frac{1}{n}\sum_{k = 1}^{n}\log \widehat{\pi}_{k}. \tag{2.1}
\]
It is worth mentioning that the spectral estimator is easier to compute in practice, by only requiring one-step eigen-decomposition. Indeed, we need only the eigenvector that corresponds to the largest eigenvalue, which can even be computed very fast by the power method. In comparison, the MLE is typically computationally heavier in terms of data storage and step size determination during the implementation of the gradient descent algorithm.
