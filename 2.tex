\begin{document}

\section{3 Ranking Inference
Methodology}\label{ranking-inference-methodology}

3 Ranking Inference MethodologyIn this section, we study the inference
methodology for the spectral estimator for the underlying scores
\(\{\theta_{i}^{*}\}_{i\in [n]}\) of \(n\) items. To be specific, we
need to establish the statistical convergence rates and asymptotic
normality for \(\widetilde{\theta_{i}}\) .

\section{3.1 Uncertainty quantification with fixed comparison
graph}\label{uncertainty-quantification-with-fixed-comparison-graph}

For the estimation of \(\pi^{*}\) , we use the following two
approximations, which we will justify later to be accurate enough so as
not to affect the asymptotic variance. Let us first focus on our
intuition. Firstly, we have

\[
\widehat{\pi}_{i} = \frac{\sum_{j:j\neq i}P_{ji}\widehat{\pi}_{j}}{\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*}}{\sum_{j:j\neq i}P_{ij}} \eqqcolon \bar{\pi}_{i}.
\]

Equivalently,

\[
\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\approx \frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}(P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*})}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}. \tag{3.1}
\]

Secondly, the denominator above can be approximated by its expected
value so that (3.1) can further be approximated as

\[
J_{i}^{*}\coloneqq \frac{\sum_{j:j\neq i}(P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}})}{\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}}}, \tag{3.2}
\]

by using \(\pi_{i}^{*}\propto e^{\theta_{i}^{*}}\) . We will rigorously
argue that the asymptotic distributions of
\(\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and
\(J_{i}^{*}\) are identical. For now, let us look at the asymptotic
distribution of \(J_{i}^{*}\) . Obviously, it is mean zero due to the
detailed balance:
\(E[P_{ji}|\mathcal{G}]\pi_{j}^{*} = E[P_{ij}|\mathcal{G}]\pi_{i}^{*}\)
. The denominator of \(J_{i}^{*}\) is a constant and can be explicitly
written out as follows:

\[
\tau_{i}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}} = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(1 - \frac{e^{\theta_{i}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\right)\frac{e^{\theta_{i}^{*}}}{f(A_{l})}. \tag{3.3}
\]

Thus, \(J_{i}^{*}\) can be expressed as

\[
J_{i}^{*} = \frac{1}{d\tau_{i}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f(A_{l})}\left(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\right)\eqqcolon \frac{1}{d}\sum_{l\in \mathcal{D}}J_{i l}(\theta^{*}), \tag{3.4}
\]

where \(\tau_{i}\) is short for \(\tau_{i}(\theta^{*})\) . Since each
\((c_{l},A_{l})\) is independent in the fixed graph setting (see Remark
2.1 for discussions), the variance of \(J_{i}^{*}\) is

\[
\begin{array}{r l} & {\mathrm{~\gamma~}_{i}^{*}|\mathcal{G}) = \frac{1}{d^{2}\tau_{i}^{2}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f^{2}(A_{l})}\cdot \mathrm{Var}\bigg(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\bigg)}\\ & {\quad = \bigg(\sum_{l\in \mathcal{D}}1(i\in A_{l})\frac{(\sum_{u\in A_{l}}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}})e^{\theta_{i}^{*}}}{f(A_{l})^{2}}\bigg)\bigg / \bigg[\sum_{l\in \mathcal{D}}1(i\in A_{l})\bigg(\frac{\sum_{u\in A_{l}}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\bigg)\frac{e^{\theta_{i}^{*}}}{f(A_{l})}\bigg]^{2}} \end{array} \tag{3.5}
\]

A few important comments are in order. Firstly, the function \(f\)
achieves the minimal variance in (3.5) when
\(\begin{array}{r}{f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}} \end{array}\)
due to simply applying the Cauchy- Schwarz inequality. Actually,

Maystre and Grossglauser (2015) showed that when
\(\begin{array}{r}f(A_l) = \sum_{u\in A_l}e^{\theta_u^*} \end{array}\) ,
spectral method estimator converges to the MLE up to the first order.
Secondly, under the situation of pairwise comparison in the BTL model,
each \((c_l,A_l)\) is independent and we assume in \(\mathcal{D}\) each
pair \((i,j)\) is either compared for \(L\) times (denoted as
\(\widetilde{A}_{ij} = 1\) ) or never compared (denoted as
\(\widetilde{A}_{ij} = 0\) ). Further assuming
\(f(A_{l}) = |A_{l}| = 2\) , we have

\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \frac{1}{L}\bigg(\sum_{j:j\neq i}\widetilde{A}_{ij}e^{\theta_i^*}e^{\theta_j^*}\bigg)\bigg / \bigg[\sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{e^{\theta_i^*} + e^{\theta_j^*}}\bigg]^2.
\]

This exactly matches with Proposition 4.2 of Gao et al.~(2021). In
addition, if we choose \(f(A_{l}) =\)
\(\textstyle \sum_{u\in A_l}e^{\theta_u^*}\) , we get the most efficient
variance just like the MLE variance given in Proposition 4.1 of Gao et
al.~(2021), which is

\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \left(L\cdot \sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{(e^{\theta_i^*} + e^{\theta_j^*})^2}\right)^{-1}.
\]

With the above discussion and computation, after some additional
derivations, we come to the conclusion that
\(\widetilde{\theta}_{i} - \theta_{i}^{*}\) has the same asymptotic
distribution as
\(\frac{\widetilde{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and
\(J_{i}^{*}\) . Therefore,

\[
\operatorname {Var}(J_i^* |\mathcal{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]

for all \(i\in [n]\) . Based on this result, we can make inference for
\(\widetilde{\theta}_{i}\) and additionally the rank of item \(i\) (see
Section 3.3). The rigorous derivations for this conclusion will be
provided in Section 4.

\section{3.2 Uncertainty quantification for the PL
model}\label{uncertainty-quantification-for-the-pl-model}

In this section, we consider the case of a random comparison graph,
which could potentially lead to dependent \((c_l,A_l)\) , unlike the
case of the fixed graph in the previous section. Note that since the
random comparison graph generation can be arbitrary, we cannot work with
each case. As an illustrating example, we consider the classical PL
model from the Erdos- Renyi graph here for two reasons. Firstly, this is
the most popularly studied random comparison model in the ranking
literature (Chen and Suh, 2015; Chen et al., 2022; Han et al., 2020; Liu
et al., 2022; Gao et al., 2021; Fan et al., 2022a,b). Secondly, we can
use the model to verify the uncertainty quantification of the spectral
method and compare it with that of the MLE. It turns out the model is
good enough to give us new insights. To further simplify the discussion
and presentation, we will only focus on \(M = 3\) in the PL model.
Results for general \(M\) can be similarly derived with the same
conclusion.

With the PL model, we can write down the specific variance of
\(J_{i}^{*}\) . Consider the most natural way to encode a 3- way
comparison. Say one ranks \((i,j,k)\) as \(i\vdash j\vdash k\) where
\(a\vdash b\) means \(a\) is better than \(b\) . Motivated by the
likelihood function, which multiplies the probability of selecting \(i\)
as the best one from \(\{i,j,k\}\) and the probability of selecting
\(j\) next from \(\{j,k\}\) , we break this complete 3- way comparison
into two dependent comparison data: \((i,\{i,j,k\})\) and
\((j,\{j,k\})\) . We call this multi- level breaking, where in the first
level comparison of all three items, \(i\) is preferred, and in the
second level comparison of the remaining items, \(j\) is preferred. By
doing this, we can naturally link

and compare results with the MLE estimator. Azari Soufiani et al.~(2013)
also proposed other ways of breaking an \(M\) - way comparison into
pairwise comparisons, but different breaking methods will lead to
different dependent structures, which we do not intend to analyze one by
one in this work. So in the sequel, we only consider multi- way
breaking, motivated by the likelihood function, and leave the study of
other possible breaking methods to the future. We use
\(\widetilde{A}_{ijk} = 1\) or \(0\) to denote whether \((i,j,k)\) has
been compared for \(L\) times or is never compared.

Let us work on the multi- level breaking. Now the key difference is that
the induced comparison graph \(\mathcal{G}\) cannot be treated as fixed.
Instead, we condition on
\(\widetilde{\mathcal{G}} = \{\widetilde{A}_{ijk}\}\) . Similar to
(3.2), we have

\[
\frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*}}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}}}{\sum_{j:j\neq i}E[P_{ij}|\widetilde{\mathcal{G}}]e^{\theta_{i}^{*}}} \eqqcolon J_{i}^{*}. \tag{3.6}
\]

In the case of the random comparison graph, i.e.~conditioning on
\(\widetilde{\mathcal{G}}\) , we obtain

\[
P_{ij} = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq i,j}\widetilde{A}_{ijk}Z_{ijk}^{\ell}, \tag{3.7}
\]

where
\(Z_{ijk}^{\ell} = 1(y_{k\gamma >j > i}^{(\ell)} = 1) / f(\{i,j\}) + 1(y_{j\gamma >k}^{(\ell)} = 1) / f(\{i,j,k\}) + 1(y_{j\gamma k\gamma i}^{(\ell)} = 1) / f(\{i,j,k\})\)
. Here \(y_{i_1\gamma i_2\gamma i_3}^{(\ell)}\) is a binary variable
which equals to \(1\) when the event \(i_1\searrow i_2\searrow i_3\)
holds under the \(\ell\) - th comparison among items \(\{i_1,i_2,i_3\}\)
. Essentially, we need to collect all terms induced from the same
comparison into one term \(Z_{ijk}^{\ell}\) so that the summation is
always over independent terms.

We lightly abuse the notation of \(J_{i}^{*}\) although here the
expectation is conditioning on \(\widetilde{\mathcal{G}}\) instead of
\(\mathcal{G}\) used in the fixed graph case. Note that

\[
E[Z_{ijk}^{\ell}|\widetilde{\mathcal{G}} ] = \frac{e^{\theta_{k}^{*}}e^{\theta_{j}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}})f(\{i,j\})} +\frac{e^{\theta_{j}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})}.
\]

Using \(\sum_{j\neq k}a_{ijk} = \sum_{j< k}(a_{ijk} + a_{ikj})\) , the
denominator of \(J_{i}^{*}\) can be expressed as

\[
\begin{array}{r l} & {\tau_{i}^{\diamond}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]e^{\theta_{i}^{*}} = \frac{L}{d}\sum_{j< k:j,k\neq i}\widetilde{A}_{i j k}e^{\theta_{i}^{*}}\Big(\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}})f(\{i,j\})}}\\ & {\qquad +\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})} +\frac{e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})}\Big).} \end{array}
\]

Hence, the expression of \(J_{i}^{*}\) is given as follows:

\[
\begin{array}{r l} & {\mathcal{I}_{i}^{*} = \frac{1}{\tau_{i}^{\diamond}}\Big(\sum_{j:j\neq i}P_{j i}e^{\theta_{j}^{*}} - P_{i j}e^{\theta_{i}^{*}}\Big) = \frac{1}{d\tau_{i}^{\diamond}}\Big(\sum_{\ell = 1}^{L}\sum_{j:j\neq i}\sum_{k:k\neq i,j}\widetilde{A}_{i j k}(Z_{j i k}^{\ell}e^{\theta_{j}^{*}} - Z_{i j k}^{\ell}e^{\theta_{i}^{*}})\Big)}\\ & {\quad = \frac{1}{d\tau_{i}^{\diamond}}\sum_{\ell = 1}^{L}\sum_{j< k:j,k\neq i}\widetilde{A}_{i j k}(Z_{j i k}^{\ell}e^{\theta_{j}^{*}} + Z_{k i j}^{\ell}e^{\theta_{k}^{*}} - Z_{i j k}^{\ell}e^{\theta_{i}^{*}} - Z_{i k j}^{\ell}e^{\theta_{i}^{*}}) = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{j< k:j,k\neq i}J_{i j k\ell}(\theta^{*}),} \end{array} \tag{3.8}
\]

where \(\tau_{i}^{\diamond}\) is short for
\(\tau_{i}^{\diamond}(\theta^{*})\) . Since each 3- way comparison is
independent, it can be shown that the variance of \(J_{i}^{*}\) is

\[
\widetilde{J}_{i}^{\diamond}(\widetilde{J}) = \frac{L}{d^{2}(\tau_{i}^{\diamond})^{2}}\sum_{j< k:j,k\neq i}\widetilde{A}_{ijk}e^{\theta_{i}^{*}}\Big(\frac{(e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})}{f^{2}(\{i,j,k\})} +\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}}}\Big(\frac{1}{f^{2}(\{i,k\})} +\frac{1}{f^{2}(\{i,j,k\})}\Big)\Big)
\]

The essential component is to compute \(EJ_{ijkl}(\theta^{*})^{2}\) due
to independence and zero- mean. For a given triplet \((i,j,k)\) , there
are 6 possible preference outcomes with probabilities governed by the PL
model. Averaging the squared random outcomes over 6 probabilities gives
\(EJ_{ijkl}(\theta^{*})^{2}\) , which results in the expression above.
We omit the details of these calculations.

Let us consider the simple situation that all \(\theta_{i}^{*}\) are
equal. In this case, if we apply the most efficient weighting function
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) , that is,
\(f(\{i,j,k\}) = 3\) , \(f(\{i,j\}) = f(\{i,k\}) = 2\) , we have
\(\mathrm{Var}(J_i^* |\widetilde{G}) = 18 / (7L)\) . However, if we
naively choose \(f\) as a constant function, we get
\(\mathrm{Var}(J_i^* |\widetilde{G}) = 8 / (3L)\) , which is indeed
larger. It is also worth noting that when we choose
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) , the
aforementioned variance matches with the variance of MLE in Fan et
al.~(2022b).

With the above formula of \(\mathrm{Var}(J_i^* |\widetilde{G})\) for the
PL model, we can also conclude that

\[
\mathrm{Var}(J_i^* |\widetilde{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]

for all \(i\in [n]\) . The rigorous arguments will be introduced in
Section 4.

\section{3.3 Ranking inference: one-sample confidence
intervals}\label{ranking-inference-one-sample-confidence-intervals}

In numerous practical applications, individuals frequently interact with
data and challenges related to rankings. The prevalent approach to
utilizing rankings typically revolves around computing preference scores
and then showcasing these scores in ranked order. These only provide
first- order information on ranks and can not answer many questions,
such as:

How do we ascertain with high confidence that an item's true rank is
among the top- 3 (or general \(K,K\geq 1\) ) choices? And how can we
establish a set of candidates with high confidence, guaranteeing that
the true top- 3 candidates are not overlooked? How do we analyze if the
ranking preferences for a given array of products are consistent in two
distinct communities (such as male and female) or the same community but
at two different time periods?

In sum, there is a need for tools and methodologies that address these
and other insightful queries in real- world applications involving
rankings, especially when the comparisons are drawn from a general
comparison graph.

Within this section, we first present a comprehensive framework designed
for the construction of two- sided confidence intervals for ranks. In
endeavoring to establish simultaneous confidence intervals for the
ranks, an intuitive methodology entails deducing the asymptotic
distribution of the empirical ranks, denoted as
\(\widetilde{r}_{m},m\in \mathcal{M}\) , and subsequently determining
the critical value. However, it is well known that this task poses
substantive challenges, given that \(\widetilde{r}_{m}\) is an integer
and is intrinsically dependent on all estimated scores, making its
asymptotic behavior daunting to analyze.

By capitalizing on the inherent interdependence between the scores and
their corresponding ranks, we discern that the task of formulating
confidence intervals for the ranks can be effectively converted to the
construction of simultaneous confidence intervals for the pairwise
differences among the population scores. It is notable that the
distribution of these empirical score differences is more amenable to
characterization. Consequently, we focus on the statistical properties
of the estimated scores \(\widetilde{\theta}_{m} \in [n]\) and present
our methodology for constructing two- sided (simultaneous) confidence
intervals for ranks through estimated score differences.

Example 3.1. We let \(\mathcal{M} = \{m\}\) , where \(1 \leq m \leq n\)
, to represent the item under consideration. We are interested in the
construction of the \((1 - \alpha) \times 100\%\) confidence interval
for the true population rank \(r_{m}\) , where \(\alpha \in (0,1)\)
denotes a pre- specified significance level. Suppose that we are able to
construct the simultaneous confidence intervals
\([\mathcal{C}_L(k,m), \mathcal{C}_U(k,m)], k \neq m, (k \in [n])\) for
the pairwise differences
\(\theta_{k}^{*} - \theta_{m}^{*}, k \neq m (k \in [n])\) , with the
following property:

\[
\mathbb{P}\Big(\mathcal{C}_L(k,m) \leq \theta_k^* - \theta_m^* \leq \mathcal{C}_U(k,m) \text{for all} k \neq m\Big) \geq 1 - \alpha . \tag{3.9}
\]

One observes that if \(\mathcal{C}_U(k,m) < 0\) (respectively,
\(\mathcal{C}_L(k,m) > 0\) ), it implies that
\(\theta_k^* < \theta_m^*\) (respectively, \(\theta_k^* > \theta_m^*\)
). Enumerating the number of items whose scores are higher than item
\(m\) gives a lower bound for rank \(r_{m}\) , and vice versa. In other
words, we deduce from (3.9) that

\[
\mathbb{P}\left(1 + \sum_{k \neq m} 1 \{C_L(k,m) > 0\} \leq r_m \leq n - \sum_{k \neq m} 1 \{C_U(k,m) < 0\}\right) \geq 1 - \alpha . \tag{3.10}
\]

This yields a \((1 - \alpha) \times 100\%\) confidence interval for
\(r_{m}\) , and our task reduces to construct simultaneous confidence
intervals for the pairwise differences (3.9).

We now formally introduce the procedure to construct the confidence
intervals for multiple ranks \(\{r_m\}_{m \in \mathcal{M}}\)
simultaneously. Motivated by Example 3.1, the key step is to construct
the simultaneous confidence intervals for the pairwise score differences
\(\{\theta_k^* - \theta_m^*\}_{m \in \mathcal{M}, k \neq m}\) such that
(3.9) holds. To this end, we let

\[
T_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{\widetilde{\theta}_k - \widetilde{\theta}_m - (\theta_k^* - \theta_m^*)}{\widetilde{\sigma}_{km}} \right|, \tag{3.11}
\]

where \(\{\widetilde{\sigma}_{km}\}_{k \neq m}\) is a sequence of
positive normalization given by (3.13) below. For any
\(\alpha \in (0,1)\) , let \(Q_{1 - \alpha}\) be critical value such
that \(\mathbb{P}(T_{\mathcal{M}} \leq Q_{1 - \alpha}) \geq 1 - \alpha\)
. Then, as in Example 3.1, our \((1 - \alpha) \times 100\%\)
simultaneous confidence intervals for \(\{r_m\}_{m \in \mathcal{M}}\)
are given by \(\{[R_{mL}, R_{mU}] \}_{m \in \mathcal{M}}\) , where

\[
= 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m > \widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right), \quad R_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m < -\widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right).
\]

\section{3.4 Multiplier bootstrap
procedure}\label{multiplier-bootstrap-procedure}

The key step for constructing the confidence interval of ranks of
interest is to pick the critical value \(Q_{1 - \alpha}\) . To calculate
the critical value above, we propose to use the wild bootstrap
procedure. The

uncertainty quantification for the spectral estimator in (3.2) reveals
that
\(\widetilde{\theta_{i}} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\)
uniformly over \(i \in [n]\) (see details in Section 4), which further
implies that asymptotically

\[
T_{\mathcal{M}} \approx \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{J_{k}(\theta^{*}) - J_{m}(\theta^{*})}{\widetilde{\sigma}_{km}} \right|. \tag{3.12}
\]

We focus on the fixed graph setting and leave the random graph setting
in Remark 3.2 below. Practically, the empirical version of
\(J_{i}(\theta^{*})\) can be obtained via plugging in the spectral
estimator \(\widetilde{\theta}\) , namely from (3.4),

\[
J_{i}(\widetilde{\theta}) = \frac{1}{d} \sum_{l \in \mathcal{D}} J_{il}(\widetilde{\theta}), \quad i \in [n].
\]

Let
\(\sigma_{km}^{2} = \operatorname {Var}\{J_{k}(\theta^{*}) - J_{m}(\theta^{*}) | \mathcal{G} \}\)
for each \(k \neq m\) . Then our estimator for \(\sigma_{km}^{2}\) is
defined by

\[
\widetilde{\sigma}_{km}^{2} = \frac{e^{\widetilde{\theta}_{k}}}{d^{2} \tau_{k}^{2}(\widetilde{\theta})} \sum_{l \in \mathcal{D}} \frac{1(k \in A_{l})}{f^{2}(A_{l})} \left(\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}} - e^{\widetilde{\theta}_{k}}\right) + \frac{e^{\widetilde{\theta}_{m}}}{d^{2} \tau_{m}^{2}(\widetilde{\theta})} \sum_{l \in \mathcal{D}} \frac{1(m \in A_{l})}{f^{2}(A_{l})} \left(\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}} - e^{\widetilde{\theta}_{m}}\right), \tag{3.13}
\]

where \(\tau_{k}(\widetilde{\theta})\) and
\(\tau_{m}(\widetilde{\theta})\) also plug in \(\widetilde{\theta}\) ;
see (3.5). Let
\(\omega_{1}, \ldots , \omega_{|\mathcal{D}|} \in \mathbb{R}\) be i.i.d.
\(N(0,1)\) random variables. The Gaussian multiplier bootstrap statistic
is then defined by

\[
G_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l} \right|. \tag{3.14}
\]

Let
\(\mathbb{P}^{*}(\cdot) = \mathbb{P}(\{|(e_{i}, A_{i})\}_{i \in \mathcal{D}})\)
denote the conditional probability. Then, for \(\alpha \in (0,1)\) , our
estimator for \(Q_{1 - \alpha}\) is defined by the \((1 - \alpha)\) th
conditional quantile of \(G_{\mathcal{M}}\) , namely

\[
\mathcal{Q}_{1 - \alpha} = \inf \{z: \mathbb{P}^{*}(G_{\mathcal{M}} \leq z) \geq 1 - \alpha \} ,
\]

which can be computed by the Monte Carlo simulation. Then, our
simultaneous confidence intervals
\(\{[\mathcal{R}_{mL}, \mathcal{R}_{mU}] \}_{m \in \mathcal{M}}\) are
given by

\[
\mathcal{R}_{mL} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right), \qquad \mathcal{R}_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} < -\widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right).
\]

Remark 3.1 (One- sample one- sided confidence intervals). Now we provide
details on constructing simultaneous one- sided intervals for population
ranks. For one- sided intervals, the overall procedure is similar to
constructing two- sided confidence intervals. Specifically, let

\[
G_{\mathcal{M}}^{\circ} = \max_{m \in \mathcal{M}} \max_{k \neq m} \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l}, \tag{3.16}
\]

where \(\omega_{1}, \ldots , \omega_{|\mathcal{D}|}\) are as before
i.i.d. \(N(0,1)\) random variables. Correspondingly, let
\(\mathcal{Q}_{1 - \alpha}^{\circ}\) be its \((1 - \alpha)\) th
quantile. Then the \((1 - \alpha) \times 100\%\) simultaneous lower
confidence bounds for \(\{r_{m}\}_{m \in \mathcal{M}}\) are given by
\(\{[\mathcal{R}_{mL}^{ \circ }, n] \}_{m \in \mathcal{M}}\) , where

\[
\mathcal{R}_{mL}^{\circ} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}^{\circ}\right). \tag{3.17}
\]

Remark 3.2 (Ranking inference for the PL model with random comparison
graph). Section 3.2 reveals that
\(\widetilde{\theta}_{i} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\)
uniformly over \(i \in [n]\) , where following (3.8),

\[
J_{i}(\theta^{*}) = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{j < s:j, s \neq i} J_{ijs\ell}(\theta^{*}).
\]

In order to carry out ranking inference for the PL model, we need to
rewrite this equation in a slightly different format. Let
\(\begin{array}{r}{\mathcal{N} = \sum_{i< j< k}\widetilde{A}_{i j k}} \end{array}\)
denote the total number of connected components on the random graph
\(\widetilde{G}\) and write \(\{(i,j,k):i< j< k\) and
\(\widetilde{A}_{i j k} = 1\} \eqqcolon \{\widetilde{A}_{q}\}_{q = 1,\ldots ,\mathcal{N}}\)
. Let \(y_{q}^{(\ell)}\) denote the \(\ell\) - th full- ranking
comparison result for \(A_{q}\) . Then we can rewrite \(P_{ij}\) as

\[
P_{ij} = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \sum_{k \neq i, j} 1\{(i,j,k) = \widetilde{A}_{q}\} Z_{ijkq}^{(\ell)}, i \neq j,
\]

where for \(i\neq j\neq k\) and \(q\in \lfloor \mathcal{N}\rfloor\) ,
and
\(Z_{i j k q}^{(\ell)} = 1\{y_{q}^{(\ell)} = (k\cdot \gamma \cdot j\cdot \gamma \cdot i)\} /f(\{i,j\}) + (1\{y_{q}^{(\ell)} = (j\cdot \gamma \cdot i)\} /f(\{i,j,k\})\)
\(k)\} +1\{y_{q}^{(\ell)} = (j\cdot k\cdot \gamma \cdot i)\} /f(\{i,j,k\})\)
. It is straightforward to verify that this \(P_{ij}\) is exactly the
same with (3.7). Therefore, we rewrite
\(\begin{array}{r}{J_{i}(\theta^{*}) = d^{- 1}\sum_{\ell = 1}^{L}\sum_{q = 1}^{N}J_{i q\ell}^{\diamond}(\theta^{*})} \end{array}\)
, where

\[
J_{iq\ell}^{\diamond}(\theta^{*}) = \sum_{j < s:j, s \neq i} 1\{(i,j,s) = \widetilde{A}_{q}\} J_{iq\ell}^{\diamond}(\theta^{*}). \tag{3.18}
\]

As is assumed,
\(\{J_{iq\ell}^{\diamond}(\theta^{*})\}_{\ell \in [L], q \in [\mathcal{N}]}\)
are independent for each \(i \in [n]\) conditioning on the comparison
graph \(\widetilde{G}\) . Let
\(\{\omega_{q\ell}^{\diamond}\}_{q, \ell \in \mathbb{N}}\) be i.i.d.
\(N(0,1)\) random variables. Then, following (3.14), the corresponding
bootstrap test statistic is given by

\[
G_{\mathcal{M}}^{\diamond} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}^{\diamond}} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \{J_{kq\ell}^{\diamond}(\widetilde{\theta}) - J_{mq\ell}^{\diamond}(\widetilde{\theta})\} \omega_{q\ell} \right|,
\]

where \(\{\widetilde{\sigma}_{km}^{\diamond}\}_{k \neq m}\) are as
before the sequence of positive normalization, calculated as the sum of
the variance of \(J_{k}(\theta^{*})\) and \(J_{m}(\theta^{*})\) similar
to (3.13). Consequently, the simultaneous confidence intervals for the
ranks can be similarly constructed.

\section{3.5 Ranking inference: two-sample and one-sample testing
applications}\label{ranking-inference-two-sample-and-one-sample-testing-applications}

In this section, we further illustrate how we may apply our inference
methodology to a few salient testing applications, in both one- sample
and two- sample testing.

Example 3.2 (Testing top- \(K\) placement). Let \(\mathcal{M} = \{m\}\)
for some \(m \in [n]\) and let \(K \geq 1\) be a prescribed positive
integer. Our objective is to ascertain if the item \(m\) is a member of
the top- \(K\) ranked items. Consequently, we shall examine the
following hypotheses:

\[
H_{0}:r_{m}\leq K\mathrm{~versus~}H_{1}:r_{m} > K. \tag{3.19}
\]

Based on the one- sided confidence interval
\([\mathcal{R}_{mL}^{\circ}, n]\) in (3.17), for any
\(\alpha \in (0,1)\) , a level \(\alpha\) test for (3.19) is simply
given by \(\phi_{m,K} = 1\{\mathcal{R}_{mL}^{\circ} > K\}\) . Under the
conditions of Theorem E.1, we have
\(\mathbb{P}(\phi_{m,K} = 1|H_{0}) \leq \alpha + \mathrm{o}(1)\) , that
is, the effective control of the Type- I error can be achieved below the
significant level \(\alpha\) when the null hypothesis is true.

Example 3.3 (Top- \(K\) sure screening set). Another example is on
constructing a screened candidate set that contains the top- \(K\) items
with high probability. This is particularly useful in college candidate
admission or company hiring decisions. Oftentimes, a university or a
company would like to design certain admission or hiring policy with the
high- probability guarantee of the sure screening of true top- \(K\)
candidates.

Let \(\mathcal{K} = \{r^{- 1}(1),\ldots ,r^{- 1}(K)\}\) denote the top-
\(K\) ranked items of the rank operator \(r:[n]\to [n]\) . We aim at
selecting a set of candidates \(\widehat{\mathcal{I}}_K\) which contains
the top- \(K\) candidates with a prescribed probability. Mathematically,
this requirement can be expressed as
\(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\)
, where \(\alpha \in (0,1)\) . Herein, we define \(\mathcal{M} = [n]\) ,
and let \(\{[\mathcal{R}_{mL}^{\circ},n],m\in [n]\}\) represent the set
of \((1 - \alpha)\times 100\%\) simultaneous left- sided confidence
intervals, as given in (3.17). It is easy to observe that the inequality
\(\mathcal{R}_{mL}^{\circ} > K\) infers that \(r_m > K\) . Consequently,
a selection for \(\widehat{\mathcal{I}}_K\) , that satisfies the
probability constraint
\(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\)
, is given by

\[
\widehat{\mathcal{I}}_K = \{m\in [n]:\mathcal{R}_{mL}^{\circ}\leq K\} .
\]

Example 3.4 (Testing ranks of two samples). In many applications, we are
concerned with the question of whether the ranks of certain items using
two samples have been changed or preserved. For example, we may care
about whether

\begin{itemize}
\tightlist
\item
  Ranking allocation differs before and after a treatment or policy
  change.- Different communities such as males versus females can have
  different ranking preferences over the same set of products.- People's
  perceived preferences over the same things have changed in two time
  periods.
\end{itemize}

Suppose we observe two independent datasets \(\mathcal{D}_1\) and
\(\mathcal{D}_2\) with preference scores
\(\theta_{[1]}^{*} = (\theta_{11}^{*},\ldots ,\theta_{1n}^{*})^{\top}\)
and
\(\theta_{[2]}^{*} = (\theta_{21}^{*},\ldots ,\theta_{2n}^{*})^{\top}\)
. The associated true rankings are respectively denoted by

\[
r_{[1]} = (r_{11},\ldots ,r_{1n})^{\top} \text{and} r_{[2]} = (r_{21},\ldots ,r_{2n})^{\top}.
\]

Given any \(m\in [n]\) , we are interested in testing whether the same
rank is preserved for item \(m\) across these two samples, that is,
testing the hypotheses

\[
H_{0}:r_{1m} = r_{2m} \text{versus} H_{1}:r_{1m}\neq r_{2m} \tag{3.20}
\]

To this end, firstly we construct simultaneous confidence intervals
\([R_{1mL},R_{1mU}]\) and \([R_{2mL},R_{2mU}]\) such that

\[
\mathbb{P}(r_{1m}\in [R_{1mL},R_{1mU}]\text{and} r_{2m}\in [R_{2mL},R_{2mU}])\geq 1 - \alpha . \tag{3.21}
\]

Then our \(\alpha\) - level test for (3.20) is defined by

\[
\phi_{m} = 1\{|[R_{1mL},R_{1mU}]\cap [R_{2mL},R_{2mU}]| = 0\} .
\]

It is straightforward to verify that
\(\mathbb{P}(\phi_{m} = 1|H_{0})\geq 1 - \alpha\) .

Example 3.5 (Testing top- \(K\) sets of two samples). Besides testing
for a single or a few ranks, one may want to evaluate whether two top-
\(K\) sets are identical or not, between two groups of people, two
periods of time, or before and after a significant event or change. Let
\(\mathcal{S}_{1K} = \{r_{[1]}^{- 1}(1),\ldots ,r_{[1]}^{- 1}(K)\}\) and
\(\mathcal{S}_{2K} = \{r_{[2]}^{- 1}(1),\ldots ,r_{[2]}^{- 1}(K)\}\)
denote the sets of top- \(K\) ranked items, respectively. We consider
testing the hypotheses

\[
H_{0}:S_{1K} = S_{2K}\mathrm{~versus~}H_{1}:S_{1K}\neq S_{2K}. \tag{3.22}
\]

For \(\alpha \in (0,1)\) , we begin with constructing
\((1 - \alpha)\times 100\%\) simultaneous confidence sets
\(\widehat{\mathcal{I}}_{1K}\) and \(\widehat{\mathcal{I}}_{2K}\) for
\(S_{1K}\) and \(S_{2K}\) such that

\[
\mathbb{P}\left(S_{1K}\subset \widehat{\mathcal{I}}_{1K}\mathrm{~and~}S_{2K}\subset \widehat{\mathcal{I}}_{2K}\right)\geq 1 - \alpha . \tag{3.23}
\]

Then our \(\alpha\) - level test for (3.22) is defined by

\[
\widetilde{\phi}_{K} = 1\{|\widehat{\mathcal{I}}_{1K}\cap \widehat{\mathcal{I}}_{2K}|< K\} .
\]

Remark 3.3. Several methodologies, including the Bonferroni adjustment
(which constructs a \((1 - \alpha /2)\times 100\%\) confidence interval
for each source), and Gaussian approximation (achieved by taking the
maximum of the test statistics of each source), enable us to establish
simultaneous confidence intervals as illustrated in equations (3.21) and
(3.23). To maintain clarity and simplicity in the subsequent context, we
simply employ the Bonferroni adjustment for two samples. Moreover, the
framework outlined in Examples 3.4 and 3.5 can be extended in a
straightforward way to evaluate whether the ranks of items or sets are
identical across three or more sources.

\section{4 Theoretical Justifications}\label{theoretical-justifications}

In this section, we rigorously justify the conclusions in Section 3 and
explicitly lay out the necessary assumptions to arrive at those
conclusions. The first assumption is to make sure we are comparing
\(\theta_{i}^{*}\) 's in the same order in a meaningful way. Otherwise,
we can always group items into categories with similar qualities and
then work on each sub- group or screen some extreme items. In addition,
as we have discussed, we need an identifiability condition for
\(\theta^{*}\) .

Assumption 4.1. There exists some positive constant
\(\bar{\kappa} < \infty\) such that

\[
\max_{i\in [n]}\theta_{i}^{*} - \min_{i\in [n]}\theta_{i}^{*}\leq \bar{\kappa}.
\]

In addition, for identifiability, assume \(1^{\top}\theta^{*} = 0\) .

In Assumption 4.1, we assume \(\bar{\kappa}\) is finite, indicating we
only rank items with preference scores on the same scale. If
\(\bar{\kappa}\) is diverging, some items will be trivially more or less
favorable than others. In this case, it is typically easy in practice to
separate the items into subgroups with similar preference scores, and
then we can conduct ranking inference within each group. Although we
assume bounded \(\bar{\kappa}\) , it serves as the role of a condition
number whose effect has been made explicit in all our results for
interested readers. However, we do not claim this dependency is optimal
as our nontrivial analysis can easily encounter powers of
\(e^{\bar{\kappa}}\) , say in bounding the ratio of
\(\pi_{i}^{*} / \pi_{j}^{*}\) .

\section{4.1 Estimation accuracy and asymptotic normality with fixed
comparisons}\label{estimation-accuracy-and-asymptotic-normality-with-fixed-comparisons}

To derive the asymptotic distribution of the spectral estimator, we need
to rigorously justify the approximations (3.1) and (3.2). We first take
care of approximating (3.1) using (3.2), where all comparisons in
\(\mathcal{G}\) are assumed to be fixed. Note that

\[
P_{ij} - E[P_{ij}|\mathcal{G}] = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_l)\left[1(c_l = j) - \frac{\pi_j^*}{\sum_{u\in A_l}\pi_u^*}\right]\frac{1}{f(A_l)}.
\]

Let \(Z_{A_l}^j = 1(c_l = j) / f(A_l)\) , which is bounded from above
and below as long as \(f\) is bounded from above and below. Furthermore,
each \(Z_{A_l}^j\) is independent. Therefore,
\(P_{ij} - E[P_{ij}|\mathcal{G}] = d^{- 1}\sum_{l\in \mathcal{D}}1(i,j\in A_l)[Z_{A_l}^j - E(Z_{A_l}^j)]\)
. By Hoeffding's inequality, conditioning on \(\mathcal{G}\) , we have
with a large probability \(1 - o(1)\) ,

\[
\max_{i\neq j}\left|P_{ij} - E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\ddagger}}.
\]

where
\(\begin{array}{r}{n^{\ddagger} = \max_{i\neq j}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})} \end{array}\)
is the maximum number of cases that each pair is compared. Similarly, we
can get the concentration bound for
\(\textstyle \sum_{j:j\neq i}P_{ij}\) . Since \(Z_{A_{l}}^{j}\) 's are
independent, another level of summation over \(j\) will lead to the
following. Again by Hoeffding's inequality, with a large probability
tending to 1, we obtain

\[
\max_{i}\left|\sum_{j:j\neq i}P_{ij} - \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\dagger}},
\]

where
\(\begin{array}{r}{n^{\dagger} = \max_{i}\sum_{l\in \mathcal{D}}1(i\in A_{l})} \end{array}\)
is the maximum number of cases that each item is compared. In addition,
we assume

\[
\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}] = \tau_{i}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger},
\]

where \(\tau_{i}\) defined in (3.3) is the denominator of \(J_{i}^{*}\)
. This assumption makes sense as
\(\tau_{i}e^{- \theta_{i}^{*}}\lesssim \sum_{l\in \mathcal{D}}1(i\in A_{l}) / d\)
, and it states for each \(i\) the comparison graph cannot be too
asymmetric. Note that \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) can
still be widely different from \(n^{\ddagger}\) for different pair
\((i,j)\) . Since the expectation term dominates the deviation if
\(n^{\dagger}\gtrsim \log n\) , it is not hard to show that in (3.2),
changing the denominator by its expectation will only cause a small
order difference, which does not affect the asymptotic distribution.

Based on the above discussion, we impose the following assumption.

Assumption 4.2. In the case of a fixed comparison graph, we assume the
graph is connected,
\(\tau_{i}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all
\(i\in [n]\) , \(e^{2\bar{\kappa}}\log n = o(n)\) and
\(e^{3\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^{1 / 2} = o(n^{\dagger})\)
.

The assumption is reasonable for a fixed comparison graph. If each pair
\((i,j)\) must be compared at least once, then every
\(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\geq 1\) . If they are all in
the same order, then
\(\sum_{l\in \mathcal{D}}1(i\in A_{l}) = \sum_{j:j\neq i}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\)
should be indeed in the order of \(n^{\ddagger}n\) . Assumption 4.2
allows some pair \((i,j)\) to be never compared directly, so we need to
leverage the information from comparing \(i\)

and \(j\) to other items separately. Moreover, we also do not require
\(\sum_{l\in \mathcal{D}}1(i,j\in A_l)\) to be in the same order for any
\(i,j:i\neq j\) since we only require the maximum pairwise degree
\(n^{\ddagger}\) to satisfy Assumption 4.2. However, in the case of a
fixed graph, we do not have the randomness from the graph, and the graph
must be relatively dense to make sure we have enough information to rank
every item. This condition will be relaxed to
\(n^{\dagger}\gtrsim n^{\ddagger}\log n\) when we have a homogeneous
random comparison graph in Section 4.2. .

We need another technical condition on the structure of the comparison
graph. Define \(\Omega = \{\Omega_{ij}\}_{i\leq n,j\leq n}\) where
\(\Omega_{ij} = - P_{ji}\pi_j^*\) for \(i\neq j\) and
\(\Omega_{ii} = \sum_{j:j\neq i}P_{ij}\pi_i^*\) . Note that as we
derived above, \(E[\Omega_{ii}|\mathcal{G}]\) is in the order of
\(n^{\dagger} / (dn)\) . We hope to understand the order of its
eigenvalues. Since \(\Omega\) has the minimal eigenvalue equal to zero,
with the corresponding eigenvector \(\mathbf{1}\) , we only focus on the
space orthogonal to \(\mathbf{1}\) . Following the notation of Gao et
al.~(2021),

\[
\lambda_{\min ,\bot}(A) = \min_{\| v\| = 1,v^{\top}\mathbf{1} = 0}v^{\top}A v.
\]

Assumption 4.3. There exist \(C_1,C_2 > 0\) such that

\[
C_1e^{-\bar{\kappa}}\frac{n^\dagger}{dn}\leq \lambda_{\min ,\bot}(E[\Omega |\mathcal{G}])\leq \lambda_{\max}(E[\Omega |\mathcal{G}])\leq C_2e^{\bar{\kappa}}\frac{n^\dagger}{dn}, \tag{4.1}
\]

\[
\| \Omega -E[\Omega |\mathcal{G}]\| = o_{P}\left(\frac{n^{\dagger}}{dn}\right). \tag{4.2}
\]

When \(\bar{\kappa} = O(1)\) , Assumption 4.3 requires that all
eigenvalues (except the minimal one) of \(E[\Omega |\mathcal{G}]\) are
in the order of \(n^{\dagger} / (dn)\) and \(\Omega\) also shares this
same eigenvalue scale as \(E[\Omega |\mathcal{G}]\) . This assumption is
intuitively correct, as we have seen that
\(E[\Omega_{ij}]\lesssim n^{\ddagger} / (dn)\) for \(i\neq j\) and
\(E[\Omega_{ii}]\asymp n^{\dagger} / (dn)\) . We will also rigorously
show that this condition can be satisfied if we consider the PL model
(Theorem 4.3).

Theorem 4.1. Under Assumptions 4.1- 4.3, the spectral estimator
\(\widetilde{\theta_{i}}\) has the following uniform approximation:
\(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + \delta_{i}\) ,
uniformly for all \(i\in [n]\) , where
\(\| \delta \coloneqq (\delta_{1},\dots ,\delta_{n})\|_{\infty} = o(1 / \sqrt{n^{\dagger}})\)
with probability \(1 - o(1)\) .

To prove Theorem 4.1, we need to verify (3.1). We leave the detailed
proof in the appendix. Given Theorem 4.1, we can easily conclude the
next theorem following the properties of \(J_{i}^{*}\) , which lead to
the rate of convergence for \(\widetilde{\theta}\) as well as its
asymptotic normality.

Remark 4.1. The results of Theorem 4.1 and the following Theorems are
proved via Bernstein and Hoeffding type inequalities with union bound
over \(n\) items. Therefore, all of the high- probability terms hold
with probability \((1 - o(1))\) (similarly for \(o_{p}(\cdot)\) and
\(O_{p}(\cdot)\) ) mentioned in the main text equivalently hold with
probability in form of \(1 - O(n^{- \zeta})\) where \(\zeta \geq 2\) is
a positive integer (different choice of \(\zeta\) will only affect
constant terms in the involved concentration inequalities).

Theorem 4.2. Under Assumptions 4.1- 4.3, the spectral estimator (2.1)
satisfies that

\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\asymp \| J^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{n^{\dagger}}}, \tag{4.3}
\]

with probability \(1 - o(1)\) , where
\(J^{*} = (J_{1}^{*},\dots ,J_{n}^{*})\) with \(J_{i}^{*},i\in [n]\)
being defined in (3.4). In addition,

\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]

for all \(i\in [n]\) with

\[
\begin{array}{r}{\mathbf{\Phi}_{i}(\theta) = \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{\sum_{u\in A_{l}}e^{\theta_{u}}}\right)\frac{e^{\theta_{i}}}{f(A_{l})}\right] / \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{f(A_{l})}\right)\frac{e^{\theta_{i}}}{f(A_{l})}\right]^{1 / 2}} \end{array}
\]

for both \(\theta = \theta^{*}\) and \(\theta =\) any consistent
estimator of \(\theta^{*}\) .

Note that Theorem 4.2 indicates that the choice of \(f(\cdot) > 0\) does
not affect the rate of convergence, but it affects the estimation
efficiency. As we argued in Section 3.1, the optimal weighting to
minimize the asymptotic variance is
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) in the class of
spectral estimators. In practice, however, we do not know
\(\theta_{u}^{*}\) beforehand. Therefore, we could implement a two- step
procedure to improve the efficiency of the spectral estimator: in the
first step, we obtain our initial consistent estimator
\(\widehat{\theta_{u}^{(\mathrm{initial})}}\) with weighting say
\(f(A_{l}) = |A_{l}|\) , and in the second step, we estimate
\(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) by plugging
\(\widehat{\theta_{u}^{(\mathrm{initial})}}\) and run the spectral
method again with this optimal weighting to get the final asymptotically
efficient estimator \(\widehat{\theta_{u}^{(\mathrm{final})}}\) . Note
that we do not intend to prove the theoretical properties of this two-
step estimator, as the data dependency in the optional weighting of the
second step makes the uniform approximation analysis highly nontrivial
due to non- i.i.d. ranking outcomes. Nonetheless, we could circumvent
this theoretical difficulty by splitting data into a very small part
\((o(|\mathcal{D}|)\) samples) for step 1, to achieve consistency with a
worse convergence rate, and using the remaining majority
\((|\mathcal{D}| - o(|\mathcal{D}|)\) samples) for step 2, to maintain
the same asymptotic behavior. In addition, empirically, we found that
directly using the same whole data in both steps achieves decent
performance given a large sample size. We refer interested readers to
our numerical studies.

\section{4.2 Estimation accuracy and asymptotic normality for the PL
model}\label{estimation-accuracy-and-asymptotic-normality-for-the-pl-model}

In the random graph case, we have to specify the graph generation
process in order to study the theoretical properties. We consider the
commonly used PL model, where we sample each \(M\) - way comparison with
probability \(p\) and compare this set for \(L\) times. Furthermore, we
will only work with \(M = 3\) since we plan to focus on a transparent
and intuitive discussion. We can easily generalize all the discussions
to general \(M\) , but derivations and formulas can be more tedious.

The PL model with 3- way comparisons has been studied in Fan et
al.~(2022b) by using MLE, where they explicitly write down the
likelihood function. The proposed spectral method can work for any fixed
graph, including the one generated from the PL model. In this section,
we would like to compare the performance of the spectral method with
that of the MLE. To make sure the spectral method works for the PL
model, we need to prove the approximations (3.1) and (3.6).

We first take care of (3.6). Consider conditioning on
\(\widetilde{\mathcal{G}}\) , where all comparisons in
\(\widetilde{\mathcal{G}}\) are independent; each
\(\widetilde{A}_{ijk}\) is compared for \(L\) times if
\(\widetilde{A}_{ijk} = 1\) . Now \(c_{l}\) and \(A_{l}\) are induced
from \(\widetilde{\mathcal{G}}\) , and

can be dependent. In this case, we can write

\[
P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}} ] = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq j,i}\widetilde{A}_{ijk}[Z_{ijk}^{l} - EZ_{ijk}^{l}],
\]

where
\(Z_{ijk}^{l} = 1(A_{l} = \{i,j\} ,c_{l} = j) / f(\{i,j\}) + 1(A_{l} = \{i,j,k\} ,c_{l} = j) / f(\{i,j,k\})\)
, which is again bounded from above and below and independent for any
given \(\widetilde{A}_{ijk}\) . In this case, with a little abuse of
notations, we redefine

\[
n^{\dagger} = L\max_{i\neq j}\sum_{k:k\neq j,i}A_{ijk},\quad n^{\dagger} = L\max_{i}\sum_{j< k:j,k\neq i}A_{ijk}.
\]

Similar to Section 4.1, conditional on \(\widetilde{G}\) , we have

\[
\begin{array}{r l} & {\max_{i}\bigg|\sum_{j:j\neq i}P_{i j} - \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\dagger}\log n}),}\\ & {\max_{i\neq j}\bigg|P_{i j} - E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\ddagger}\log n}),}\\ & {\sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ] = \tau_{i}^{\diamond}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger} \mathrm{(assumption)}.} \end{array}
\]

We adapt Assumption 4.2 to the following assumption. Note that we have
no assumption on \(L\) , so \(L\) can be as low as 1.

Assumption 4.4. In the PL model with \(M\) - way complete comparisons,
choose \(d\asymp n^{\dagger}\) in the spectral ranking, and assume
\(\tau_{i}^{\diamond}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for
all \(i\in [n]\) , \(e^{4\bar{\kappa}} = o(n)\) and
\(p\gtrsim e^{6\bar{\kappa}}\mathrm{poly}(\log n) / \binom{n- 1}{M- 1}\)

Under Assumption 4.4, we can prove

\[
n^{\dagger}\asymp \binom{n-1}{M-1}p L,\qquad\max \Big\{\binom{n-2}{M-2}p-\log n,0\Big\}L\lesssim n^{\ddagger}\lesssim\Big[\binom{n-2}{M-2}p+\log n\Big]
\]

with probability \(1 - o(1)\) . Note that in \(n^{\dagger}\) , by
Assumption 4.4, we know the dominating term is
\(\textstyle{\binom{n- 1}{M- 1}}p L\) . However, in \(n^{\ddagger}\) ,
we have the additional term \(\log n\) , which comes from the sub-
exponential tail decay in Bernstein inequality, and if \(p\) is really
small, it could happen that \(\log n\) dominates \(n^{\ddagger}\) . When
\(p\) is large, that is \(\textstyle{\binom{n- 2}{M- 2}}p\gtrsim\log n\)
, then \(n^{\ddagger}\asymp n n^{\ddagger}\) and Assumption 4.2 holds.
Therefore, we have a dense comparison graph, and the proof for this part
follows in a similar vein as Theorem 4.2. When \(p\) is small, that is,
\(\textstyle{\binom{n- 2}{M- 2}}p\lesssim\log n\) ,
\(n^{\ddagger}\lesssim\log n\) if \(L\) is bounded. In this case, we
will modify the proof of Theorem 4.2 to the random graph case in order
to show Theorem 4.4 below. In addition, since
\(\begin{array}{r}{\sum_{j:j\neq i}P_{i j} = \mathcal{O}_{P}(n^{\dagger} / d)} \end{array}\)
, it makes sense to choose \(d\asymp n^{\dagger}\) in Assumption 4.4 to
make the diagonal elements of the transition matrix a constant order.
Note that in the fixed graph case, we do not need to impose rate
assumptions on \(d\) as the comparison graph has no randomness.

Next, we verify that under the PL model, Assumption 4.3 holds with high
probability.

Theorem 4.3. Under the PL model and Assumption 4.4, with probability
\(1 - o(1)\) , Assumption 4.3 holds when we condition on
\(\widetilde{G}\) instead of \(\mathcal{G}\) .

We next hope to show that under Assumptions 4.4, the spectral estimator
\(\widehat{\theta}_{i}\) has the uniform approximation: the differences
between \(\widetilde{\theta}_{i} - \theta_{i}^{*}\) and \(J_{i}^{*}\)
for all \(i\in [n]\) are \(o_{P}(1 / \sqrt{n^{\dagger}})\) . The key
step is still the verification of (3.1) under this weaker Assumptions
4.4 for a random comparison graph.

Theorem 4.4. Under the PL model and Assumptions 4.1 and 4.4, the
spectral estimator \(\widetilde{\theta}_{i}\) has the uniform
approximation:
\(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + o_{P}\big(1 / \sqrt{n^{\dagger}}\big)\)
, uniformly for all \(i\in [n]\) . Therefore, the spectral estimator
(2.1) satisfies

\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{\binom{n - 1}{M - 1}pL}}, \tag{4.5}
\]

with probability \(1 - o(1)\) . In addition,

\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]

for all \(i\in [n]\) with
\(\rho_{i}(\theta) = \mathrm{Var}(J_{i}^{*}|\widetilde{G})^{- 1 / 2}\) ,
where in the formula of \(\mathrm{Var}(J_{i}^{*}|\widetilde{G})\) we can
choose both \(\theta = \theta^{*}\) and \(\theta =\) any consistent
estimator of \(\theta^{*}\) .

Remark 4.2. The two- step estimator under optimal weight
\(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) (can be consistently
estimated with a small proportion of a separate dataset) achieves the
same variance as the MLE estimator, which matches the Cramer Rao lower
bound among all estimators (Fan et al., 2022a,b).

Corollary 4.1. Under the conditions of Theorem 4.4, if we have
\(\theta_{(K)}^{*} - \theta_{(K + 1)}^{*}\geq \Delta\) , with
\(\theta_{(i)}^{*}\) denoting the underlying score of the item with true
rank \(i\) for \(i\in [n]\) , and when the sample complexity satisfies

\[
e^{2\bar{\kappa}}\Delta^{-2}\cdot \log n = \mathcal{O}\bigg(\binom{n-1}{M-1}pL\bigg),
\]

we have
\(\{i\in [n],\widehat{r_{i}}\leq K\} = \{i\in [n],r_{i}^{*}\leq K\}\)
(the selected top- K set is identical to the true top- K set), where
\(\widehat{r_{i}},r_{i}^{*}\) denote the empirical rank of
\(\widehat{\theta}_{i}\) among \(\{\widehat{\theta}_{i},i\in [n]\}\) and
true rank of the i- th item, respectively.

We remark that when \(M = 2\) , and \(\bar{\kappa} = \mathcal{O}(1)\) ,
our conclusion from Corollary 4.1 reduces to the conclusion of Theorem 1
in Chen et al.~(2019).

\section{4.3 Validity Justification for Bootstrap
Procedure}\label{validity-justification-for-bootstrap-procedure}

The primary goal of this section is to justify the validity of the
proposed bootstrap procedure in Section 3.4. Recall that the targeted
quantity \(T_{\mathcal{M}}\) is the maximum modulus of the random vector

\[
\Delta_{\mathcal{M}}\coloneqq \left\{\frac{\widetilde{\theta}_{k} - \widetilde{\theta}_{m} - (\theta_{k}^{*} - \theta_{m}^{*})}{\widetilde{\sigma}_{km}}\right\}_{m\in \mathcal{M},k\neq m}.
\]

For each marginal of \(\Delta_{\mathcal{M}}\) , the asymptotic normality
can be similarly established following Theorem 4.2. However, studying
the asymptotic distribution of \(\| \Delta_{\mathcal{M}}\|_{\infty}\)
becomes quite challenging as

its dimension \((n - 1)|\mathcal{M}|\) can increase with the number of
items. In particular, the traditional multivariate central limit theorem
for \(\Delta_{\mathcal{M}}\) may no longer be valid asymptotically
(Portnoy, 1986). To handle the high dimensionality, we shall invoke the
modern Gaussian approximation theory (Chernozhukov et al., 2017, 2019)
in order to derive the asymptotic distribution of
\(\| \Delta_{\mathcal{M}}\|_{\infty}\) , shown in Theorem E.1. Moreover,
the validity of our multiplier bootstrap procedure is justified in the
following theorem.

Theorem 4.5. Assume \(e^{3\bar{\kappa}}(\log n)^2 = o(n)\) and
\(e^{5\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^3 = o(n^{\dagger})\) .
Then, under the conditions of Theorem 4.1, we have

\[
|\mathbb{P}(T_{\mathcal{M}} > \mathcal{Q}_{1 - \alpha}) - \alpha |\to 0.
\]

Remark 4.3. Theorem 4.5 indicates that the estimated critical value
\(\mathcal{Q}_{1 - \alpha}\) from the Gaussian multiplier bootstrap
indeed controls the significance level of the simultaneous confidence
intervals (3.15) for \(\{r_m\}_{m\in \mathcal{M}}\) to the prespecified
level \(\alpha\) , that is,

\[
\mathbb{P}\Big(r_{m}\in [\mathcal{R}_{mU},\mathcal{R}_{mR}]\mathrm{~for~all~}m\in \mathcal{M}\Big)\geq 1 - \alpha +o(1).
\]

Recently Fan et al.~(2022b) proposed a similar approach to construct
simultaneous confidence intervals for ranks in the context of the PL
model with only the top choice observed for each comparison, which,
however, requires the number of comparisons \(L\) for each connected
item to be sufficiently large such that
\(L\gtrsim \mathrm{poly}(\log n)\) . In contrast, our procedure in
Section 3.4 works without any constraints on the number of comparisons
for each \(A_{l}\) (i.e., we even allow \(L = 1\) for all comparisons)
and is thus much more widely applicable, since in many real problems,
sets of size \(M\) can be compared at different times and sometimes only
once.

\section{7 Conclusion and Discussion}\label{conclusion-and-discussion}

In this work, we studied the performance of the spectral method in
preference score estimation, quantified the asymptotic distribution of
the estimated scores, and explored one- sample and two- sample inference
on ranks. In particular, we worked with general multiway comparisons
with fixed comparison graphs, where the size of each comparison can vary
and can be as low as only one. This is much closer to real applications
than the homogeneous random sampling assumption imposed in the BTL or PL
models. The applications of journal ranking and movie ranking have
demonstrated the clear usefulness of our proposed methodologies.
Furthermore, we studied the relationship between the spectral method and
the MLE in terms of estimation efficiency and revealed that with a
carefully chosen weighting scheme, the spectral method can approximately
achieve the same efficiency as the MLE, which is also verified using
numerical simulations. Finally, to the best of our knowledge, it is the
first time that effective two- sample rank testing methods have been
proposed in the literature.

Although we have made significant improvements in relaxing conditions,
the role of general comparison graphs is still not fully understood,
especially in the setting of multiway comparisons. Questions like how to
design a better sampling regime, either online or offline, remain open.
In addition, the spectral method essentially encodes multiway
comparisons into pairwise comparisons, where the encoding will break
data independence. The best encoding or breaking method should be
further investigated. Finally, a set of recent works on ranking
inferences opens the door to many possibilities of theoretical studies
on ranking inferences and related problems such as assortment
optimization, under the setting of, say, rank time series, rank change
point detection, rank panel data, recommendation based on rank
inferences, uncertainty quantification and inference for properties of
the optimal assortment. These may find potential application in numerous
management settings.

\section{References}\label{references}

Aouad, A., Farias, V., Levi, R. and Segev, D. (2018). The
approximability of assortment optimization under ranking preferences.
\emph{Operations Research}, \textbf{66} 1661- 1669. Avery, C. N.,
Glickman, M. E., Hoxby, C. M. and Metrick, A. (2013). A revealed
preference ranking of us colleges and universities. \emph{The Quarterly
Journal of Economics}, \textbf{128} 425- 467. Azari Soufiani, H., Chen,
W., Parkes, D. C. and Xia, L. (2013). Generalized method- of- moments
for rank aggregation. \emph{Advances in Neural Information Processing
Systems}, \textbf{26. Baltrunas, L., Makcinskas, T. and Ricci, F.
(2010). Group recommendations with rank aggregation and collaborative
filtering. In \emph{Proceedings of the fourth ACM conference on
Recommender systems}.Bennett, J., Lanning, S. et al.~(2007). The Netflix
Prize. In \emph{Proceedings of KDD cup and workshop}, vol.~2007. New
York.Caron, F., Teh, Y. W. and Murphy, T. B. (2014). Bayesian
nonparametric Plackett- Luce models for the analysis of preferences for
college degree programmes. \emph{The Annals of Applied Statistics},} 8**
1145- 1181. Chen, P., Gao, C. and Zhang, A. Y. (2022). Partial recovery
for top- \(K\) ranking: Optimality of mle and suboptimality of the
spectral method. \emph{The Annals of Statistics}, \textbf{50} 1618-
1652. Chen, X., Krishnamurthy, A. and Wang, Y. (2023). Robust dynamic
assortment optimization in the presence of outlier customers.
\emph{Operations Research}.Chen, X., Wang, Y. and Zhou, Y. (2020).
Dynamic assortment optimization with changing contextual information.
\emph{The Journal of Machine Learning Research}, \textbf{21} 8918- 8961.
Chen, Y., Fan, J., Ma, C. and Wang, K. (2019). Spectral method and
regularized mle are both optimal for top- \(K\) ranking. \emph{Annals of
statistics}, \textbf{47} 2204. Chen, Y. and Suh, C. (2015). Spectral
mle: Top- \(K\) rank aggregation from pairwise comparisons. In
\emph{International Conference on Machine Learning}. PMLR.Cheng, W.,
Dembzynski, K. and Hllermeier, E. (2010). Label ranking methods based
on the Plackett- Luce model. In \emph{ICML}.Chernozhukov, V.,
Chetverikov, D. and Kato, K. (2017). Central limit theorems and
bootstrap in high dimensions. \emph{The Annals of Probability},
\textbf{45} 2309- 2352. Chernozhukov, V., Chetverikov, D., Kato, K. and
Koike, Y. (2019). Improved central limit theorem and bootstrap
approximations in high dimensions. \emph{arXiv preprint
arXiv:1912.10529}.Davis, J. M., Gallego, G. and Topaloglu, H. (2014).
Assortment optimization under variants of the nested logit model.
\emph{Operations Research}, \textbf{62} 250- 273.

Dwork, C., Kumar, R., Naor, M. and Sivakumar, D. (2001). Rank
aggregation methods for the web. In Proceedings of the 10th
international conference on World Wide Web.Fan, J., Hou, J. and Yu, M.
(2022a). Uncertainty quantification of mle for entity ranking with
covariates. arXiv preprint arXiv:2212.09961. Fan, J., Lou, Z., Wang, W.
and Yu, M. (2022b). Ranking inferences based on the top choice of
multiway comparisons. arXiv preprint arXiv:2211.11957. Gallego, G. and
Topaloglu, H. (2014). Constrained assortment optimization for the nested
logit model. Management Science, 60 2583- 2601. Gao, C., Shen, Y. and
Zhang, A. Y. (2021). Uncertainty quantification in the Bradley- Terry-
Luce model. arXiv preprint arXiv:2110.03874. Guiver, J. and Snelson, E.
(2009). Bayesian inference for Plackett- Luce ranking models. In
proceedings of the 26th annual international conference on machine
learning.Hajek, B., Oh, S. and Xu, J. (2014). Minimax- optimal inference
from partial rankings. Advances in Neural Information Processing
Systems, 27. Han, R. and Xu, Y. (2023). A unified analysis of
likelihood- based estimators in the Plackett- Luce model. arXiv preprint
arXiv:2306.02821. Han, R., Ye, R., Tan, C. and Chen, K. (2020).
Asymptotic theory of sparse Bradley- Terry model. The Annals of Applied
Probability, 30 2491- 2515. Hunter, D. R. (2004). MM algorithms for
generalized Bradley- Terry models. The annals of statistics, 32 384-
406. Jang, M., Kim, S. and Suh, C. (2018). Top- \(K\) rank aggregation
from \(m\) - wise comparisons. IEEE Journal of Selected Topics in Signal
Processing, 12 989- 1004. Jang, M., Kim, S., Suh, C. and Oh, S. (2016).
Top- \(K\) ranking from pairwise comparisons: When spectral ranking is
optimal. arXiv preprint arXiv:1603.04153. Ji, P., Jin, J., Ke, Z. T. and
Li, W. (2022). Co- citation and co- authorship networks of
statisticians. Journal of Business \& Economic Statistics, 40 469- 485.
Ji, P., Jin, J., Ke, Z. T. and Li, W. (2023+). Meta- analysis on
citations for statisticians. To Appear.Johnson, V. E., Deaner, R. O. and
Van Schaik, C. P. (2002). Bayesian analysis of rank data with
application to primate intelligence experiments. Journal of the American
Statistical Association, 97 8- 17. Li, H., Simchi- Levi, D., Wu, M. X.
and Zhu, W. (2019). Estimating and exploiting the impact of photo
layout: A structural approach. Available at SSRN 3470877.

Li, W., Shrotriya, S. and Rinaldo, A. (2022). \(\ell_{\infty}\) - bounds
of the mle in the btl model under general comparison graphs. In
Uncertainty in Artificial Intelligence. PMLR.Liu, Y., Fang, E. X. and
Lu, J. (2022). Lagrangian inference for ranking problems. Operations
Research.Luce, R. D. (1959). Individual choice behavior: A theoretical
analysis. John Wiley \& Sons, Inc., New York; Chapman \& Hall, Ltd.,
London.Massey, K. (1997). Statistical models applied to the rating of
sports teams. Bluefield College, 1077. Mattei, N., Forshee, J. and
Goldsmith, J. (2012). An empirical study of voting rules and
manipulation with large datasets. Proceedings of COMSOC, 59. Mattei, N.
and Walsh, T. (2013). Preflib: A library for preferences
http://www.preflib.org. In International conference on algorithmic
decision theory. Springer.Maystre, L. and Grossglauser, M. (2015). Fast
and accurate inference of Plackett- Luce models. Advances in Neural
Information Processing Systems, 28. Negahban, S., Oh, S. and Shah, D.
(2012). Iterative ranking from pair- wise comparisons. Advances in
Neural Information Processing Systems, 25. Ouyang, L., Wu, J., Jiang,
X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S.,
Slama, K., Ray, A. et al.~(2022). Training language models to follow
instructions with human feedback. Advances in Neural Information
Processing Systems, 35 27730- 27744. Plackett, R. L. (1975). The
analysis of permutations. Journal of the Royal Statistical Society:
Series C (Applied Statistics), 24 193- 202. Portnoy, S. (1986). On the
central limit theorem in \(\mathbf{R}^p\) when \(p \to \infty\) .
Probab. Theory Related Fields, 73 571- 583. Rusmevichientong, P., Shen,
Z.- J. M. and Shmoys, D. B. (2010). Dynamic assortment optimization with
a multinomial logit choice model and capacity constraint. Operations
research, 58 1666- 1680. Rusmevichientong, P. and Topaloglu, H. (2012).
Robust assortment optimization in revenue management under the
multinomial logit choice model. Operations research, 60 865- 882. Shah,
N., Balakrishnan, S., Bradley, J., Parekh, A., Ramchandran, K. and
Wainwright, M. (2015). Estimation from pairwise comparisons: Sharp
minimax bounds with topology dependence. In Artificial intelligence and
statistics. PMLR.Shen, S., Chen, X., Fang, E. and Lu, J. (2023).
Combinatorial inference on the optimal assortment in multinomial logit
models. Available at SSRN 4371919.

Simons, G. and Yao, Y.- C. (1999). Asymptotics when the number of
parameters tends to infinity in the Bradley- Terry model for paired
comparisons. \emph{The Annals of Statistics}, \textbf{27} 1041--1060.
Sumida, M., Gallego, G., Rusmevichientong, P., Topaloglu, H. and Davis,
J. (2021). Revenue- utility tradeoff in assortment optimization under
the multinomial logit model with totally unimodular constraints.
\emph{Management Science}, \textbf{67} 2845--2869. Szrnyi, B., Busa-
Fekete, R., Paul, A. and Hllermeier, E. (2015). Online rank elicitation
for Plackett- Luce: A dueling bandits approach. \emph{Advances in Neural
Information Processing Systems}, \textbf{28}.Talluri, K. and Van Ryzin,
G. (2004). Revenue management under a general discrete choice model of
consumer behavior. \emph{Management Science}, \textbf{50} 15--33. Tropp,
J. A. (2012). User- friendly tail bounds for sums of random matrices.
\emph{Foundations of computational mathematics}, \textbf{12} 389--434.
Turner, H. and Firth, D. (2012). Bradley- Terry models in R: the
BradleyTerry2 package. \emph{Journal of Statistical Software},
\textbf{48} 1--21. Vulcano, G., Van Ryzin, G. and Ratliff, R. (2012).
Estimating primary demand for substitutable products from sales
transaction data. \emph{Operations Research}, \textbf{60} 313--334.
Wang, X., Bendersky, M., Metzler, D. and Najork, M. (2016). Learning to
rank with selection bias in personal search. In \emph{Proceedings of the
39th International ACM SIGIR conference on Research and Development in
Information Retrieval}.Zhang, H., Rusmevichientong, P. and Topaloglu, H.
(2020). Assortment optimization under the paired combinatorial logit
model. \emph{Operations Research}, \textbf{68} 741--761.



\end{document}

