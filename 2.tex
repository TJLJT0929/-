
\begin{document}

\section{3 Ranking Inference Methodology}\label{ranking-inference-methodology}

In this section, we study the inference methodology for the spectral estimator for the underlying scores \(\{\theta_{i}^{*}\}_{i\in [n]}\) of \(n\) items. To be specific, we need to establish the statistical convergence rates and asymptotic normality for \(\widetilde{\theta_{i}}\).

\section{3.1 Uncertainty quantification with fixed comparison graph}\label{uncertainty-quantification-with-fixed-comparison-graph}

For the estimation of \(\pi^{*}\), we use the following two approximations, which we will justify later to be accurate enough so as not to affect the asymptotic variance. Let us first focus on our intuition. Firstly, we have
\[
\widehat{\pi}_{i} = \frac{\sum_{j:j\neq i}P_{ji}\widehat{\pi}_{j}}{\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*}}{\sum_{j:j\neq i}P_{ij}} \eqqcolon \bar{\pi}_{i}.
\]
Equivalently,
\[
\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\approx \frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}(P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*})}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}.
\]
Secondly, the denominator above can be approximated by its expected value so that (3.1) can further be approximated as
\[
J_{i}^{*}\coloneqq \frac{\sum_{j:j\neq i}(P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}})}{\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}}}, \tag{3.2}
\]
by using \(\pi_{i}^{*}\propto e^{\theta_{i}^{*}}\). We will rigorously argue that the asymptotic distributions of \(\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and \(J_{i}^{*}\) are identical. For now, let us look at the asymptotic distribution of \(J_{i}^{*}\). Obviously, it is mean zero due to the detailed balance: \(E[P_{ji}|\mathcal{G}]\pi_{j}^{*} = E[P_{ij}|\mathcal{G}]\pi_{i}^{*}\). The denominator of \(J_{i}^{*}\) is a constant and can be explicitly written out as follows:
\[
\tau_{i}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}} = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(1 - \frac{e^{\theta_{i}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\right)\frac{e^{\theta_{i}^{*}}}{f(A_{l})}.
\]
Thus, \(J_{i}^{*}\) can be expressed as
\[
J_{i}^{*} = \frac{1}{d\tau_{i}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f(A_{l})}\left(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\right),
\]
where \(\tau_{i}\) is short for \(\tau_{i}(\theta^{*})\). Since each \((c_{l},A_{l})\) is independent in the fixed graph setting (see Remark 2.1 for discussions), the variance of \(J_{i}^{*}\) is
\[
\begin{array}{r l} & {\mathrm{Var}(J_{i}^{*}|\mathcal{G}) = \frac{1}{d^{2}\tau_{i}^{2}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f^{2}(A_{l})}\cdot \mathrm{Var}\bigg(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\bigg|\mathcal{G}\bigg).}
\end{array}
\]
A few important comments are in order. Firstly, the function \(f\) achieves the minimal variance in (3.5) when \(\begin{array}{r}{f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}} \end{array}\) due to simply applying the Cauchy-Schwarz inequality. Actually, Maystre and Grossglauser (2015) showed that when \(\begin{array}{r}f(A_l) = \sum_{u\in A_l}e^{\theta_u^*} \end{array}\), spectral method estimator converges to the MLE up to the first order. Secondly, under the situation of pairwise comparison in the BTL model, each \((c_l,A_l)\) is independent and we assume in \(\mathcal{D}\) each pair \((i,j)\) is either compared for \(L\) times (denoted as \(\widetilde{A}_{ij} = 1\)) or never compared (denoted as \(\widetilde{A}_{ij} = 0\)). Further assuming \(f(A_{l}) = |A_{l}| = 2\), we have
\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \frac{1}{L}\bigg(\sum_{j:j\neq i}\widetilde{A}_{ij}e^{\theta_i^*}e^{\theta_j^*}\bigg)\bigg / \bigg[\sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{(e^{\theta_i^*} + e^{\theta_j^*})}\bigg]^2.
\]
This exactly matches with Proposition 4.2 of Gao et al.~(2021). In addition, if we choose \(f(A_{l}) = \sum_{u\in A_l}e^{\theta_u^*}\), we get the most efficient variance just like the MLE variance given in Proposition 4.1 of Gao et al.~(2021), which is
\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \left(L\cdot \sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{(e^{\theta_i^*} + e^{\theta_j^*})^2}\right)^{-1}.
\]
With the above discussion and computation, after some additional derivations, we come to the conclusion that \(\widetilde{\theta}_{i} - \theta_{i}^{*}\) has the same asymptotic distribution as \(\frac{\widetilde{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and \(J_{i}^{*}\). Therefore,
\[
\operatorname {Var}(J_i^* |\mathcal{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]
for all \(i\in [n]\). Based on this result, we can make inference for \(\widetilde{\theta}_{i}\) and additionally the rank of item \(i\) (see Section 3.3). The rigorous derivations for this conclusion will be provided in Section 4.

\section{3.2 Uncertainty quantification for the PL model}\label{uncertainty-quantification-for-the-pl-model}

In this section, we consider the case of a random comparison graph, which could potentially lead to dependent \((c_l,A_l)\), unlike the case of the fixed graph in the previous section. Note that since the random comparison graph generation can be arbitrary, we cannot work with each case. As an illustrating example, we consider the classical PL model from the Erdos-Renyi graph here for two reasons. Firstly, this is the most popularly studied random comparison model in the ranking literature (Chen and Suh, 2015; Chen et al., 2022; Han et al., 2020; Liu et al., 2022; Gao et al., 2021; Fan et al., 2022a,b). Secondly, we can use the model to verify the uncertainty quantification of the spectral method and compare it with that of the MLE. It turns out the model is good enough to give us new insights. To further simplify the discussion and presentation, we will only focus on \(M = 3\) in the PL model. Results for general \(M\) can be similarly derived with the same conclusion.

With the PL model, we can write down the specific variance of \(J_{i}^{*}\). Consider the most natural way to encode a 3-way comparison. Say one ranks \((i,j,k)\) as \(i\vdash j\vdash k\) where \(a\vdash b\) means \(a\) is better than \(b\). Motivated by the likelihood function, which multiplies the probability of selecting \(i\) as the best one from \(\{i,j,k\}\) and the probability of selecting \(j\) next from \(\{j,k\}\), we break this complete 3-way comparison into two dependent comparison data: \((i,\{i,j,k\})\) and \((j,\{j,k\})\). We call this multi-level breaking, where in the first level comparison of all three items, \(i\) is preferred, and in the second level comparison of the remaining items, \(j\) is preferred. By doing this, we can naturally link and compare results with the MLE estimator. Azari Soufiani et al.~(2013) also proposed other ways of breaking an \(M\)-way comparison into pairwise comparisons, but different breaking methods will lead to different dependent structures, which we do not intend to analyze one by one in this work. So in the sequel, we only consider multi-way breaking, motivated by the likelihood function, and leave the study of other possible breaking methods to the future. We use \(\widetilde{A}_{ijk} = 1\) or \(0\) to denote whether \((i,j,k)\) has been compared for \(L\) times or is never compared.

Let us work on the multi-level breaking. Now the key difference is that the induced comparison graph \(\mathcal{G}\) cannot be treated as fixed. Instead, we condition on \(\widetilde{\mathcal{G}} = \{\widetilde{A}_{ijk}\}\). Similar to (3.2), we have
\[
\frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*}}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}}}{\sum_{j:j\neq i}E[P_{ij}|\widetilde{\mathcal{G}}]e^{\theta_{i}^{*}}}.
\]
In the case of the random comparison graph, i.e.~conditioning on \(\widetilde{\mathcal{G}}\), we obtain
\[
P_{ij} = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq i,j}\widetilde{A}_{ijk}Z_{ijk}^{\ell}, \tag{3.7}
\]
where \(Z_{ijk}^{\ell} = 1(y_{k\succ j \succ i}^{(\ell)} = 1) / f(\{i,j\}) + 1(y_{j\succ k \succ i}^{(\ell)} = 1) / f(\{i,j,k\}) + 1(y_{j\succ k\succ i}^{(\ell)} = 1) / f(\{i,j,k\})\). Here \(y_{i_1\succ i_2\succ i_3}^{(\ell)}\) is a binary variable which equals to \(1\) when the event \(i_1\succ i_2\succ i_3\) holds under the \(\ell\)-th comparison among items \(\{i_1,i_2,i_3\}\). Essentially, we need to collect all terms induced from the same comparison into one term \(Z_{ijk}^{\ell}\) so that the summation is always over independent terms.

We lightly abuse the notation of \(J_{i}^{*}\) although here the expectation is conditioning on \(\widetilde{\mathcal{G}}\) instead of \(\mathcal{G}\) used in the fixed graph case. Note that
\[
E[Z_{ijk}^{\ell}|\widetilde{\mathcal{G}} ] = \frac{e^{\theta_{k}^{*}}e^{\theta_{j}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}})f(\{i,j\})}+\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{k}^{*}})f(\{i,k\})}.
\]
Using \(\sum_{j\neq k}a_{ijk} = \sum_{j< k}(a_{ijk} + a_{ikj})\), the denominator of \(J_{i}^{*}\) can be expressed as
\[
\begin{array}{r l} & {\tau_{i}^{\diamond}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]e^{\theta_{i}^{*}} = \frac{L}{d}\sum_{j< k:j,k\neq i}\widetilde{A}_{i j k}e^{\theta_{i}^{*}}\bigg(\frac{e^{\theta_{j}^{*}}}{f(\{i,j\})} + \frac{e^{\theta_{k}^{*}}}{f(\{i,k\})}\bigg).}
\end{array}
\]
Hence, the expression of \(J_{i}^{*}\) is given as follows:
\[
\begin{array}{r l} & {J_{i}^{*} = \frac{1}{\tau_{i}^{\diamond}}\Big(\sum_{j:j\neq i}P_{j i}e^{\theta_{j}^{*}} - P_{i j}e^{\theta_{i}^{*}}\Big) = \frac{1}{d\tau_{i}^{\diamond}}\Big(\sum_{\ell = 1}^{L}\sum_{j< k:j,k\neq i}\widetilde{A}_{ijk}J_{ijk\ell}(\theta^{*})\Big),}
\end{array}
\]
where \(\tau_{i}^{\diamond}\) is short for \(\tau_{i}^{\diamond}(\theta^{*})\). Since each 3-way comparison is independent, it can be shown that the variance of \(J_{i}^{*}\) is
\[
\mathrm{Var}(J_{i}^{*}|\widetilde{\mathcal{G}}) = \frac{L}{d^{2}(\tau_{i}^{\diamond})^{2}}\sum_{j< k:j,k\neq i}\widetilde{A}_{ijk}e^{\theta_{i}^{*}}\Big(\frac{(e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})}{f^{2}(\{i,j,k\})}(e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}} + e^{\theta_{i}^{*}}) + \frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{f^{2}(\{j,k\})}\Big).
\]
The essential component is to compute \(E[J_{ijkl}(\theta^{*})^{2}]\) due to independence and zero-mean. For a given triplet \((i,j,k)\), there are 6 possible preference outcomes with probabilities governed by the PL model. Averaging the squared random outcomes over 6 probabilities gives \(E[J_{ijkl}(\theta^{*})^{2}]\), which results in the expression above. We omit the details of these calculations.

Let us consider the simple situation that all \(\theta_{i}^{*}\) are equal. In this case, if we apply the most efficient weighting function \(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\), that is, \(f(\{i,j,k\}) = 3\), \(f(\{i,j\}) = f(\{i,k\}) = 2\), we have \(\mathrm{Var}(J_i^* |\widetilde{G}) = 18 / (7L)\). However, if we naively choose \(f\) as a constant function, we get \(\mathrm{Var}(J_i^* |\widetilde{G}) = 8 / (3L)\), which is indeed larger. It is also worth noting that when we choose \(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\), the aforementioned variance matches with the variance of MLE in Fan et al.~(2022b).

With the above formula of \(\mathrm{Var}(J_i^* |\widetilde{G})\) for the PL model, we can also conclude that
\[
\mathrm{Var}(J_i^* |\widetilde{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]
for all \(i\in [n]\). The rigorous arguments will be introduced in Section 4.

\section{3.3 Ranking inference: one-sample confidence intervals}\label{ranking-inference-one-sample-confidence-intervals}

In numerous practical applications, individuals frequently interact with data and challenges related to rankings. The prevalent approach to utilizing rankings typically revolves around computing preference scores and then showcasing these scores in ranked order. These only provide first-order information on ranks and can not answer many questions, such as: How do we ascertain with high confidence that an item's true rank is among the top-3 (or general \(K,K\geq 1\)) choices? And how can we establish a set of candidates with high confidence, guaranteeing that the true top-3 candidates are not overlooked? How do we analyze if the ranking preferences for a given array of products are consistent in two distinct communities (such as male and female) or the same community but at two different time periods? In sum, there is a need for tools and methodologies that address these and other insightful queries in real-world applications involving rankings, especially when the comparisons are drawn from a general comparison graph.

Within this section, we first present a comprehensive framework designed for the construction of two-sided confidence intervals for ranks. In endeavoring to establish simultaneous confidence intervals for the ranks, an intuitive methodology entails deducing the asymptotic distribution of the empirical ranks, denoted as \(\widetilde{r}_{m},m\in \mathcal{M}\), and subsequently determining the critical value. However, it is well known that this task poses substantive challenges, given that \(\widetilde{r}_{m}\) is an integer and is intrinsically dependent on all estimated scores, making its asymptotic behavior daunting to analyze.

By capitalizing on the inherent interdependence between the scores and their corresponding ranks, we discern that the task of formulating confidence intervals for the ranks can be effectively converted to the construction of simultaneous confidence intervals for the pairwise differences among the population scores. It is notable that the distribution of these empirical score differences is more amenable to characterization. Consequently, we focus on the statistical properties of the estimated scores \(\widetilde{\theta}_{m} \in [n]\) and present our methodology for constructing two-sided (simultaneous) confidence intervals for ranks through estimated score differences.

Example 3.1. We let \(\mathcal{M} = \{m\}\), where \(1 \leq m \leq n\), to represent the item under consideration. We are interested in the construction of the \((1 - \alpha) \times 100\%\) confidence interval for the true population rank \(r_{m}\), where \(\alpha \in (0,1)\) denotes a pre-specified significance level. Suppose that we are able to construct the simultaneous confidence intervals \([\mathcal{C}_L(k,m), \mathcal{C}_U(k,m)], k \neq m, (k \in [n])\) for the pairwise differences \(\theta_{k}^{*} - \theta_{m}^{*}, k \neq m (k \in [n])\), with the following property:
\[
\mathbb{P}\Big(\mathcal{C}_L(k,m) \leq \theta_k^* - \theta_m^* \leq \mathcal{C}_U(k,m) \text{for all} k \neq m\Big) \geq 1 - \alpha . \tag{3.9}
\]
One observes that if \(\mathcal{C}_U(k,m) < 0\) (respectively, \(\mathcal{C}_L(k,m) > 0\)), it implies that \(\theta_k^* < \theta_m^*\) (respectively, \(\theta_k^* > \theta_m^*\)). Enumerating the number of items whose scores are higher than item \(m\) gives a lower bound for rank \(r_{m}\), and vice versa. In other words, we deduce from (3.9) that
\[
\mathbb{P}\left(1 + \sum_{k \neq m} 1 \{C_L(k,m) > 0\} \leq r_m \leq n - \sum_{k \neq m} 1 \{C_U(k,m) < 0\}\right) \geq 1 - \alpha . \tag{3.10}
\]
This yields a \((1 - \alpha) \times 100\%\) confidence interval for \(r_{m}\), and our task reduces to construct simultaneous confidence intervals for the pairwise differences (3.9).

We now formally introduce the procedure to construct the confidence intervals for multiple ranks \(\{r_m\}_{m \in \mathcal{M}}\) simultaneously. Motivated by Example 3.1, the key step is to construct the simultaneous confidence intervals for the pairwise score differences \(\{\theta_k^* - \theta_m^*\}_{m \in \mathcal{M}, k \neq m}\) such that (3.9) holds. To this end, we let
\[
T_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{\widetilde{\theta}_k - \widetilde{\theta}_m - (\theta_k^* - \theta_m^*)}{\widetilde{\sigma}_{km}} \right|, \tag{3.11}
\]
where \(\{\widetilde{\sigma}_{km}\}_{k \neq m}\) is a sequence of positive normalization given by (3.13) below. For any \(\alpha \in (0,1)\), let \(Q_{1 - \alpha}\) be critical value such that \(\mathbb{P}(T_{\mathcal{M}} \leq Q_{1 - \alpha}) \geq 1 - \alpha\). Then, as in Example 3.1, our \((1 - \alpha) \times 100\%\) simultaneous confidence intervals for \(\{r_m\}_{m \in \mathcal{M}}\) are given by \(\{[R_{mL}, R_{mU}] \}_{m \in \mathcal{M}}\), where
\[
R_{mL} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m > \widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right), \quad R_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m < -\widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right).
\]

\section{3.4 Multiplier bootstrap procedure}\label{multiplier-bootstrap-procedure}

The key step for constructing the confidence interval of ranks of interest is to pick the critical value \(Q_{1 - \alpha}\). To calculate the critical value above, we propose to use the wild bootstrap procedure. The uncertainty quantification for the spectral estimator in (3.2) reveals that \(\widetilde{\theta_{i}} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\) uniformly over \(i \in [n]\) (see details in Section 4), which further implies that asymptotically
\[
T_{\mathcal{M}} \approx \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{J_{k}(\theta^{*}) - J_{m}(\theta^{*})}{\widetilde{\sigma}_{km}} \right|. \tag{3.12}
\]
We focus on the fixed graph setting and leave the random graph setting in Remark 3.2 below. Practically, the empirical version of \(J_{i}(\theta^{*})\) can be obtained via plugging in the spectral estimator \(\widetilde{\theta}\), namely from (3.4),
\[
J_{i}(\widetilde{\theta}) = \frac{1}{d} \sum_{l \in \mathcal{D}} J_{il}(\widetilde{\theta}), \quad i \in [n].
\]
Let \(\sigma_{km}^{2} = \operatorname {Var}\{J_{k}(\theta^{*}) - J_{m}(\theta^{*}) | \mathcal{G} \}\) for each \(k \neq m\). Then our estimator for \(\sigma_{km}^{2}\) is defined by
\[
\widetilde{\sigma}_{km}^{2} = \frac{e^{\widetilde{\theta}_{k}}}{d^{2} \tau_{k}^{2}(\widetilde{\theta})} \sum_{l \in \mathcal{D}} \frac{1(k \in A_{l})}{f^{2}(A_{l})} \left(\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}} - e^{\widetilde{\theta}_{k}}\right) \frac{e^{\widetilde{\theta}_{k}}}{\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}}} + \dots
\]
where \(\tau_{k}(\widetilde{\theta})\) and \(\tau_{m}(\widetilde{\theta})\) also plug in \(\widetilde{\theta}\); see (3.5). Let \(\omega_{1}, \ldots , \omega_{|\mathcal{D}|} \in \mathbb{R}\) be i.i.d. \(N(0,1)\) random variables. The Gaussian multiplier bootstrap statistic is then defined by
\[
G_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l} \right|. \tag{3.14}
\]
Let \(\mathbb{P}^{*}(\cdot) = \mathbb{P}(\cdot | \{(c_{i}, A_{i})\}_{i \in \mathcal{D}})\) denote the conditional probability. Then, for \(\alpha \in (0,1)\), our estimator for \(Q_{1 - \alpha}\) is defined by the \((1 - \alpha)\)th conditional quantile of \(G_{\mathcal{M}}\), namely
\[
\mathcal{Q}_{1 - \alpha} = \inf \{z: \mathbb{P}^{*}(G_{\mathcal{M}} \leq z) \geq 1 - \alpha \} ,
\]
which can be computed by the Monte Carlo simulation. Then, our simultaneous confidence intervals \(\{[\mathcal{R}_{mL}, \mathcal{R}_{mU}] \}_{m \in \mathcal{M}}\) are given by
\[
\mathcal{R}_{mL} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right), \qquad \mathcal{R}_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} < -\widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right).
\]

Remark 3.1 (One-sample one-sided confidence intervals). Now we provide details on constructing simultaneous one-sided intervals for population ranks. For one-sided intervals, the overall procedure is similar to constructing two-sided confidence intervals. Specifically, let
\[
G_{\mathcal{M}}^{\circ} = \max_{m \in \mathcal{M}} \max_{k \neq m} \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l}, \tag{3.16}
\]
where \(\omega_{1}, \ldots , \omega_{|\mathcal{D}|}\) are as before i.i.d. \(N(0,1)\) random variables. Correspondingly, let \(\mathcal{Q}_{1 - \alpha}^{\circ}\) be its \((1 - \alpha)\)th quantile. Then the \((1 - \alpha) \times 100\%\) simultaneous lower confidence bounds for \(\{r_{m}\}_{m \in \mathcal{M}}\) are given by \(\{[\mathcal{R}_{mL}^{ \circ }, n] \}_{m \in \mathcal{M}}\), where
\[
\mathcal{R}_{mL}^{\circ} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}^{\circ}\right). \tag{3.17}
\]

Remark 3.2 (Ranking inference for the PL model with random comparison graph). Section 3.2 reveals that \(\widetilde{\theta}_{i} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\) uniformly over \(i \in [n]\), where following (3.8),
\[
J_{i}(\theta^{*}) = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{j < s:j, s \neq i} J_{ijs\ell}(\theta^{*}).
\]
In order to carry out ranking inference for the PL model, we need to rewrite this equation in a slightly different format. Let \(\begin{array}{r}{\mathcal{N} = \sum_{i< j< k}\widetilde{A}_{i j k}} \end{array}\) denote the total number of connected components on the random graph \(\widetilde{G}\) and write \(\{(i,j,k):i< j< k\) and \(\widetilde{A}_{i j k} = 1\} \eqqcolon \{\widetilde{A}_{q}\}_{q = 1,\ldots ,\mathcal{N}}\). Let \(y_{q}^{(\ell)}\) denote the \(\ell\)-th full-ranking comparison result for \(A_{q}\). Then we can rewrite \(P_{ij}\) as
\[
P_{ij} = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \sum_{k \neq i, j} 1\{(i,j,k) = \widetilde{A}_{q}\} Z_{ijkq}^{(\ell)}, i \neq j,
\]
where for \(i\neq j\neq k\) and \(q\in \lfloor \mathcal{N}\rfloor\), and \(Z_{i j k q}^{(\ell)} = 1\{y_{q}^{(\ell)} = (k\succ j \succ i)\} /f(\{i,j\}) + (1\{y_{q}^{(\ell)} = (j\succ i \succ k)\} /f(\{i,j,k\})) +1\{y_{q}^{(\ell)} = (j\succ k \succ i)\} /f(\{i,j,k\})\). It is straightforward to verify that this \(P_{ij}\) is exactly the same with (3.7). Therefore, we rewrite \(\begin{array}{r}{J_{i}(\theta^{*}) = d^{- 1}\sum_{\ell = 1}^{L}\sum_{q = 1}^{N}J_{i q\ell}^{\diamond}(\theta^{*})} \end{array}\), where
\[
J_{iq\ell}^{\diamond}(\theta^{*}) = \sum_{j < s:j, s \neq i} 1\{(i,j,s) = \widetilde{A}_{q}\} J_{iq\ell}^{\diamond}(\theta^{*}). \tag{3.18}
\]
As is assumed, \(\{J_{iq\ell}^{\diamond}(\theta^{*})\}_{\ell \in [L], q \in [\mathcal{N}]}\) are independent for each \(i \in [n]\) conditioning on the comparison graph \(\widetilde{G}\). Let \(\{\omega_{q\ell}^{\diamond}\}_{q, \ell \in \mathbb{N}}\) be i.i.d. \(N(0,1)\) random variables. Then, following (3.14), the corresponding bootstrap test statistic is given by
\[
G_{\mathcal{M}}^{\diamond} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}^{\diamond}} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \{J_{kq\ell}^{\diamond}(\widetilde{\theta}) - J_{mq\ell}^{\diamond}(\widetilde{\theta})\} \omega_{q\ell}^{\diamond} \right|,
\]
where \(\{\widetilde{\sigma}_{km}^{\diamond}\}_{k \neq m}\) are as before the sequence of positive normalization, calculated as the sum of the variance of \(J_{k}(\theta^{*})\) and \(J_{m}(\theta^{*})\) similar to (3.13). Consequently, the simultaneous confidence intervals for the ranks can be similarly constructed.

\section{3.5 Ranking inference: two-sample and one-sample testing applications}\label{ranking-inference-two-sample-and-one-sample-testing-applications}

In this section, we further illustrate how we may apply our inference methodology to a few salient testing applications, in both one-sample and two-sample testing.

Example 3.2 (Testing top-\(K\) placement). Let \(\mathcal{M} = \{m\}\) for some \(m \in [n]\) and let \(K \geq 1\) be a prescribed positive integer. Our objective is to ascertain if the item \(m\) is a member of the top-\(K\) ranked items. Consequently, we shall examine the following hypotheses:
\[
H_{0}:r_{m}\leq K\mathrm{~versus~}H_{1}:r_{m} > K. \tag{3.19}
\]
Based on the one-sided confidence interval \([\mathcal{R}_{mL}^{\circ}, n]\) in (3.17), for any \(\alpha \in (0,1)\), a level \(\alpha\) test for (3.19) is simply given by \(\phi_{m,K} = 1\{\mathcal{R}_{mL}^{\circ} > K\}\). Under the conditions of Theorem E.1, we have \(\mathbb{P}(\phi_{m,K} = 1|H_{0}) \leq \alpha + \mathrm{o}(1)\), that is, the effective control of the Type-I error can be achieved below the significant level \(\alpha\) when the null hypothesis is true.

Example 3.3 (Top-\(K\) sure screening set). Another example is on constructing a screened candidate set that contains the top-\(K\) items with high probability. This is particularly useful in college candidate admission or company hiring decisions. Oftentimes, a university or a company would like to design certain admission or hiring policy with the high-probability guarantee of the sure screening of true top-\(K\) candidates.
Let \(\mathcal{K} = \{r^{- 1}(1),\ldots ,r^{- 1}(K)\}\) denote the top-\(K\) ranked items of the rank operator \(r:[n]\to [n]\). We aim at selecting a set of candidates \(\widehat{\mathcal{I}}_K\) which contains the top-\(K\) candidates with a prescribed probability. Mathematically, this requirement can be expressed as \(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\), where \(\alpha \in (0,1)\). Herein, we define \(\mathcal{M} = [n]\), and let \(\{[\mathcal{R}_{mL}^{\circ},n],m\in [n]\}\) represent the set of \((1 - \alpha)\times 100\%\) simultaneous left-sided confidence intervals, as given in (3.17). It is easy to observe that the inequality \(\mathcal{R}_{mL}^{\circ} > K\) infers that \(r_m > K\). Consequently, a selection for \(\widehat{\mathcal{I}}_K\), that satisfies the probability constraint \(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\), is given by
\[
\widehat{\mathcal{I}}_K = \{m\in [n]:\mathcal{R}_{mL}^{\circ}\leq K\} .
\]

Example 3.4 (Testing ranks of two samples). In many applications, we are concerned with the question of whether the ranks of certain items using two samples have been changed or preserved. For example, we may care about whether
\begin{itemize}
\tightlist
\item
  Ranking allocation differs before and after a treatment or policy change.
\item
  Different communities such as males versus females can have different ranking preferences over the same set of products.
\item
  People's perceived preferences over the same things have changed in two time periods.
\end{itemize}
Suppose we observe two independent datasets \(\mathcal{D}_1\) and \(\mathcal{D}_2\) with preference scores \(\theta_{[1]}^{*} = (\theta_{11}^{*},\ldots ,\theta_{1n}^{*})^{\top}\) and \(\theta_{[2]}^{*} = (\theta_{21}^{*},\ldots ,\theta_{2n}^{*})^{\top}\). The associated true rankings are respectively denoted by
\[
r_{[1]} = (r_{11},\ldots ,r_{1n})^{\top} \text{and} r_{[2]} = (r_{21},\ldots ,r_{2n})^{\top}.
\]
Given any \(m\in [n]\), we are interested in testing whether the same rank is preserved for item \(m\) across these two samples, that is, testing the hypotheses
\[
H_{0}:r_{1m} = r_{2m} \text{versus} H_{1}:r_{1m}\neq r_{2m} \tag{3.20}
\]
To this end, firstly we construct simultaneous confidence intervals \([R_{1mL},R_{1mU}]\) and \([R_{2mL},R_{2mU}]\) such that
\[
\mathbb{P}(r_{1m}\in [R_{1mL},R_{1mU}]\text{and} r_{2m}\in [R_{2mL},R_{2mU}])\geq 1 - \alpha . \tag{3.21}
\]
Then our \(\alpha\)-level test for (3.20) is defined by
\[
\phi_{m} = 1\{|[R_{1mL},R_{1mU}]\cap [R_{2mL},R_{2mU}]| = 0\} .
\]
It is straightforward to verify that \(\mathbb{P}(\phi_{m} = 1|H_{0})\geq 1 - \alpha\).

Example 3.5 (Testing top-\(K\) sets of two samples). Besides testing for a single or a few ranks, one may want to evaluate whether two top-\(K\) sets are identical or not, between two groups of people, two periods of time, or before and after a significant event or change. Let \(\mathcal{S}_{1K} = \{r_{[1]}^{- 1}(1),\ldots ,r_{[1]}^{- 1}(K)\}\) and \(\mathcal{S}_{2K} = \{r_{[2]}^{- 1}(1),\ldots ,r_{[2]}^{- 1}(K)\}\) denote the sets of top-\(K\) ranked items, respectively. We consider testing the hypotheses
\[
H_{0}:S_{1K} = S_{2K}\mathrm{~versus~}H_{1}:S_{1K}\neq S_{2K}. \tag{3.22}
\]
For \(\alpha \in (0,1)\), we begin with constructing \((1 - \alpha)\times 100\%\) simultaneous confidence sets \(\widehat{\mathcal{I}}_{1K}\) and \(\widehat{\mathcal{I}}_{2K}\) for \(S_{1K}\) and \(S_{2K}\) such that
\[
\mathbb{P}\left(S_{1K}\subset \widehat{\mathcal{I}}_{1K}\mathrm{~and~}S_{2K}\subset \widehat{\mathcal{I}}_{2K}\right)\geq 1 - \alpha . \tag{3.23}
\]
Then our \(\alpha\)-level test for (3.22) is defined by
\[
\widetilde{\phi}_{K} = 1\{|\widehat{\mathcal{I}}_{1K}\cap \widehat{\mathcal{I}}_{2K}|< K\} .
\]

Remark 3.3. Several methodologies, including the Bonferroni adjustment (which constructs a \((1 - \alpha /2)\times 100\%\) confidence interval for each source), and Gaussian approximation (achieved by taking the maximum of the test statistics of each source), enable us to establish simultaneous confidence intervals as illustrated in equations (3.21) and (3.23). To maintain clarity and simplicity in the subsequent context, we simply employ the Bonferroni adjustment for two samples. Moreover, the framework outlined in Examples 3.4 and 3.5 can be extended in a straightforward way to evaluate whether the ranks of items or sets are identical across three or more sources.

\section{4 Theoretical Justifications}\label{theoretical-justifications}

In this section, we rigorously justify the conclusions in Section 3 and explicitly lay out the necessary assumptions to arrive at those conclusions. The first assumption is to make sure we are comparing \(\theta_{i}^{*}\)'s in the same order in a meaningful way. Otherwise, we can always group items into categories with similar qualities and then work on each sub-group or screen some extreme items. In addition, as we have discussed, we need an identifiability condition for \(\theta^{*}\).

Assumption 4.1. There exists some positive constant \(\bar{\kappa} < \infty\) such that
\[
\max_{i\in [n]}\theta_{i}^{*} - \min_{i\in [n]}\theta_{i}^{*}\leq \bar{\kappa}.
\]
In addition, for identifiability, assume \(1^{\top}\theta^{*} = 0\).

In Assumption 4.1, we assume \(\bar{\kappa}\) is finite, indicating we only rank items with preference scores on the same scale. If \(\bar{\kappa}\) is diverging, some items will be trivially more or less favorable than others. In this case, it is typically easy in practice to separate the items into subgroups with similar preference scores, and then we can conduct ranking inference within each group. Although we assume bounded \(\bar{\kappa}\), it serves as the role of a condition number whose effect has been made explicit in all our results for interested readers. However, we do not claim this dependency is optimal as our nontrivial analysis can easily encounter powers of \(e^{\bar{\kappa}}\), say in bounding the ratio of \(\pi_{i}^{*} / \pi_{j}^{*}\).

\section{4.1 Estimation accuracy and asymptotic normality with fixed comparisons}\label{estimation-accuracy-and-asymptotic-normality-with-fixed-comparisons}

To derive the asymptotic distribution of the spectral estimator, we need to rigorously justify the approximations (3.1) and (3.2). We first take care of approximating (3.1) using (3.2), where all comparisons in \(\mathcal{G}\) are assumed to be fixed. Note that
\[
P_{ij} - E[P_{ij}|\mathcal{G}] = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_l)\left[1(c_l = j) - \frac{\pi_j^*}{\sum_{u\in A_l}\pi_u^*}\right]\frac{1}{f(A_l)}.
\]
Let \(Z_{A_l}^j = 1(c_l = j) / f(A_l)\), which is bounded from above and below as long as \(f\) is bounded from above and below. Furthermore, each \(Z_{A_l}^j\) is independent. Therefore, \(P_{ij} - E[P_{ij}|\mathcal{G}] = d^{- 1}\sum_{l\in \mathcal{D}}1(i,j\in A_l)[Z_{A_l}^j - E(Z_{A_l}^j)]\). By Hoeffding's inequality, conditioning on \(\mathcal{G}\), we have with a large probability \(1 - o(1)\),
\[
\max_{i\neq j}\left|P_{ij} - E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\ddagger}}.
\]
where \(\begin{array}{r}{n^{\ddagger} = \max_{i\neq j}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})} \end{array}\) is the maximum number of cases that each pair is compared. Similarly, we can get the concentration bound for \(\sum_{j:j\neq i}P_{ij}\). Since \(Z_{A_{l}}^{j}\)'s are independent, another level of summation over \(j\) will lead to the following. Again by Hoeffding's inequality, with a large probability tending to 1, we obtain
\[
\max_{i}\left|\sum_{j:j\neq i}P_{ij} - \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\dagger}},
\]
where \(\begin{array}{r}{n^{\dagger} = \max_{i}\sum_{l\in \mathcal{D}}1(i\in A_{l})} \end{array}\) is the maximum number of cases that each item is compared. In addition, we assume
\[
\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}] = \tau_{i}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger},
\]
where \(\tau_{i}\) defined in (3.3) is the denominator of \(J_{i}^{*}\). This assumption makes sense as \(\tau_{i}e^{- \theta_{i}^{*}}\lesssim \sum_{l\in \mathcal{D}}1(i\in A_{l}) / d\), and it states for each \(i\) the comparison graph cannot be too asymmetric. Note that \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) can still be widely different from \(n^{\ddagger}\) for different pair \((i,j)\). Since the expectation term dominates the deviation if \(n^{\dagger}\gtrsim \log n\), it is not hard to show that in (3.2), changing the denominator by its expectation will only cause a small order difference, which does not affect the asymptotic distribution.

Based on the above discussion, we impose the following assumption.

Assumption 4.2. In the case of a fixed comparison graph, we assume the graph is connected, \(\tau_{i}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all \(i\in [n]\), \(e^{2\bar{\kappa}}\log n = o(n)\) and \(e^{3\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^{1 / 2} = o(n^{\dagger})\).

The assumption is reasonable for a fixed comparison graph. If each pair \((i,j)\) must be compared at least once, then every \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\geq 1\). If they are all in the same order, then \(\sum_{l\in \mathcal{D}}1(i\in A_{l}) = \sum_{j:j\neq i}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) should be indeed in the order of \(n^{\ddagger}n\). Assumption 4.2 allows some pair \((i,j)\) to be never compared directly, so we need to leverage the information from comparing \(i\) and \(j\) to other items separately. Moreover, we also do not require \(\sum_{l\in \mathcal{D}}1(i,j\in A_l)\) to be in the same order for any \(i,j:i\neq j\) since we only require the maximum pairwise degree \(n^{\ddagger}\) to satisfy Assumption 4.2. However, in the case of a fixed graph, we do not have the randomness from the graph, and the graph must be relatively dense to make sure we have enough information to rank every item. This condition will be relaxed to \(n^{\dagger}\gtrsim n^{\ddagger}\log n\) when we have a homogeneous random comparison graph in Section 4.2.

We need another technical condition on the structure of the comparison graph. Define \(\Omega = \{\Omega_{ij}\}_{i\leq n,j\leq n}\) where \(\Omega_{ij} = - P_{ji}\pi_j^*\) for \(i\neq j\) and \(\Omega_{ii} = \sum_{j:j\neq i}P_{ij}\pi_i^*\). Note that as we derived above, \(E[\Omega_{ii}|\mathcal{G}]\) is in the order of \(n^{\dagger} / (dn)\). We hope to understand the order of its eigenvalues. Since \(\Omega\) has the minimal eigenvalue equal to zero, with the corresponding eigenvector \(\mathbf{1}\), we only focus on the space orthogonal to \(\mathbf{1}\). Following the notation of Gao et al.~(2021),
\[
\lambda_{\min ,\bot}(A) = \min_{\| v\| = 1,v^{\top}\mathbf{1} = 0}v^{\top}A v.
\]
Assumption 4.3. There exist \(C_1,C_2 > 0\) such that
\[
C_1e^{-\bar{\kappa}}\frac{n^\dagger}{dn}\leq \lambda_{\min ,\bot}(E[\Omega |\mathcal{G}])\leq \lambda_{\max}(E[\Omega |\mathcal{G}])\leq C_2e^{\bar{\kappa}}\frac{n^\dagger}{dn}, \tag{4.1}
\]
\[
\| \Omega -E[\Omega |\mathcal{G}]\| = o_{P}\left(\frac{n^{\dagger}}{dn}\right). \tag{4.2}
\]
When \(\bar{\kappa} = O(1)\), Assumption 4.3 requires that all eigenvalues (except the minimal one) of \(E[\Omega |\mathcal{G}]\) are in the order of \(n^{\dagger} / (dn)\) and \(\Omega\) also shares this same eigenvalue scale as \(E[\Omega |\mathcal{G}]\). This assumption is intuitively correct, as we have seen that \(E[\Omega_{ij}]\lesssim n^{\ddagger} / (dn)\) for \(i\neq j\) and \(E[\Omega_{ii}]\asymp n^{\dagger} / (dn)\). We will also rigorously show that this condition can be satisfied if we consider the PL model (Theorem 4.3).

Theorem 4.1. Under Assumptions 4.1-4.3, the spectral estimator \(\widetilde{\theta_{i}}\) has the following uniform approximation: \(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + \delta_{i}\), uniformly for all \(i\in [n]\), where \(\| \delta \coloneqq (\delta_{1},\dots ,\delta_{n})\|_{\infty} = o(1 / \sqrt{n^{\dagger}})\) with probability \(1 - o(1)\).

To prove Theorem 4.1, we need to verify (3.1). We leave the detailed proof in the appendix. Given Theorem 4.1, we can easily conclude the next theorem following the properties of \(J_{i}^{*}\), which lead to the rate of convergence for \(\widetilde{\theta}\) as well as its asymptotic normality.

Remark 4.1. The results of Theorem 4.1 and the following Theorems are proved via Bernstein and Hoeffding type inequalities with union bound over \(n\) items. Therefore, all of the high-probability terms hold with probability \((1 - o(1))\) (similarly for \(o_{p}(\cdot)\) and \(O_{p}(\cdot)\)) mentioned in the main text equivalently hold with probability in form of \(1 - O(n^{- \zeta})\) where \(\zeta \geq 2\) is a positive integer (different choice of \(\zeta\) will only affect constant terms in the involved concentration inequalities).

Theorem 4.2. Under Assumptions 4.1-4.3, the spectral estimator (2.1) satisfies that
\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\asymp \| J^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{n^{\dagger}}}, \tag{4.3}
\]
with probability \(1 - o(1)\), where \(J^{*} = (J_{1}^{*},\dots ,J_{n}^{*})\) with \(J_{i}^{*},i\in [n]\) being defined in (3.4). In addition,
\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]
for all \(i\in [n]\) with
\[
\rho_{i}(\theta) = \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{\sum_{u\in A_{l}}e^{\theta_{u}}}\right)\frac{e^{\theta_{i}}}{f^{2}(A_{l})}\right]^{-1/2},
\]
for both \(\theta = \theta^{*}\) and \(\theta =\) any consistent estimator of \(\theta^{*}\).

Note that Theorem 4.2 indicates that the choice of \(f(\cdot) > 0\) does not affect the rate of convergence, but it affects the estimation efficiency. As we argued in Section 3.1, the optimal weighting to minimize the asymptotic variance is \(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) in the class of spectral estimators. In practice, however, we do not know \(\theta_{u}^{*}\) beforehand. Therefore, we could implement a two-step procedure to improve the efficiency of the spectral estimator: in the first step, we obtain our initial consistent estimator \(\widehat{\theta_{u}^{(\mathrm{initial})}}\) with weighting say \(f(A_{l}) = |A_{l}|\), and in the second step, we estimate \(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) by plugging \(\widehat{\theta_{u}^{(\mathrm{initial})}}\) and run the spectral method again with this optimal weighting to get the final asymptotically efficient estimator \(\widehat{\theta_{u}^{(\mathrm{final})}}\). Note that we do not intend to prove the theoretical properties of this two-step estimator, as the data dependency in the optional weighting of the second step makes the uniform approximation analysis highly nontrivial due to non-i.i.d. ranking outcomes. Nonetheless, we could circumvent this theoretical difficulty by splitting data into a very small part \((o(|\mathcal{D}|)\) samples) for step 1, to achieve consistency with a worse convergence rate, and using the remaining majority \((|\mathcal{D}| - o(|\mathcal{D}|)\) samples) for step 2, to maintain the same asymptotic behavior. In addition, empirically, we found that directly using the same whole data in both steps achieves decent performance given a large sample size. We refer interested readers to our numerical studies.

\section{4.2 Estimation accuracy and asymptotic normality for the PL model}\label{estimation-accuracy-and-asymptotic-normality-for-the-pl-model}

In the random graph case, we have to specify the graph generation process in order to study the theoretical properties. We consider the commonly used PL model, where we sample each \(M\)-way comparison with probability \(p\) and compare this set for \(L\) times. Furthermore, we will only work with \(M = 3\) since we plan to focus on a transparent and intuitive discussion. We can easily generalize all the discussions to general \(M\), but derivations and formulas can be more tedious.

The PL model with 3-way comparisons has been studied in Fan et al.~(2022b) by using MLE, where they explicitly write down the likelihood function. The proposed spectral method can work for any fixed graph, including the one generated from the PL model. In this section, we would like to compare the performance of the spectral method with that of the MLE. To make sure the spectral method works for the PL model, we need to prove the approximations (3.1) and (3.6).

We first take care of (3.6). Consider conditioning on \(\widetilde{\mathcal{G}}\), where all comparisons in \(\widetilde{\mathcal{G}}\) are independent; each \(\widetilde{A}_{ijk}\) is compared for \(L\) times if \(\widetilde{A}_{ijk} = 1\). Now \(c_{l}\) and \(A_{l}\) are induced from \(\widetilde{\mathcal{G}}\), and can be dependent. In this case, we can write
\[
P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}} ] = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq j,i}\widetilde{A}_{ijk}[Z_{ijk}^{l} - EZ_{ijk}^{l}],
\]
where \(Z_{ijk}^{l} = 1(A_{l} = \{i,j\} ,c_{l} = j) / f(\{i,j\}) + 1(A_{l} = \{i,j,k\} ,c_{l} = j) / f(\{i,j,k\})\), which is again bounded from above and below and independent for any given \(\widetilde{A}_{ijk}\). In this case, with a little abuse of notations, we redefine
\[
n^{\dagger} = L\max_{i\neq j}\sum_{k:k\neq j,i}A_{ijk},\quad n^{\dagger} = L\max_{i}\sum_{j< k:j,k\neq i}A_{ijk}.
\]
Similar to Section 4.1, conditional on \(\widetilde{G}\), we have
\[
\begin{array}{r l} & {\max_{i}\bigg|\sum_{j:j\neq i}P_{i j} - \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\dagger}\log n}),}\\ & {\max_{i\neq j}\bigg|P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}}]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\ddagger}\log n}).}
\end{array}
\]
We adapt Assumption 4.2 to the following assumption. Note that we have no assumption on \(L\), so \(L\) can be as low as 1.

Assumption 4.4. In the PL model with \(M\)-way complete comparisons, choose \(d\asymp n^{\dagger}\) in the spectral ranking, and assume \(\tau_{i}^{\diamond}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all \(i\in [n]\), \(e^{4\bar{\kappa}} = o(n)\) and \(p\gtrsim e^{6\bar{\kappa}}\mathrm{poly}(\log n) / \binom{n- 1}{M- 1}\).

Under Assumption 4.4, we can prove
\[
n^{\dagger}\asymp \binom{n-1}{M-1}p L,\qquad\max \Big\{\binom{n-2}{M-2}p-\log n,0\Big\}L\lesssim n^{\ddagger}\lesssim\Big[\binom{n-2}{M-2}p+\log n\Big]L,
\]
with probability \(1 - o(1)\). Note that in \(n^{\dagger}\), by Assumption 4.4, we know the dominating term is \(\binom{n- 1}{M- 1}p L\). However, in \(n^{\ddagger}\), we have the additional term \(\log n\), which comes from the sub-exponential tail decay in Bernstein inequality, and if \(p\) is really small, it could happen that \(\log n\) dominates \(n^{\ddagger}\). When \(p\) is large, that is \(\binom{n- 2}{M- 2}p\gtrsim\log n\), then \(n^{\dagger}\asymp n n^{\ddagger}\) and Assumption 4.2 holds. Therefore, we have a dense comparison graph, and the proof for this part follows in a similar vein as Theorem 4.2. When \(p\) is small, that is, \(\binom{n- 2}{M- 2}p\lesssim\log n\), \(n^{\ddagger}\lesssim\log n\) if \(L\) is bounded. In this case, we will modify the proof of Theorem 4.2 to the random graph case in order to show Theorem 4.4 below. In addition, since \(\sum_{j:j\neq i}P_{i j} = \mathcal{O}_{P}(n^{\dagger} / d)\), it makes sense to choose \(d\asymp n^{\dagger}\) in Assumption 4.4 to make the diagonal elements of the transition matrix a constant order. Note that in the fixed graph case, we do not need to impose rate assumptions on \(d\) as the comparison graph has no randomness.

Next, we verify that under the PL model, Assumption 4.3 holds with high probability.

Theorem 4.3. Under the PL model and Assumption 4.4, with probability \(1 - o(1)\), Assumption 4.3 holds when we condition on \(\widetilde{G}\) instead of \(\mathcal{G}\).

We next hope to show that under Assumptions 4.4, the spectral estimator \(\widehat{\theta}_{i}\) has the uniform approximation: the differences between \(\widetilde{\theta}_{i} - \theta_{i}^{*}\) and \(J_{i}^{*}\) for all \(i\in [n]\) are \(o_{P}(1 / \sqrt{n^{\dagger}})\). The key step is still the verification of (3.1) under this weaker Assumptions 4.4 for a random comparison graph.

Theorem 4.4. Under the PL model and Assumptions 4.1 and 4.4, the spectral estimator \(\widetilde{\theta}_{i}\) has the uniform approximation: \(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + o_{P}\big(1 / \sqrt{n^{\dagger}}\big)\), uniformly for all \(i\in [n]\). Therefore, the spectral estimator (2.1) satisfies
\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{\binom{n - 1}{M - 1}pL}}, \tag{4.5}
\]
with probability \(1 - o(1)\). In addition,
\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]
for all \(i\in [n]\) with \(\rho_{i}(\theta) = \mathrm{Var}(J_{i}^{*}|\widetilde{G})^{- 1 / 2}\), where in the formula of \(\mathrm{Var}(J_{i}^{*}|\widetilde{G})\) we can choose both \(\theta = \theta^{*}\) and \(\theta =\) any consistent estimator of \(\theta^{*}\).

Remark 4.2. The two-step estimator under optimal weight \(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) (can be consistently estimated with a small proportion of a separate dataset) achieves the same variance as the MLE estimator, which matches the Cramer Rao lower bound among all estimators (Fan et al., 2022a,b).

Corollary 4.1. Under the conditions of Theorem 4.4, if we have \(\theta_{(K)}^{*} - \theta_{(K + 1)}^{*}\geq \Delta\), with \(\theta_{(i)}^{*}\) denoting the underlying score of the item with true rank \(i\) for \(i\in [n]\), and when the sample complexity satisfies
\[
e^{2\bar{\kappa}}\Delta^{-2}\cdot \log n = \mathcal{O}\bigg(\binom{n-1}{M-1}pL\bigg),
\]
we have \(\{i\in [n],\widehat{r_{i}}\leq K\} = \{i\in [n],r_{i}^{*}\leq K\}\) (the selected top-K set is identical to the true top-K set), where \(\widehat{r_{i}},r_{i}^{*}\) denote the empirical rank of \(\widehat{\theta}_{i}\) among \(\{\widehat{\theta}_{i},i\in [n]\}\) and true rank of the i-th item, respectively.

We remark that when \(M = 2\), and \(\bar{\kappa} = \mathcal{O}(1)\), our conclusion from Corollary 4.1 reduces to the conclusion of Theorem 1 in Chen et al.~(2019).

\section{4.3 Validity Justification for Bootstrap Procedure}\label{validity-justification-for-bootstrap-procedure}

The primary goal of this section is to justify the validity of the proposed bootstrap procedure in Section 3.4. Recall that the targeted quantity \(T_{\mathcal{M}}\) is the maximum modulus of the random vector
\[
\Delta_{\mathcal{M}}\coloneqq \left\{\frac{\widetilde{\theta}_{k} - \widetilde{\theta}_{m} - (\theta_{k}^{*} - \theta_{m}^{*})}{\widetilde{\sigma}_{km}}\right\}_{m\in \mathcal{M},k\neq m}.
\]
For each marginal of \(\Delta_{\mathcal{M}}\), the asymptotic normality can be similarly established following Theorem 4.2. However, studying the joint distribution is more complex.




\end{document}
