
\begin{document}

\section{4 Theoretical Justifications}\label{theoretical-justifications}

In this section, we rigorously justify the conclusions in Section 3 and explicitly lay out the necessary assumptions to arrive at those conclusions. The first assumption is to make sure we are comparing \(\theta_{i}^{*}\)'s in the same order in a meaningful way. Otherwise, we can always group items into categories with similar qualities and then work on each sub-group or screen some extreme items. In addition, as we have discussed, we need an identifiability condition for \(\theta^{*}\).

Assumption 4.1. There exists some positive constant \(\bar{\kappa} < \infty\) such that
\[
\max_{i\in [n]}\theta_{i}^{*} - \min_{i\in [n]}\theta_{i}^{*}\leq \bar{\kappa}.
\]
In addition, for identifiability, assume \(1^{\top}\theta^{*} = 0\).

In Assumption 4.1, we assume \(\bar{\kappa}\) is finite, indicating we only rank items with preference scores on the same scale. If \(\bar{\kappa}\) is diverging, some items will be trivially more or less favorable than others. In this case, it is typically easy in practice to separate the items into subgroups with similar preference scores, and then we can conduct ranking inference within each group. Although we assume bounded \(\bar{\kappa}\), it serves as the role of a condition number whose effect has been made explicit in all our results for interested readers. However, we do not claim this dependency is optimal as our nontrivial analysis can easily encounter powers of \(e^{\bar{\kappa}}\), say in bounding the ratio of \(\pi_{i}^{*} / \pi_{j}^{*}\).

\section{4.1 Estimation accuracy and asymptotic normality with fixed comparisons}\label{estimation-accuracy-and-asymptotic-normality-with-fixed-comparisons}

To derive the asymptotic distribution of the spectral estimator, we need to rigorously justify the approximations (3.1) and (3.2). We first take care of approximating (3.1) using (3.2), where all comparisons in \(\mathcal{G}\) are assumed to be fixed. Note that
\[
P_{ij} - E[P_{ij}|\mathcal{G}] = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_l)\left[1(c_l = j) - \frac{\pi_j^*}{\sum_{u\in A_l}\pi_u^*}\right]\frac{1}{f(A_l)}.
\]
Let \(Z_{A_l}^j = 1(c_l = j) / f(A_l)\), which is bounded from above and below as long as \(f\) is bounded from above and below. Furthermore, each \(Z_{A_l}^j\) is independent. Therefore, \(P_{ij} - E[P_{ij}|\mathcal{G}] = d^{- 1}\sum_{l\in \mathcal{D}}1(i,j\in A_l)[Z_{A_l}^j - E(Z_{A_l}^j)]\). By Hoeffding's inequality, conditioning on \(\mathcal{G}\), we have with a large probability \(1 - o(1)\),
\[
\max_{i\neq j}\left|P_{ij} - E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\ddagger}}.
\]
where \(\begin{array}{r}{n^{\ddagger} = \max_{i\neq j}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})} \end{array}\) is the maximum number of cases that each pair is compared. Similarly, we can get the concentration bound for \(\sum_{j:j\neq i}P_{ij}\). Since \(Z_{A_{l}}^{j}\)'s are independent, another level of summation over \(j\) will lead to the following. Again by Hoeffding's inequality, with a large probability tending to 1, we obtain
\[
\max_{i}\left|\sum_{j:j\neq i}P_{ij} - \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\dagger}},
\]
where \(\begin{array}{r}{n^{\dagger} = \max_{i}\sum_{l\in \mathcal{D}}1(i\in A_{l})} \end{array}\) is the maximum number of cases that each item is compared. In addition, we assume
\[
\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}] = \tau_{i}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger},
\]
where \(\tau_{i}\) defined in (3.3) is the denominator of \(J_{i}^{*}\). This assumption makes sense as \(\tau_{i}e^{- \theta_{i}^{*}}\lesssim \sum_{l\in \mathcal{D}}1(i\in A_{l}) / d\), and it states for each \(i\) the comparison graph cannot be too asymmetric. Note that \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) can still be widely different from \(n^{\ddagger}\) for different pair \((i,j)\). Since the expectation term dominates the deviation if \(n^{\dagger}\gtrsim \log n\), it is not hard to show that in (3.2), changing the denominator by its expectation will only cause a small order difference, which does not affect the asymptotic distribution.

Based on the above discussion, we impose the following assumption.

Assumption 4.2. In the case of a fixed comparison graph, we assume the graph is connected, \(\tau_{i}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all \(i\in [n]\), \(e^{2\bar{\kappa}}\log n = o(n)\) and \(e^{3\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^{1 / 2} = o(n^{\dagger})\).

The assumption is reasonable for a fixed comparison graph. If each pair \((i,j)\) must be compared at least once, then every \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\geq 1\). If they are all in the same order, then \(\sum_{l\in \mathcal{D}}1(i\in A_{l}) = \sum_{j:j\neq i}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) should be indeed in the order of \(n^{\ddagger}n\). Assumption 4.2 allows some pair \((i,j)\) to be never compared directly, so we need to leverage the information from comparing \(i\) and \(j\) to other items separately. Moreover, we also do not require \(\sum_{l\in \mathcal{D}}1(i,j\in A_l)\) to be in the same order for any \(i,j:i\neq j\) since we only require the maximum pairwise degree \(n^{\ddagger}\) to satisfy Assumption 4.2. However, in the case of a fixed graph, we do not have the randomness from the graph, and the graph must be relatively dense to make sure we have enough information to rank every item. This condition will be relaxed to \(n^{\dagger}\gtrsim n^{\ddagger}\log n\) when we have a homogeneous random comparison graph in Section 4.2.

We need another technical condition on the structure of the comparison graph. Define \(\Omega = \{\Omega_{ij}\}_{i\leq n,j\leq n}\) where \(\Omega_{ij} = - P_{ji}\pi_j^*\) for \(i\neq j\) and \(\Omega_{ii} = \sum_{j:j\neq i}P_{ij}\pi_i^*\). Note that as we derived above, \(E[\Omega_{ii}|\mathcal{G}]\) is in the order of \(n^{\dagger} / (dn)\). We hope to understand the order of its eigenvalues. Since \(\Omega\) has the minimal eigenvalue equal to zero, with the corresponding eigenvector \(\mathbf{1}\), we only focus on the space orthogonal to \(\mathbf{1}\). Following the notation of Gao et al.~(2021),
\[
\lambda_{\min ,\bot}(A) = \min_{\| v\| = 1,v^{\top}\mathbf{1} = 0}v^{\top}A v.
\]
Assumption 4.3. There exist \(C_1,C_2 > 0\) such that
\[
C_1e^{-\bar{\kappa}}\frac{n^\dagger}{dn}\leq \lambda_{\min ,\bot}(E[\Omega |\mathcal{G}])\leq \lambda_{\max}(E[\Omega |\mathcal{G}])\leq C_2e^{\bar{\kappa}}\frac{n^\dagger}{dn}, \tag{4.1}
\]
\[
\| \Omega -E[\Omega |\mathcal{G}]\| = o_{P}\left(\frac{n^{\dagger}}{dn}\right). \tag{4.2}
\]
When \(\bar{\kappa} = O(1)\), Assumption 4.3 requires that all eigenvalues (except the minimal one) of \(E[\Omega |\mathcal{G}]\) are in the order of \(n^{\dagger} / (dn)\) and \(\Omega\) also shares this same eigenvalue scale as \(E[\Omega |\mathcal{G}]\). This assumption is intuitively correct, as we have seen that \(E[\Omega_{ij}]\lesssim n^{\ddagger} / (dn)\) for \(i\neq j\) and \(E[\Omega_{ii}]\asymp n^{\dagger} / (dn)\). We will also rigorously show that this condition can be satisfied if we consider the PL model (Theorem 4.3).

Theorem 4.1. Under Assumptions 4.1-4.3, the spectral estimator \(\widetilde{\theta_{i}}\) has the following uniform approximation: \(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + \delta_{i}\), uniformly for all \(i\in [n]\), where \(\| \delta \coloneqq (\delta_{1},\dots ,\delta_{n})\|_{\infty} = o(1 / \sqrt{n^{\dagger}})\) with probability \(1 - o(1)\).

To prove Theorem 4.1, we need to verify (3.1). We leave the detailed proof in the appendix. Given Theorem 4.1, we can easily conclude the next theorem following the properties of \(J_{i}^{*}\), which lead to the rate of convergence for \(\widetilde{\theta}\) as well as its asymptotic normality.

Remark 4.1. The results of Theorem 4.1 and the following Theorems are proved via Bernstein and Hoeffding type inequalities with union bound over \(n\) items. Therefore, all of the high-probability terms hold with probability \((1 - o(1))\) (similarly for \(o_{p}(\cdot)\) and \(O_{p}(\cdot)\)) mentioned in the main text equivalently hold with probability in form of \(1 - O(n^{- \zeta})\) where \(\zeta \geq 2\) is a positive integer (different choice of \(\zeta\) will only affect constant terms in the involved concentration inequalities).

Theorem 4.2. Under Assumptions 4.1-4.3, the spectral estimator (2.1) satisfies that
\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\asymp \| J^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{n^{\dagger}}}, \tag{4.3}
\]
with probability \(1 - o(1)\), where \(J^{*} = (J_{1}^{*},\dots ,J_{n}^{*})\) with \(J_{i}^{*},i\in [n]\) being defined in (3.4). In addition,
\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]
for all \(i\in [n]\) with
\[
\rho_{i}(\theta) = \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{\sum_{u\in A_{l}}e^{\theta_{u}}}\right)\frac{e^{\theta_{i}}}{f^{2}(A_{l})}\right]^{-1/2},
\]
for both \(\theta = \theta^{*}\) and \(\theta =\) any consistent estimator of \(\theta^{*}\).

Note that Theorem 4.2 indicates that the choice of \(f(\cdot) > 0\) does not affect the rate of convergence, but it affects the estimation efficiency. As we argued in Section 3.1, the optimal weighting to minimize the asymptotic variance is \(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) in the class of spectral estimators. In practice, however, we do not know \(\theta_{u}^{*}\) beforehand. Therefore, we could implement a two-step procedure to improve the efficiency of the spectral estimator: in the first step, we obtain our initial consistent estimator \(\widehat{\theta_{u}^{(\mathrm{initial})}}\) with weighting say \(f(A_{l}) = |A_{l}|\), and in the second step, we estimate \(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) by plugging \(\widehat{\theta_{u}^{(\mathrm{initial})}}\) and run the spectral method again with this optimal weighting to get the final asymptotically efficient estimator \(\widehat{\theta_{u}^{(\mathrm{final})}}\). Note that we do not intend to prove the theoretical properties of this two-step estimator, as the data dependency in the optional weighting of the second step makes the uniform approximation analysis highly nontrivial due to non-i.i.d. ranking outcomes. Nonetheless, we could circumvent this theoretical difficulty by splitting data into a very small part \((o(|\mathcal{D}|)\) samples) for step 1, to achieve consistency with a worse convergence rate, and using the remaining majority \((|\mathcal{D}| - o(|\mathcal{D}|)\) samples) for step 2, to maintain the same asymptotic behavior. In addition, empirically, we found that directly using the same whole data in both steps achieves decent performance given a large sample size. We refer interested readers to our numerical studies.

\section{4.2 Estimation accuracy and asymptotic normality for the PL model}\label{estimation-accuracy-and-asymptotic-normality-for-the-pl-model}

In the random graph case, we have to specify the graph generation process in order to study the theoretical properties. We consider the commonly used PL model, where we sample each \(M\)-way comparison with probability \(p\) and compare this set for \(L\) times. Furthermore, we will only work with \(M = 3\) since we plan to focus on a transparent and intuitive discussion. We can easily generalize all the discussions to general \(M\), but derivations and formulas can be more tedious.

The PL model with 3-way comparisons has been studied in Fan et al.~(2022b) by using MLE, where they explicitly write down the likelihood function. The proposed spectral method can work for any fixed graph, including the one generated from the PL model. In this section, we would like to compare the performance of the spectral method with that of the MLE. To make sure the spectral method works for the PL model, we need to prove the approximations (3.1) and (3.6).

We first take care of (3.6). Consider conditioning on \(\widetilde{\mathcal{G}}\), where all comparisons in \(\widetilde{\mathcal{G}}\) are independent; each \(\widetilde{A}_{ijk}\) is compared for \(L\) times if \(\widetilde{A}_{ijk} = 1\). Now \(c_{l}\) and \(A_{l}\) are induced from \(\widetilde{\mathcal{G}}\), and can be dependent. In this case, we can write
\[
P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}} ] = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq j,i}\widetilde{A}_{ijk}[Z_{ijk}^{l} - EZ_{ijk}^{l}],
\]
where \(Z_{ijk}^{l} = 1(A_{l} = \{i,j\} ,c_{l} = j) / f(\{i,j\}) + 1(A_{l} = \{i,j,k\} ,c_{l} = j) / f(\{i,j,k\})\), which is again bounded from above and below and independent for any given \(\widetilde{A}_{ijk}\). In this case, with a little abuse of notations, we redefine
\[
n^{\dagger} = L\max_{i\neq j}\sum_{k:k\neq j,i}A_{ijk},\quad n^{\dagger} = L\max_{i}\sum_{j< k:j,k\neq i}A_{ijk}.
\]
Similar to Section 4.1, conditional on \(\widetilde{G}\), we have
\[
\begin{array}{r l} & {\max_{i}\bigg|\sum_{j:j\neq i}P_{i j} - \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\dagger}\log n}),}\\ & {\max_{i\neq j}\bigg|P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}}]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\ddagger}\log n}).}
\end{array}
\]
We adapt Assumption 4.2 to the following assumption. Note that we have no assumption on \(L\), so \(L\) can be as low as 1.

Assumption 4.4. In the PL model with \(M\)-way complete comparisons, choose \(d\asymp n^{\dagger}\) in the spectral ranking, and assume \(\tau_{i}^{\diamond}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all \(i\in [n]\), \(e^{4\bar{\kappa}} = o(n)\) and \(p\gtrsim e^{6\bar{\kappa}}\mathrm{poly}(\log n) / \binom{n- 1}{M- 1}\).

Under Assumption 4.4, we can prove
\[
n^{\dagger}\asymp \binom{n-1}{M-1}p L,\qquad\max \Big\{\binom{n-2}{M-2}p-\log n,0\Big\}L\lesssim n^{\ddagger}\lesssim\Big[\binom{n-2}{M-2}p+\log n\Big]L,
\]
with probability \(1 - o(1)\). Note that in \(n^{\dagger}\), by Assumption 4.4, we know the dominating term is \(\binom{n- 1}{M- 1}p L\). However, in \(n^{\ddagger}\), we have the additional term \(\log n\), which comes from the sub-exponential tail decay in Bernstein inequality, and if \(p\) is really small, it could happen that \(\log n\) dominates \(n^{\ddagger}\). When \(p\) is large, that is \(\binom{n- 2}{M- 2}p\gtrsim\log n\), then \(n^{\dagger}\asymp n n^{\ddagger}\) and Assumption 4.2 holds. Therefore, we have a dense comparison graph, and the proof for this part follows in a similar vein as Theorem 4.2. When \(p\) is small, that is, \(\binom{n- 2}{M- 2}p\lesssim\log n\), \(n^{\ddagger}\lesssim\log n\) if \(L\) is bounded. In this case, we will modify the proof of Theorem 4.2 to the random graph case in order to show Theorem 4.4 below. In addition, since \(\sum_{j:j\neq i}P_{i j} = \mathcal{O}_{P}(n^{\dagger} / d)\), it makes sense to choose \(d\asymp n^{\dagger}\) in Assumption 4.4 to make the diagonal elements of the transition matrix a constant order. Note that in the fixed graph case, we do not need to impose rate assumptions on \(d\) as the comparison graph has no randomness.

Next, we verify that under the PL model, Assumption 4.3 holds with high probability.

Theorem 4.3. Under the PL model and Assumption 4.4, with probability \(1 - o(1)\), Assumption 4.3 holds when we condition on \(\widetilde{G}\) instead of \(\mathcal{G}\).

We next hope to show that under Assumptions 4.4, the spectral estimator \(\widehat{\theta}_{i}\) has the uniform approximation: the differences between \(\widetilde{\theta}_{i} - \theta_{i}^{*}\) and \(J_{i}^{*}\) for all \(i\in [n]\) are \(o_{P}(1 / \sqrt{n^{\dagger}})\). The key step is still the verification of (3.1) under this weaker Assumptions 4.4 for a random comparison graph.

Theorem 4.4. Under the PL model and Assumptions 4.1 and 4.4, the spectral estimator \(\widetilde{\theta}_{i}\) has the uniform approximation: \(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + o_{P}\big(1 / \sqrt{n^{\dagger}}\big)\), uniformly for all \(i\in [n]\). Therefore, the spectral estimator (2.1) satisfies
\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{\binom{n - 1}{M - 1}pL}}, \tag{4.5}
\]
with probability \(1 - o(1)\). In addition,
\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]
for all \(i\in [n]\) with \(\rho_{i}(\theta) = \mathrm{Var}(J_{i}^{*}|\widetilde{G})^{- 1 / 2}\), where in the formula of \(\mathrm{Var}(J_{i}^{*}|\widetilde{G})\) we can choose both \(\theta = \theta^{*}\) and \(\theta =\) any consistent estimator of \(\theta^{*}\).

Remark 4.2. The two-step estimator under optimal weight \(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) (can be consistently estimated with a small proportion of a separate dataset) achieves the same variance as the MLE estimator, which matches the Cramer Rao lower bound among all estimators (Fan et al., 2022a,b).

Corollary 4.1. Under the conditions of Theorem 4.4, if we have \(\theta_{(K)}^{*} - \theta_{(K + 1)}^{*}\geq \Delta\), with \(\theta_{(i)}^{*}\) denoting the underlying score of the item with true rank \(i\) for \(i\in [n]\), and when the sample complexity satisfies
\[
e^{2\bar{\kappa}}\Delta^{-2}\cdot \log n = \mathcal{O}\bigg(\binom{n-1}{M-1}pL\bigg),
\]
we have \(\{i\in [n],\widehat{r_{i}}\leq K\} = \{i\in [n],r_{i}^{*}\leq K\}\) (the selected top-K set is identical to the true top-K set), where \(\widehat{r_{i}},r_{i}^{*}\) denote the empirical rank of \(\widehat{\theta}_{i}\) among \(\{\widehat{\theta}_{i},i\in [n]\}\) and true rank of the i-th item, respectively.

We remark that when \(M = 2\), and \(\bar{\kappa} = \mathcal{O}(1)\), our conclusion from Corollary 4.1 reduces to the conclusion of Theorem 1 in Chen et al.~(2019).

\section{4.3 Validity Justification for Bootstrap Procedure}\label{validity-justification-for-bootstrap-procedure}

The primary goal of this section is to justify the validity of the proposed bootstrap procedure in Section 3.4. Recall that the targeted quantity \(T_{\mathcal{M}}\) is the maximum modulus of the random vector
\[
\Delta_{\mathcal{M}}\coloneqq \left\{\frac{\widetilde{\theta}_{k} - \widetilde{\theta}_{m} - (\theta_{k}^{*} - \theta_{m}^{*})}{\widetilde{\sigma}_{km}}\right\}_{m\in \mathcal{M},k\neq m}.
\]
For each marginal of \(\Delta_{\mathcal{M}}\), the asymptotic normality can be similarly established following Theorem 4.2. However, studying the joint distribution is more complex.




\end{document}
