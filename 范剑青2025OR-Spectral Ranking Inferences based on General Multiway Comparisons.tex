\begin{document}


\section{Spectral Ranking Inferences based on General Multiway
Comparisons*}\label{spectral-ranking-inferences-based-on-general-multiway-comparisons}

Jianqing Fan Zhipeng Lou Weichen Wang Mengxin Yu

March 4, 2024

\section{Abstract}\label{abstract}

This paper studies the performance of the spectral method in the
estimation and uncertainty quantification of the unobserved preference
scores of compared entities in a general and more realistic setup.
Specifically, the comparison graph consists of hyper- edges of possible
heterogeneous sizes, and the number of comparisons can be as low as one
for a given hyper- edge. Such a setting is pervasive in real
applications, circumventing the need to specify the graph randomness and
the restrictive homogeneous sampling assumption imposed in the commonly-
used Bradley- Terry- Luce (BTL) or Plackett- Luce (PL) models.
Furthermore, in scenarios where the BTL or PL models are appropriate, we
unravel the relationship between the spectral estimator and the Maximum
Likelihood Estimator (MLE). We discover that a two- step spectral
method, where we apply the optimal weighting estimated from the equal
weighting vanilla spectral method, can achieve the same asymptotic
efficiency as the MLE. Given the asymptotic distributions of the
estimated preference scores, we also introduce a comprehensive framework
to carry out both one- sample and two- sample ranking inferences,
applicable to both fixed and random graph settings. It is noteworthy
that this is the first time effective two- sample rank testing methods
have been proposed. Finally, we substantiate our findings via
comprehensive numerical simulations and subsequently apply our developed
methodologies to perform statistical inferences for statistical journals
and movie rankings.

\section{1 Introduction}\label{introduction}

Rank aggregation is crucial in various applications, including web
search (Dwork et al., 2001; Wang et al., 2016), primate intelligence
experiments (Johnson et al., 2002), assortment optimization (Aouad et
al., 2018; Chen et al., 2020), recommendation systems (Baltrunas et al.,
2010; Li et al., 2019), sports ranking (Massey, 1997; Turner and Firth,
2012), education (Avery et al., 2013; Caron et al., 2014), voting
(Plackett, 1975; Mattei and Walsh, 2013), and instruction tuning used in
the recent popular large language model ChatGPT (Ouyang et al., 2022).
Therefore, it becomes an

essential problem in many fields, such as psychology, econometrics,
education, operation research, statistics, machine learning, artificial
intelligence, etc.

Luce (Luce, 1959) introduced the celebrated Luce's axiom of choice. Let
\(p(i\mid A)\) be the probability of selecting item \(i\) over all other
items in the set of alternatives \(A\) . According to the axiom, when
comparing two items \(i\) and \(j\) in any sets of alternatives \(A\)
containing both \(i\) and \(j\) , the probability of choosing \(i\) over
\(j\) is unaffected by the presence of other alternatives in the set. In
specific, the axiom postulates that

\[
\frac{\mathbb{P}(i\mathrm{~is~preferred~in~}A)}{\mathbb{P}(j\mathrm{~is~preferred~in~}A)} = \frac{\mathbb{P}(i\mathrm{~is~preferred~in~}\{i,j\})}{\mathbb{P}(j\mathrm{~is~preferred~in~}\{i,j\})}.
\]

This assumption gives rise to a unique parametric choice model, the
Bradley- Terry- Luce (BTL) model for pairwise comparisons, and the
Plackett- Luce (PL) model for \(M\) - way rankings \(M\geq 2\)

In this paper, we consider a collection of \(n\) items whose true
ranking is determined by some unobserved preference scores
\(\theta_{i}^{*}\) for \(i = 1,\dots ,n\) . In this scenario, the BTL
model assumes that an individual or a random event ranks item \(i\) over
\(j\) with probability \(\mathbb{P}(\mathrm{item}~i\) is preferred over
item \(j) =\) \(e^{\theta_i^*} / (e^{\theta_i^*} + e^{\theta_j^*})\) .
The Plackett- Luce model is an expanded version of pairwise comparison,
which allows for a more comprehensive \(M\) - way full ranking, as
initially described in Plackett (1975). This model takes individual
preferences into account when ranking a selected subset of items with
size \(M< \infty\) (among all \(n\) items), which we represent as
\(i_{1}\succ \dots \succ i_{M}\) . Think of this full ranking as
\(M - 1\) distinct events where \(i_{1}\) is favored over the set
\(i_{1},\ldots ,i_{M}\) , followed by \(i_{2}\) being favored over the
set \(i_{2},\ldots ,i_{M}\) , and so on. The PL model calculates the
probability of a full ranking \(i_{1}\succ \dots \succ i_{M}\) using the
formula:

\[
\mathbb{P}(i_1\succ \dots \succ i_M) = \prod_{j = 1}^{M - 1}\left[e^{\theta_{ij}^*} / \sum_{k = j}^{M}e^{\theta_{ik}^*}\right].
\]

Next, we will give a brief introduction to the literature that has made
progress on model estimation and uncertainty quantification for the BTL
and the PL models over the parametric model.

\section{1.1 Related literature}\label{related-literature}

A series of papers studied model estimation or inference based on the
BTL or PL models. In the case of the Bradley- Terry- Luce model, its
theoretical characteristics were solidified through a minorization-
maximization algorithm, as outlined by Hunter (2004). Additionally,
Negahban et al.~(2012) developed an iterative rank aggregation algorithm
called Rank Centrality (spectral method), which can recover the BTL
model's underlying scores at an optimal \(\ell_2\) - statistical rate.
Subsequently, Chen and Suh (2015) used a two- step methodology (spectral
method followed by MLE) to examine the BTL model in a context where the
comparison graph is based on the Erdős- Rényi model, where every item
pair is assumed to have a probability \(p\) of being compared, and once
a pair is connected, it will be compared for \(L\) times. Subsequently,
under a similar setting with Chen and Suh (2015), Chen et al.~(2019)
investigated the optimal statistical rates for recovering the underlying
scores, demonstrating that regularized maximum likelihood estimation
(MLE) and the spectral method are both optimal for retrieving top- \(K\)
items when the conditional number is a constant. They derived

\(\ell_2\) - as well as \(\ell_\infty\) - rates for the unknown
underlying preference scores in their study. Furthermore, Chen et
al.~(2022) extended the investigation of Chen et al.~(2019) to the
partial recovery scenarios and improved the analysis to un- regularized
MLE.

Expanding beyond simple pairwise comparisons, researchers also explored
ranking issues through \(M\) - way comparisons, where \(M \geq 2\) . The
Plackett- Luce model and its variations serve as prominent examples in
this line of study, as evidenced by numerous references (Plackett, 1975;
Guiver and Snelson, 2009; Cheng et al., 2010; Hajek et al., 2014;
Maystre and Grossglauser, 2015; Szorenyi et al., 2015; Jang et al.,
2018). In particular, Jang et al.~(2018) investigated the Plackett- Luce
model within the context of a uniform hyper- graph, where a tuple with
size \(M\) is compared with probability \(p\) and once a tuple is
connected or compared in the hyper- graph, it will be compared for \(L\)
times. By dividing \(M\) - way comparison data into pairs, they employ
the spectral method to obtain the \(\ell_\infty\) - statistical rate for
the underlying scores. Additionally, they presented a lower bound for
sample complexity necessary to identify the top- \(K\) items under the
Plackett- Luce model. In a more recent development, under the same model
setting, Fan et al.~(2022b) enhanced the findings of Jang et al.~(2018),
focusing solely on the top choice. Rather than splitting the comparison
data into pairwise comparisons, they applied the Maximum Likelihood
Estimation (MLE) and matched the sample complexity lower bound needed to
recover the top- \(K\) items. This contrasts with Jang et al.~(2018),
which requires a significantly denser comparison graph or a much larger
number of comparisons for their results to hold.

The aforementioned literature primarily concentrated on the non-
asymptotic statistical consistency for estimating item scores. However,
the results of limiting distribution for ranking models remained largely
unexplored. Only a limited number of findings on asymptotic
distributions of estimated ranking scores exist under the Bradley-
Terry- Luce model, whose comparison graphs are sampled from the Erdős-
Rényi graph with connection probability \(p\) and each observed pair has
the same number of comparisons \(L\) . For example, Simons and Yao
(1999) established the asymptotic normality of the BTL model's maximum
likelihood estimator when all comparison pairs are entirely conducted
(i.e., \(p = 1\) ). Han et al.~(2020) expanded these findings for dense,
but not fully connected, comparison graphs (Erdős- Rényi random graphs)
where \(p \gtrsim n^{- 1 / 10}\) . Recently, Liu et al.~(2022)
introduced a Lagrangian debiasing approach to derive asymptotic
distributions for ranking scores, accommodating sparse comparison graphs
with \(p \asymp 1 / n\) but necessitating comparison times
\(L \gtrsim n^2\) . Furthermore, Gao et al.~(2021) employed a ``leave-
two- out'' technique to determine asymptotic distributions for ranking
scores, achieving optimal sample complexity and allowing
\(L = \mathcal{O}(1)\) in the sparse comparison graph setting (i.e.,
\(p \asymp 1 / n\) up to logarithm terms). Fan et al.~(2022a) extended
upon existing research by incorporating covariate information into the
BTL model. By introducing an innovative proof, they presented the MLE's
asymptotic variance with optimal sample complexity when
\(p \asymp 1 / n\) and \(L = \mathcal{O}(1)\) . In the sequel, Fan et
al.~(2022b) broadened the asymptotic results of the BTL model to
encompass Plackett- Luce (PL) models with \(M \geq 2\) again with
optimal sample complexity. They also developed a unified framework to
construct rank confidence intervals, requiring the number of comparisons
\(L \gtrsim \mathrm{poly}(\log n)\) . Moreover, recently, Han and Xu
(2023) further extended the settings in Fan et al.~(2022b) by
investigating the asymptotic distribution of the MLE, where the
comparisons are generated from a mixture of

Erdos- Renyi graphs with different sizes or a hypergraph stochastic
block model.

Erdős- Rényi graphs with different sizes or a hypergraph stochastic
block model.Finally, we discuss related literature of an important
application of our framework: assortment optimization (Talluri and Van
Ryzin, 2004; Rusmevichientong and Topaloglu, 2012; Vulcano et al., 2012;
Davis et al., 2014; Zhang et al., 2020; Chen et al., 2020, 2023; Shen et
al., 2023) which is of great importance in revenue management.
Specifically, in their settings, each product (including the no-
purchase alternative) is also associated with an unknown customer
preference score, which can characterize the customers' choice behavior
over a set of offered products. Based on the consistently estimated
preference scores and the available profit information of each product,
various efficient algorithms have been proposed to determine the optimal
assortment under different kinds of practical constraints (Talluri and
Van Ryzin, 2004; Rusmevichientong et al., 2010; Gallego and Topaloglu,
2014; Sumida et al., 2021). Moreover, uncertainty quantification of the
estimated preference scores also enables statistical inference on the
properties of the optimal assortment (Shen et al., 2023).

\section{1.2 Motivations and
Contributions}\label{motivations-and-contributions}

1.2 Motivations and ContributionsIn this section, we discuss our
motivation and problem settings and compare our results with previous
literature in different aspects, namely the comparison graph, the
connection between the spectral method and MLE, and ranking inferences.

\section{1.2.1 Comparison graph}\label{comparison-graph}

Previous studies on parametric ranking models mostly require comparison
graphs derived from a specific random graph. For example, in the
endeavor of understand multiway comparisons (e.g.~Jang et al.~(2016);
Fan et al.~(2022b)), it is typically assumed that the comparisons are
generated explicitly from a homogeneous graph with a known distribution.
This assumption may pose a challenge in certain contexts. Although
practical applications with homogeneous comparisons exist, it is
sometimes unrealistic to presume that all comparisons are generated from
a known homogeneous distribution. In fact, there are more cases where we
see heterogeneous comparisons, where some are compared more often than
others and the comparison graph generation process is unknown. We will
present Example 1.1 as our motivation.

Example 1.1. There is a sequence of customers buying goods. For the
\(l\) - th customer, according to her preference, her reviewed products
are \(A_{l}\) (a choice set), and she finally chose product
\(c_{l}\in A_{l}\) (her top choice). Then the total datasets presented
to us is \(\{(A_l,c_l)\}_{l = 1}^D\) . If all choice sets are presented
to the customers with the same probability and the reviewed number of
items are of the same size (such as pairwise comparisons), we say the
comparison graph is homogeneous. But if some choice sets, possibly with
different sizes, are presented more often to the customers or are chosen
arbitrarily based on the customers' preference profiles, then this
heterogeneous comparison graph cannot be well approximated by a given
random graph model. That is, the comparisons may not follow, say, the
BTL or PL models with Erdos- Renyi types of uniform graphs.

The heterogeneous comparison scheme in Example 1.1 above is applicable
across a wide range of practical scenarios. For instance, it covers the
typical setup of the assortment optimization,

\pandocbounded{\includegraphics[keepaspectratio]{images/166cf6f6b99e4beefb26f15500d7fb45e7a5c1bf6743c6b0bcc83e3bdcb260e6.jpg}}

wherein the no- purchase alternative is also included in the choice set
\(A_{l}\) . We give a toy example with 5 products in Figure 1, where
sizes of \(A_{l}\) are among \(\{2,3,4\}\) . Due to the heterogeneity,
it is unrealistic to assume \(A_{l}\) is of the same size or sampled
from an explicit random graph. However, most of the previous works
focused on statistical properties under certain ad- hoc random graphs,
most commonly the Erdős- Rényi type of uniform graphs, e.g., Chen and
Suh (2015); Chen et al.~(2019); Jang et al.~(2016); Gao et al.~(2021);
Liu et al.~(2022); Fan et al.~(2022b); Han and Xu (2023). One
interesting piece of research that indeed worked with the fixed
comparison graph is Shah et al.~(2015), which explored the optimality of
MLE in \(\ell_{2}\) estimation with pairwise comparisons. Following this
work, Li et al.~(2022) further discussed the optimality of MLE in
\(\ell_{\infty}\) error. Still, little has been known about the
inference results for general fixed comparison graphs.

In this paper, we focus on the setting of a general fixed comparison
graph, where we circumvent the modeling for the complicated graph-
generating process. Specifically, we study statistical estimation and
uncertainty quantification of the preference scores over a general,
heterogeneous choice set via the spectral method. In addition, we also
study the theoretical performance of the spectral method when we do have
a homogeneous random comparison graph, and compare the results. Our
results require slightly stronger conditions to handle fixed graph
settings since we need to make sure each item has enough information to
be ranked.

For the general setting, we denote the choice preference for the \(l\) -
th comparison as \((c_{l},A_{l})\) , wherein \(A_{l}\) signifies the set
of choices with heterogeneous size, which can be either fixed or random,
and \(c_{l}\in A_{l}\) represents the most preferred item in \(A_{l}\) .
Hence, in the \(l\) - th comparison, we understand that \(c_{l}\)
outranks all other elements within \(A_{l}\) . As such, our broadest
comparison data is symbolized as \(\mathcal{D} = \{l|(c_{l},A_{l})\}\) .
The associated collection of choice sets is denoted as
\(\mathcal{G} = \{A_{l}|l\in \mathcal{D}\}\) . This framework also
contains the Plackett- Luce model as a special case, if we treat the PL
model as \(M - 1\) selections over \(M - 1\) choice sets. Under mild
conditions, we manage to obtain optimal statistical rates for our
spectral estimator conditional on the comparison graphs and specify the
explicit form of its asymptotic distribution. This gives an efficient
solution when one encounters heterogeneous comparison graphs. In
addition, since the graph is fixed or conditioned upon, it is not
necessary for us to repeat each comparison for \(L\geq 1\) times. We can
even accommodate situations where a choice set is chosen and compared
for just a single time, which is true in many practical applications.

\section{1.2.2 Connection between the spectral estimator and the
MLE}\label{connection-between-the-spectral-estimator-and-the-mle}

Our general setting, as introduced in Section 1.2.1, encompasses
homogeneous random comparison graphs as a particular instance. The bulk
of prior research has centered around the evaluation of the Maximum
Likelihood Estimator (MLE) or the spectral method when applied to
homogeneous comparisons (Chen and Suh, 2015; Chen et al., 2019, 2022;
Fan et al., 2022a,b). Both are effective methods for examining ranking
issues within the context of the BTL or PL model. Hence, an interesting
question arises: What is the relationship between the MLE and the
spectral method?

A handful of studies have offered insights into this question. For
instance, Maystre and Gross- glauser (2015) identified a link between
the MLE and spectral method in multiway comparisons, where the spectral
estimator aligns with the MLE through the iterative updating of specific
weight-

ing functions in constructing the spectral estimator. This connection
was only limited to the first order in the sense that the paper only
concerns the convergence property. Furthermore, Gao et al.~(2021)
demonstrated that the asymptotic variance of the spectral method exceeds
that of the MLE in pairwise comparisons using the BTL model. However,
this discrepancy arises from their choice of a suboptimal weighting
function for the spectral estimator.

In our paper, we leverage the homogeneous random comparison graph case
(as it is the most popularly studied setting in many previous articles)
to illustrate that by employing certain optimally estimated information
weighting functions, the asymptotic variance of the spectral estimator
matches that of the MLE with multiway comparisons in the PL model.
Therefore, the MLE could be considered a ``two- step'' spectral method,
where in the first step we consistently estimate the unobserved
preference scores, and in the second step we use the proper weighting in
the spectral method to achieve an efficient estimator. It is also
noteworthy that we achieve the optimal sample complexity over the
sparsest sampling graph up to logarithmic terms.

\section{1.2.3 Ranking inferences: one sample vs two
samples}\label{ranking-inferences-one-sample-vs-two-samples}

As another contribution, we also study several rank- related inference
problems. We have the following motivating example:

Example 1.2. First, we consider the one- sample inference problem.
Consider a group of candidate items \(\{1,\dots ,n\}\) and one observed
dataset on their comparisons; we are interested in

\begin{itemize}
\tightlist
\item
  Building the confidence intervals for the ranks of certain items
  \(\{r_1,\dots ,r_m\}\) of our interest.- Testing whether a given item
  \(m\) is in the top- \(K\) set, which includes \(K\) best items.
\end{itemize}

Second, we consider the two- sample inference problem. For two groups of
datasets of the same list of items \(\{1,\dots ,n\}\) , we are
interested in

\begin{itemize}
\tightlist
\item
  Testing whether the rank of a certain item \(m\) is preserved across
  these two samples (e.g.~groups or time periods).- Testing whether the
  top- \(K\) sets have changed or not.
\end{itemize}

Rankings are ubiquitous in real- world applications, for instance, in
the evaluation of universities, sports teams, or web pages. However,
most of these rankings provide only first- order information, presenting
the results without offering any measure of uncertainty. For example,
under the BTL model, when two items have equivalent underlying scores,
there's a \(50\%\) probability of one being ranked higher than the
other. Thus, rankings between these two items could be unreliable due to
their indistinguishable underlying scores, emphasizing the necessity for
confidence intervals in rankings.

Given these critical considerations, our study offers a comprehensive
framework that efficiently solves the problems outlined in Example 1.2
over heterogeneous comparison graphs. Additionally, our approach
enhances the sample complexity of several previous works. For instance,
when restricting our general framework to homogeneous random comparison
graphs, regarding the one- sample

inference, Liu et al.~(2022) required \(L \gtrsim n^2\) to carry out the
statistical inference, while Fan et al.~(2022b) further improved this
requirement to \(L \gtrsim \mathrm{poly}(\log n)\) . In our paper, our
framework can allow \(L = \mathcal{O}(1)\) and even \(L = 1\) .
Furthermore, two- sample ranking inference, which can be widely applied
in real- world scenarios like policy evaluation, treatment effect
comparison, change point detection, etc., has not been previously
studied. Our paper also introduces a general framework for studying the
two- sample ranking inference problems, again offering optimal sample
complexity.

\section{1.2.4 Theoretical
contributions}\label{theoretical-contributions}

We build up our theoretical analyses based on some previously developed
techniques from Gao et al.~(2021) and Chen et al.~(2019). However, our
proofs have the following novelty: In those two papers and other papers
with a random comparison graph, graph randomness and ranking outcome
randomness are typically intertwined in the analysis. We will separate
them and reveal the proper quantities of interest to summarize the
information in a fixed comparison graph. We study the connection between
these quantities and the spectral ranking performance, and provide
sufficient conditions under the fixed graph for valid ranking inference.
This theoretical attempt has not previously been seen in the literature.
In addition, all our analyses allow varying comparison sizes and an
arbitrary number of repetitions of each comparison set. This
significantly broadens the applicability of our proposed methodology, as
in practice, a lot of ranking problems contain non- repeating
comparisons of different numbers of items. We also work on the theory
when we also have graph randomness. We realize that the homogeneity of
sampling each comparison tuple can lead to more relaxed assumptions.
With more relaxed conditions, we clearly show where and how we can
achieve an improved performance guarantee (see the assumption and proof
of Theorem 4.4). This part highlights the difference between fixed and
random graphs and provides more theoretical insights into the role of
graph randomness in spectral ranking.

\section{1.3 Roadmap and notations}\label{roadmap-and-notations}

In Section 2, we set up the model and introduce the spectral ranking
method. Section 3 is dedicated to the examination of the asymptotic
distribution of the spectral estimator, based on fixed comparison graphs
and random graphs with the PL model, respectively. Within the same
section, we also introduce the framework designed for the construction
of rank confidence intervals and rank testing statistics for both one-
sample and two- sample analysis. Section 4 details the theoretical
guarantees for all proposed methodologies. Sections 5 and 6 contain
comprehensive numerical studies to verify theoretical results and two
real data examples to illustrate the usefulness of our ranking inference
methods. Finally, we conclude the paper with some discussions in Section
7. All the proofs are deferred to the appendix.

Throughout this work, we use \([n]\) to denote the index set
\(\{1,2,\dots ,n\}\) . For any given vector
\(\mathbf{x} \in \mathbb{R}^n\) and \(q \geq 0\) , we use
\(\| \mathbf{x}\| _q = (\sum_{i = 1}^{n} |x_i|^q)^{1 / q}\) to represent
the vector \(\ell_q\) norm. For any given matrix
\(\mathbf{X} \in \mathbb{R}^{d_1 \times d_2}\) , we use \(\| \cdot \|\)
to denote the spectral norm of \(\mathbf{X}\) and write
\(\mathbf{X} \succcurlyeq 0\) or \(\mathbf{X} \preccurlyeq 0\) if
\(\mathbf{X}\) or \(- \mathbf{X}\) is positive semidefinite. For event
\(A\) , \(1(A)\) denotes an indicator which equals 1 if \(A\) is true
and 0 otherwise. For two positive sequences \(\{a_n\}_{n \geq 1}\) ,
\(\{b_n\}_{n \geq 1}\) , we write \(a_n = \mathcal{O}(b_n)\) or

\(a_{n} \lesssim b_{n}\) if there exists a positive constant \(C\) such
that \(a_{n} / b_{n} \leq C\) and we write \(a_{n} = o(b_{n})\) if
\(a_{n} / b_{n} \to 0\) . In addition, \(\mathcal{O}_{p}(\cdot)\) and
\(o_{p}(\cdot)\) share similar meanings as \(\mathcal{O}(\cdot)\) and
\(o(\cdot)\) , respectively, but these relations hold asymptotically
with probability tending to 1. Similarly we have
\(a_{n} = \Omega (b_{n})\) or \(a_{n} \gtrsim b_{n}\) if
\(a_{n} / b_{n} \geq c\) with some constant \(c > 0\) . We use
\(a_{n} = \Theta (b_{n})\) or \(a_{n} \asymp b_{n}\) if
\(a_{n} = \mathcal{O}(b_{n})\) and \(a_{n} = \Omega (b_{n})\) . For two
random variables \(A_{n}, B_{n}\) , if we write \(A_{n} \approx B_{n}\)
, it holds that \(A_{n} - B_{n} = o(1)\) with probability goes to 1.
Given \(n\) items, we use \(\theta_{i}^{*}\) to indicate the underlying
preference score of the \(i\) - th item. Define \(r: [n] \to [n]\) as
the rank operator on the \(n\) items, which maps each item to its
population rank based on the preference scores. We write the rank of the
\(i\) - th item as \(r_{i}\) or \(r(i)\) . By default, we consider
ranking from the largest score to the smallest score.

\section{2 Multiway Comparison Model and Spectral
Ranking}\label{multiway-comparison-model-and-spectral-ranking}

We first introduce a general discrete choice model, which encompasses
the classical Plackett- Luce model as well as fixed comparison graph
scenario.

\section{2.1 Discrete choice model}\label{discrete-choice-model}

We assume there are \(n\) items to be ranked. According to Luce's choice
axiom (Luce, 1959), the preference scores of a given group of \(n\)
items can be parameterized as a vector
\((\theta_{1}^{*}, \ldots , \theta_{n}^{*})^{\top}\) such that
\(\mathbb{P}(i\) wins among
\(A) = e^{\theta_{i}^{*}} / (\sum_{k \in A} e^{\theta_{k}^{*}})\) for
any choice set \(A\) and item \(i \in A\) . Since the parameters are
only identifiable up to a location shift, without loss of generality, we
assume \(\sum_{i = 1}^{n} \theta_{i}^{*} = 0\) for identification. We
consider the general comparison model, where we are given a collection
of comparisons and outcomes \(\{(c_{l}, A_{l})\}_{l \in \mathcal{D}}\) .
Here \(c_{l}\) denotes the selected item over the choice set \(A_{l}\)
with probability
\(e^{\theta_{c_{l}}^{*}} / (\sum_{k \in A_{l}} e^{\theta_{k}^{*}})\) .

Remark 2.1. This general comparison model contains many well- known
special cases.

\begin{itemize}
\item
  For the Bradley-Terry-Luce (BTL) model, it is easy to set \(A_{l}\) as
  the pair being compared every time. If each pair is compared for \(L\)
  times independently, we just need to write the outcomes as
  \((c_{l}, A_{l})\) and re-index \(l\) .
\item
  For the Plackett-Luce (PL) model, we have obtained the full ranking of
  a choice set \(B = \{i_{1}, \dots , i_{B}\}\) . The probability of
  observing a certain ranking becomes
\end{itemize}

\[
\begin{array}{r l} & {\mathbb{P}(i_{1} > i_{2} > \dots >i_{B}) = \mathbb{P}(i_{1}\mathrm{~wins~among~}C_{1}\mid C_{1} = B)\cdot \mathbb{P}(i_{2}\mathrm{~wins~among~}C_{2}\mid C_{2} = B\{-i_{1}\})\cdot \dots}\\ & {\qquad \cdot \mathbb{P}(i_{B - 1}\mathrm{~wins~among~}C_{B - 1}\mid C_{B - 1} = B\{-i_{1},\dots , - i_{B - 2}\})}\\ & {\qquad = \frac{e^{\theta_{i_{1}}^{*}}}{\sum_{j = 1}^{B}e^{\theta_{i_{j}}^{*}}}\cdot \frac{e^{\theta_{i_{2}}^{*}}}{\sum_{j = 2}^{B}e^{\theta_{i_{j}}^{*}}}\cdot \dots \frac{e^{\theta_{i_{B - 1}}^{*}}}{\sum_{j = B - 1}^{B}e^{\theta_{i_{j}}^{*}}},} \end{array}
\]

where \(C_{i}, i \geq 1\) is the \(i\) - th comparison set and
\(B\{- i_{1}, \dots , - i_{M}\}\) denotes the set of remained items
after removing \(\{i_{1}, \dots , i_{M}\}\) . These comparison results
can also be decomposed into the comparisons:

\[
\{(i_{1}, B), (i_{2}, B\{-i_{1}\}), \dots , (i_{B - 1}, B\{-i_{1}, \dots , -i_{B - 2}\})\} .
\]

\begin{itemize}
\tightlist
\item
  With fixed comparison graphs, \(\{A_{l},l\in \mathcal{D}\}\) are given
  and hence have no randomness, so the comparison results in \(c_{l}\)
  are assumed independent. In contrast, with a random comparison graph,
  such as in the PL model, \(A_{l}\) may be dependent. For instance,
  \((\theta_{i_{1}},B)\) and \((\theta_{i_{2}},B\{-i_{1}\})\) are
  dependent as \(B\{-i_{1}\}\) depends on the winner of the first
  comparison \(i_{1}\) . Therefore, we have to explicitly lay out the
  random process assumption for comparison generation in order to study
  the theoretical properties in a case-by-case manner.
\end{itemize}

Recall that the general comparison data is denoted as
\(\{(c_{l},A_{l})\}_{l\in \mathcal{D}}\) . The corresponding collection
of choice sets is \(\mathcal{G} = \{A_{l}|l\in \mathcal{D}\}\) . When we
only have pairwise comparisons, \(|A_{l}| = 2\) and \(\mathcal{G}\)
represents the set of all edges we have compared. But in a general
setting, \(A_{l}\) can have different sizes and we denote
\(M = \max_{l\in \mathcal{D}}|A_{l}|< \infty\) as the maximal size of
the comparison hyper- graph edge. Also if we have \(L\) independent
comparisons of the same comparison hyper- edge \(A_{l}\) , we use
different \(l\) to indicate the comparison. So in \(\mathcal{G}\) , the
hyper- edge \(A_{l}\) may be compared for multiple times with different
outcomes \(c_{l}\) .

Throughout this paper, we consider using the spectral method on the
preference data based on multiway comparisons. We will first focus on
the fixed comparison graph and then consider commonly- used random
comparison graph structures. Notice that no matter whether the
comparison graph \(\mathcal{G}\) is fixed or random, our spectral
ranking methodology will be conditional on \(\mathcal{G}\) , which is
observed in practice. The underlying model for generating
\(\mathcal{G}\) can be very general: it can be given, or random based on
the Erdős- Rényi random graph with the same probability \(p\) , or more
generally induced from some other comparison rules, which could even
cause some \(A_{l}\) dependent. For example, if we view each comparison
of the PL model as \(M - 1\) pairwise comparisons involving top 1 vs top
2, top 2 vs top 3, \ldots, top \(M - 1\) vs top \(M\) . Then the
resulting comparison data, denoted as
\((c_{l} - i_{k},A_{l} = \{i_{k},i_{k + 1}\})\) for
\(k = 1,\ldots ,M - 1\) , are dependent (even the definition of
\(A_{l}\) depends on the complete comparison result).

\section{2.2 Spectral ranking}\label{spectral-ranking}

In the spectral method, we formally define a Markov chain, denoted as
\(M = (S,P)\) . Here, \(S\) signifies the collection of \(n\) states
corresponding to the \(n\) items to be compared, represented as vertices
of a directed comparison graph. And \(P\) constitutes the transition
matrix defined below. This matrix oversees transitions amongst the
states by representing whether any two particular states within \(S\)
are capable of being connected via non- zero transition probabilities.

Define two index sets \(\mathcal{W}_{j},\mathcal{L}_{i}\) for
comparisons, with \(j\) as the winner and \(i\) as the loser:

\[
\mathcal{W}_{j} = \{l\in \mathcal{D}|j\in A_{l},c_{l} = j\} ,\qquad \mathcal{L}_{i} = \{l\in \mathcal{D}|i\in A_{l},c_{l}\neq i\} .
\]

So their intersection for \(i\neq j\) gives all situations where \(i,j\)
are compared and \(j\) wins, i.e.,
\(\mathcal{W}_{j}\cap \mathcal{L}_{i} = \{l\in \mathcal{D}|i,j\in A_{l},c_{l} = j\}\)
. Define the transition matrix \(P\) with transition probability

\[
P_{ij} = \left\{ \begin{array}{ll}\frac{1}{d}\sum_{l\in \mathcal{W}_{j}}\mathcal{L}_{i}\frac{1}{f(A_{l})}, & \text{if} i\neq j, \\ 1 - \sum_{k:k\neq i}P_{ik}, & \text{if} i = j. \end{array} \right.
\]

Here, \(d\) is chosen to be large enough so that the diagonal element is
non- negative, but not too large to give enough transition probability.
When the comparison graph is random, we choose \(d\) to make non-
negative diagonal elements with probability approaching 1 by studying
the concentration inequality for \(\sum_{k:k\neq i}P_{i k}\) . Here,
\(f(A_{l}) > 0\) is a weighting function to encode the total information
in the \(l\) - th comparison. A natural choice is \(f(A_{l}) = |A_{l}|\)
giving more weight to hyper- edges with a smaller number of compared
items. We will discuss later the optimal choice of \(f(\cdot)\) .When
\(i\neq j\) , \(P_{i j}\) can also be written as

When \(i\neq j\) \(P_{i j}\) can also be written as

\[
P_{i j} = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})1(c_{l} = j)\frac{1}{f(A_{l})}
\]

Conditioning on \(\mathcal{G}\) , the population transition is

\[
P_{i j}^{*} = E[P_{i j}|\mathcal{G}] = \left\{ \begin{array}{l l}{\frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\frac{e^{\theta_{j}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\frac{1}{f(A_{l})},} & {\mathrm{if~}i\neq j,}\\ {1 - \sum_{k:k\neq i}P_{i k}^{*},} & {\mathrm{if~}i = j.} \end{array} \right.
\]

Let

\[
\pi^{*} = (e^{\theta_{1}^{*}},\ldots ,e^{\theta_{n}^{*}}) / \sum_{k = 1}^{n}e^{\theta_{k}^{*}}.
\]

Note that both \(\sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) and \(f(A_{l})\)
in the denominator are symmetric with respect to
\(\theta_{i}^{*},\theta_{j}^{*}\) as long as both \(i,j\) belong to
\(A_{l}\) . So we have
\(P_{i j}^{*}\pi_{i}^{*} = P_{i j}^{*}\pi_{j}^{*}\) . This is the so-
called detailed balance that leads to \(\pi^{*}\) being the stationary
measure of the Markov chain with the above population transition for any
\(f(\cdot)\) . That is \(\pi^{*}^{\top}P^{*} = \pi^{*}^{\top}\) ,
namely, \(\pi^{*}\) is the top- left eigenvector of \(P^{*}\)

The spectral method estimates \(\pi^{*}\) by using the stationary
measure \(\widehat{\pi}\) of the empirical transition \(P\) , namely,

\[
\widehat{\pi}^{\top}P = \widehat{\pi}^{\top}.
\]

Note that if we consider the directed graph induced by \(P\) to be
strongly connected, this implies that the Markov chain it generates will
be ergodic, which ensures the existence of a unique stationary
distribution \(\widehat{\pi}\) as defined above. Consider the toy
example in Figure 1, if we naively choose \(f(\cdot) = 1\) as a constant
weighting function, it is not hard to count the times that \(j\) beats
\(i\) and fill the value into the transition matrix \(P_{i j}\) (divided
by \(d\) ). In the right panel, the transition probabilities are
calculated with \(d = 6\) to guarantee the self- loop transition happens
with a positive probability. For this \(P\) , the stationary
distribution is
\(\widehat{\pi} = (0.199,0.531,0.796,0.199,0.066)^{\top}\) , meaning
that the estimated ranking of preference scores of the 5 products are
\(3\succ 2\succ 1 = 4\succ 5\)

Finally given the identifiability condition of
\(1^{\top}\theta^{*} = 0\) , we can estimate \(\theta_{i}^{*}\) by

\[
\widehat{\theta}_{i}\coloneqq \log \widehat{\pi}_{i} - \frac{1}{n}\sum_{k = 1}^{n}\log \widehat{\pi}_{k}. \tag{2.1}
\]

It is worth mentioning that the spectral estimator is easier to compute
in practice, by only requiring one- step eigen- decomposition. Indeed,
we need only the eigenvector that corresponds to the largest eigenvalue,
which can even be computed very fast by the power method. In comparison,
the MLE is typically computationally heavier in terms of data storage
and step size determination during the implementation of the gradient
descent algorithm.

\section{3 Ranking Inference
Methodology}\label{ranking-inference-methodology}

3 Ranking Inference MethodologyIn this section, we study the inference
methodology for the spectral estimator for the underlying scores
\(\{\theta_{i}^{*}\}_{i\in [n]}\) of \(n\) items. To be specific, we
need to establish the statistical convergence rates and asymptotic
normality for \(\widetilde{\theta_{i}}\) .

\section{3.1 Uncertainty quantification with fixed comparison
graph}\label{uncertainty-quantification-with-fixed-comparison-graph}

For the estimation of \(\pi^{*}\) , we use the following two
approximations, which we will justify later to be accurate enough so as
not to affect the asymptotic variance. Let us first focus on our
intuition. Firstly, we have

\[
\widehat{\pi}_{i} = \frac{\sum_{j:j\neq i}P_{ji}\widehat{\pi}_{j}}{\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*}}{\sum_{j:j\neq i}P_{ij}} \eqqcolon \bar{\pi}_{i}.
\]

Equivalently,

\[
\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\approx \frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}(P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*})}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}. \tag{3.1}
\]

Secondly, the denominator above can be approximated by its expected
value so that (3.1) can further be approximated as

\[
J_{i}^{*}\coloneqq \frac{\sum_{j:j\neq i}(P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}})}{\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}}}, \tag{3.2}
\]

by using \(\pi_{i}^{*}\propto e^{\theta_{i}^{*}}\) . We will rigorously
argue that the asymptotic distributions of
\(\frac{\widehat{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and
\(J_{i}^{*}\) are identical. For now, let us look at the asymptotic
distribution of \(J_{i}^{*}\) . Obviously, it is mean zero due to the
detailed balance:
\(E[P_{ji}|\mathcal{G}]\pi_{j}^{*} = E[P_{ij}|\mathcal{G}]\pi_{i}^{*}\)
. The denominator of \(J_{i}^{*}\) is a constant and can be explicitly
written out as follows:

\[
\tau_{i}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]e^{\theta_{i}^{*}} = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(1 - \frac{e^{\theta_{i}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\right)\frac{e^{\theta_{i}^{*}}}{f(A_{l})}. \tag{3.3}
\]

Thus, \(J_{i}^{*}\) can be expressed as

\[
J_{i}^{*} = \frac{1}{d\tau_{i}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f(A_{l})}\left(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\right)\eqqcolon \frac{1}{d}\sum_{l\in \mathcal{D}}J_{i l}(\theta^{*}), \tag{3.4}
\]

where \(\tau_{i}\) is short for \(\tau_{i}(\theta^{*})\) . Since each
\((c_{l},A_{l})\) is independent in the fixed graph setting (see Remark
2.1 for discussions), the variance of \(J_{i}^{*}\) is

\[
\begin{array}{r l} & {\mathrm{~\gamma~}_{i}^{*}|\mathcal{G}) = \frac{1}{d^{2}\tau_{i}^{2}}\sum_{l\in \mathcal{D}}\frac{1(i\in A_{l})}{f^{2}(A_{l})}\cdot \mathrm{Var}\bigg(1(c_{l} = i)\sum_{u\in A_{l},u\neq i}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}\sum_{u\in A_{l},u\neq i}1(c_{l} = u)\bigg)}\\ & {\quad = \bigg(\sum_{l\in \mathcal{D}}1(i\in A_{l})\frac{(\sum_{u\in A_{l}}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}})e^{\theta_{i}^{*}}}{f(A_{l})^{2}}\bigg)\bigg / \bigg[\sum_{l\in \mathcal{D}}1(i\in A_{l})\bigg(\frac{\sum_{u\in A_{l}}e^{\theta_{u}^{*}} - e^{\theta_{i}^{*}}}{\sum_{u\in A_{l}}e^{\theta_{u}^{*}}}\bigg)\frac{e^{\theta_{i}^{*}}}{f(A_{l})}\bigg]^{2}} \end{array} \tag{3.5}
\]

A few important comments are in order. Firstly, the function \(f\)
achieves the minimal variance in (3.5) when
\(\begin{array}{r}{f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}} \end{array}\)
due to simply applying the Cauchy- Schwarz inequality. Actually,

Maystre and Grossglauser (2015) showed that when
\(\begin{array}{r}f(A_l) = \sum_{u\in A_l}e^{\theta_u^*} \end{array}\) ,
spectral method estimator converges to the MLE up to the first order.
Secondly, under the situation of pairwise comparison in the BTL model,
each \((c_l,A_l)\) is independent and we assume in \(\mathcal{D}\) each
pair \((i,j)\) is either compared for \(L\) times (denoted as
\(\widetilde{A}_{ij} = 1\) ) or never compared (denoted as
\(\widetilde{A}_{ij} = 0\) ). Further assuming
\(f(A_{l}) = |A_{l}| = 2\) , we have

\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \frac{1}{L}\bigg(\sum_{j:j\neq i}\widetilde{A}_{ij}e^{\theta_i^*}e^{\theta_j^*}\bigg)\bigg / \bigg[\sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{e^{\theta_i^*} + e^{\theta_j^*}}\bigg]^2.
\]

This exactly matches with Proposition 4.2 of Gao et al.~(2021). In
addition, if we choose \(f(A_{l}) =\)
\(\textstyle \sum_{u\in A_l}e^{\theta_u^*}\) , we get the most efficient
variance just like the MLE variance given in Proposition 4.1 of Gao et
al.~(2021), which is

\[
\operatorname {Var}(J_i^* |\mathcal{G}) = \left(L\cdot \sum_{j:j\neq i}\widetilde{A}_{ij}\frac{e^{\theta_i^*}e^{\theta_j^*}}{(e^{\theta_i^*} + e^{\theta_j^*})^2}\right)^{-1}.
\]

With the above discussion and computation, after some additional
derivations, we come to the conclusion that
\(\widetilde{\theta}_{i} - \theta_{i}^{*}\) has the same asymptotic
distribution as
\(\frac{\widetilde{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}}\) and
\(J_{i}^{*}\) . Therefore,

\[
\operatorname {Var}(J_i^* |\mathcal{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]

for all \(i\in [n]\) . Based on this result, we can make inference for
\(\widetilde{\theta}_{i}\) and additionally the rank of item \(i\) (see
Section 3.3). The rigorous derivations for this conclusion will be
provided in Section 4.

\section{3.2 Uncertainty quantification for the PL
model}\label{uncertainty-quantification-for-the-pl-model}

In this section, we consider the case of a random comparison graph,
which could potentially lead to dependent \((c_l,A_l)\) , unlike the
case of the fixed graph in the previous section. Note that since the
random comparison graph generation can be arbitrary, we cannot work with
each case. As an illustrating example, we consider the classical PL
model from the Erdos- Renyi graph here for two reasons. Firstly, this is
the most popularly studied random comparison model in the ranking
literature (Chen and Suh, 2015; Chen et al., 2022; Han et al., 2020; Liu
et al., 2022; Gao et al., 2021; Fan et al., 2022a,b). Secondly, we can
use the model to verify the uncertainty quantification of the spectral
method and compare it with that of the MLE. It turns out the model is
good enough to give us new insights. To further simplify the discussion
and presentation, we will only focus on \(M = 3\) in the PL model.
Results for general \(M\) can be similarly derived with the same
conclusion.

With the PL model, we can write down the specific variance of
\(J_{i}^{*}\) . Consider the most natural way to encode a 3- way
comparison. Say one ranks \((i,j,k)\) as \(i\vdash j\vdash k\) where
\(a\vdash b\) means \(a\) is better than \(b\) . Motivated by the
likelihood function, which multiplies the probability of selecting \(i\)
as the best one from \(\{i,j,k\}\) and the probability of selecting
\(j\) next from \(\{j,k\}\) , we break this complete 3- way comparison
into two dependent comparison data: \((i,\{i,j,k\})\) and
\((j,\{j,k\})\) . We call this multi- level breaking, where in the first
level comparison of all three items, \(i\) is preferred, and in the
second level comparison of the remaining items, \(j\) is preferred. By
doing this, we can naturally link

and compare results with the MLE estimator. Azari Soufiani et al.~(2013)
also proposed other ways of breaking an \(M\) - way comparison into
pairwise comparisons, but different breaking methods will lead to
different dependent structures, which we do not intend to analyze one by
one in this work. So in the sequel, we only consider multi- way
breaking, motivated by the likelihood function, and leave the study of
other possible breaking methods to the future. We use
\(\widetilde{A}_{ijk} = 1\) or \(0\) to denote whether \((i,j,k)\) has
been compared for \(L\) times or is never compared.

Let us work on the multi- level breaking. Now the key difference is that
the induced comparison graph \(\mathcal{G}\) cannot be treated as fixed.
Instead, we condition on
\(\widetilde{\mathcal{G}} = \{\widetilde{A}_{ijk}\}\) . Similar to
(3.2), we have

\[
\frac{\bar{\pi}_{i} - \pi_{i}^{*}}{\pi_{i}^{*}} = \frac{\sum_{j:j\neq i}P_{ji}\pi_{j}^{*} - P_{ij}\pi_{i}^{*}}{\pi_{i}^{*}\sum_{j:j\neq i}P_{ij}}\approx \frac{\sum_{j:j\neq i}P_{ji}e^{\theta_{j}^{*}} - P_{ij}e^{\theta_{i}^{*}}}{\sum_{j:j\neq i}E[P_{ij}|\widetilde{\mathcal{G}}]e^{\theta_{i}^{*}}} \eqqcolon J_{i}^{*}. \tag{3.6}
\]

In the case of the random comparison graph, i.e.~conditioning on
\(\widetilde{\mathcal{G}}\) , we obtain

\[
P_{ij} = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq i,j}\widetilde{A}_{ijk}Z_{ijk}^{\ell}, \tag{3.7}
\]

where
\(Z_{ijk}^{\ell} = 1(y_{k\gamma >j > i}^{(\ell)} = 1) / f(\{i,j\}) + 1(y_{j\gamma >k}^{(\ell)} = 1) / f(\{i,j,k\}) + 1(y_{j\gamma k\gamma i}^{(\ell)} = 1) / f(\{i,j,k\})\)
. Here \(y_{i_1\gamma i_2\gamma i_3}^{(\ell)}\) is a binary variable
which equals to \(1\) when the event \(i_1\searrow i_2\searrow i_3\)
holds under the \(\ell\) - th comparison among items \(\{i_1,i_2,i_3\}\)
. Essentially, we need to collect all terms induced from the same
comparison into one term \(Z_{ijk}^{\ell}\) so that the summation is
always over independent terms.

We lightly abuse the notation of \(J_{i}^{*}\) although here the
expectation is conditioning on \(\widetilde{\mathcal{G}}\) instead of
\(\mathcal{G}\) used in the fixed graph case. Note that

\[
E[Z_{ijk}^{\ell}|\widetilde{\mathcal{G}} ] = \frac{e^{\theta_{k}^{*}}e^{\theta_{j}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}})f(\{i,j\})} +\frac{e^{\theta_{j}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})}.
\]

Using \(\sum_{j\neq k}a_{ijk} = \sum_{j< k}(a_{ijk} + a_{ikj})\) , the
denominator of \(J_{i}^{*}\) can be expressed as

\[
\begin{array}{r l} & {\tau_{i}^{\diamond}(\theta^{*})\coloneqq \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]e^{\theta_{i}^{*}} = \frac{L}{d}\sum_{j< k:j,k\neq i}\widetilde{A}_{i j k}e^{\theta_{i}^{*}}\Big(\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}})f(\{i,j\})}}\\ & {\qquad +\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})(e^{\theta_{i}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})} +\frac{e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}}}{(e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})f(\{i,j,k\})}\Big).} \end{array}
\]

Hence, the expression of \(J_{i}^{*}\) is given as follows:

\[
\begin{array}{r l} & {\mathcal{I}_{i}^{*} = \frac{1}{\tau_{i}^{\diamond}}\Big(\sum_{j:j\neq i}P_{j i}e^{\theta_{j}^{*}} - P_{i j}e^{\theta_{i}^{*}}\Big) = \frac{1}{d\tau_{i}^{\diamond}}\Big(\sum_{\ell = 1}^{L}\sum_{j:j\neq i}\sum_{k:k\neq i,j}\widetilde{A}_{i j k}(Z_{j i k}^{\ell}e^{\theta_{j}^{*}} - Z_{i j k}^{\ell}e^{\theta_{i}^{*}})\Big)}\\ & {\quad = \frac{1}{d\tau_{i}^{\diamond}}\sum_{\ell = 1}^{L}\sum_{j< k:j,k\neq i}\widetilde{A}_{i j k}(Z_{j i k}^{\ell}e^{\theta_{j}^{*}} + Z_{k i j}^{\ell}e^{\theta_{k}^{*}} - Z_{i j k}^{\ell}e^{\theta_{i}^{*}} - Z_{i k j}^{\ell}e^{\theta_{i}^{*}}) = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{j< k:j,k\neq i}J_{i j k\ell}(\theta^{*}),} \end{array} \tag{3.8}
\]

where \(\tau_{i}^{\diamond}\) is short for
\(\tau_{i}^{\diamond}(\theta^{*})\) . Since each 3- way comparison is
independent, it can be shown that the variance of \(J_{i}^{*}\) is

\[
\widetilde{J}_{i}^{\diamond}(\widetilde{J}) = \frac{L}{d^{2}(\tau_{i}^{\diamond})^{2}}\sum_{j< k:j,k\neq i}\widetilde{A}_{ijk}e^{\theta_{i}^{*}}\Big(\frac{(e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}})}{f^{2}(\{i,j,k\})} +\frac{e^{\theta_{j}^{*}}e^{\theta_{k}^{*}}}{e^{\theta_{i}^{*}} + e^{\theta_{j}^{*}} + e^{\theta_{k}^{*}}}\Big(\frac{1}{f^{2}(\{i,k\})} +\frac{1}{f^{2}(\{i,j,k\})}\Big)\Big)
\]

The essential component is to compute \(EJ_{ijkl}(\theta^{*})^{2}\) due
to independence and zero- mean. For a given triplet \((i,j,k)\) , there
are 6 possible preference outcomes with probabilities governed by the PL
model. Averaging the squared random outcomes over 6 probabilities gives
\(EJ_{ijkl}(\theta^{*})^{2}\) , which results in the expression above.
We omit the details of these calculations.

Let us consider the simple situation that all \(\theta_{i}^{*}\) are
equal. In this case, if we apply the most efficient weighting function
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) , that is,
\(f(\{i,j,k\}) = 3\) , \(f(\{i,j\}) = f(\{i,k\}) = 2\) , we have
\(\mathrm{Var}(J_i^* |\widetilde{G}) = 18 / (7L)\) . However, if we
naively choose \(f\) as a constant function, we get
\(\mathrm{Var}(J_i^* |\widetilde{G}) = 8 / (3L)\) , which is indeed
larger. It is also worth noting that when we choose
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) , the
aforementioned variance matches with the variance of MLE in Fan et
al.~(2022b).

With the above formula of \(\mathrm{Var}(J_i^* |\widetilde{G})\) for the
PL model, we can also conclude that

\[
\mathrm{Var}(J_i^* |\widetilde{G})^{-1 / 2}(\widetilde{\theta}_i - \theta_i^*)\Rightarrow N(0,1),
\]

for all \(i\in [n]\) . The rigorous arguments will be introduced in
Section 4.

\section{3.3 Ranking inference: one-sample confidence
intervals}\label{ranking-inference-one-sample-confidence-intervals}

In numerous practical applications, individuals frequently interact with
data and challenges related to rankings. The prevalent approach to
utilizing rankings typically revolves around computing preference scores
and then showcasing these scores in ranked order. These only provide
first- order information on ranks and can not answer many questions,
such as:

How do we ascertain with high confidence that an item's true rank is
among the top- 3 (or general \(K,K\geq 1\) ) choices? And how can we
establish a set of candidates with high confidence, guaranteeing that
the true top- 3 candidates are not overlooked? How do we analyze if the
ranking preferences for a given array of products are consistent in two
distinct communities (such as male and female) or the same community but
at two different time periods?

In sum, there is a need for tools and methodologies that address these
and other insightful queries in real- world applications involving
rankings, especially when the comparisons are drawn from a general
comparison graph.

Within this section, we first present a comprehensive framework designed
for the construction of two- sided confidence intervals for ranks. In
endeavoring to establish simultaneous confidence intervals for the
ranks, an intuitive methodology entails deducing the asymptotic
distribution of the empirical ranks, denoted as
\(\widetilde{r}_{m},m\in \mathcal{M}\) , and subsequently determining
the critical value. However, it is well known that this task poses
substantive challenges, given that \(\widetilde{r}_{m}\) is an integer
and is intrinsically dependent on all estimated scores, making its
asymptotic behavior daunting to analyze.

By capitalizing on the inherent interdependence between the scores and
their corresponding ranks, we discern that the task of formulating
confidence intervals for the ranks can be effectively converted to the
construction of simultaneous confidence intervals for the pairwise
differences among the population scores. It is notable that the
distribution of these empirical score differences is more amenable to
characterization. Consequently, we focus on the statistical properties
of the estimated scores \(\widetilde{\theta}_{m} \in [n]\) and present
our methodology for constructing two- sided (simultaneous) confidence
intervals for ranks through estimated score differences.

Example 3.1. We let \(\mathcal{M} = \{m\}\) , where \(1 \leq m \leq n\)
, to represent the item under consideration. We are interested in the
construction of the \((1 - \alpha) \times 100\%\) confidence interval
for the true population rank \(r_{m}\) , where \(\alpha \in (0,1)\)
denotes a pre- specified significance level. Suppose that we are able to
construct the simultaneous confidence intervals
\([\mathcal{C}_L(k,m), \mathcal{C}_U(k,m)], k \neq m, (k \in [n])\) for
the pairwise differences
\(\theta_{k}^{*} - \theta_{m}^{*}, k \neq m (k \in [n])\) , with the
following property:

\[
\mathbb{P}\Big(\mathcal{C}_L(k,m) \leq \theta_k^* - \theta_m^* \leq \mathcal{C}_U(k,m) \text{for all} k \neq m\Big) \geq 1 - \alpha . \tag{3.9}
\]

One observes that if \(\mathcal{C}_U(k,m) < 0\) (respectively,
\(\mathcal{C}_L(k,m) > 0\) ), it implies that
\(\theta_k^* < \theta_m^*\) (respectively, \(\theta_k^* > \theta_m^*\)
). Enumerating the number of items whose scores are higher than item
\(m\) gives a lower bound for rank \(r_{m}\) , and vice versa. In other
words, we deduce from (3.9) that

\[
\mathbb{P}\left(1 + \sum_{k \neq m} 1 \{C_L(k,m) > 0\} \leq r_m \leq n - \sum_{k \neq m} 1 \{C_U(k,m) < 0\}\right) \geq 1 - \alpha . \tag{3.10}
\]

This yields a \((1 - \alpha) \times 100\%\) confidence interval for
\(r_{m}\) , and our task reduces to construct simultaneous confidence
intervals for the pairwise differences (3.9).

We now formally introduce the procedure to construct the confidence
intervals for multiple ranks \(\{r_m\}_{m \in \mathcal{M}}\)
simultaneously. Motivated by Example 3.1, the key step is to construct
the simultaneous confidence intervals for the pairwise score differences
\(\{\theta_k^* - \theta_m^*\}_{m \in \mathcal{M}, k \neq m}\) such that
(3.9) holds. To this end, we let

\[
T_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{\widetilde{\theta}_k - \widetilde{\theta}_m - (\theta_k^* - \theta_m^*)}{\widetilde{\sigma}_{km}} \right|, \tag{3.11}
\]

where \(\{\widetilde{\sigma}_{km}\}_{k \neq m}\) is a sequence of
positive normalization given by (3.13) below. For any
\(\alpha \in (0,1)\) , let \(Q_{1 - \alpha}\) be critical value such
that \(\mathbb{P}(T_{\mathcal{M}} \leq Q_{1 - \alpha}) \geq 1 - \alpha\)
. Then, as in Example 3.1, our \((1 - \alpha) \times 100\%\)
simultaneous confidence intervals for \(\{r_m\}_{m \in \mathcal{M}}\)
are given by \(\{[R_{mL}, R_{mU}] \}_{m \in \mathcal{M}}\) , where

\[
= 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m > \widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right), \quad R_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_k - \widetilde{\theta}_m < -\widetilde{\sigma}_{km} \times Q_{1 - \alpha}\right).
\]

\section{3.4 Multiplier bootstrap
procedure}\label{multiplier-bootstrap-procedure}

The key step for constructing the confidence interval of ranks of
interest is to pick the critical value \(Q_{1 - \alpha}\) . To calculate
the critical value above, we propose to use the wild bootstrap
procedure. The

uncertainty quantification for the spectral estimator in (3.2) reveals
that
\(\widetilde{\theta_{i}} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\)
uniformly over \(i \in [n]\) (see details in Section 4), which further
implies that asymptotically

\[
T_{\mathcal{M}} \approx \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{J_{k}(\theta^{*}) - J_{m}(\theta^{*})}{\widetilde{\sigma}_{km}} \right|. \tag{3.12}
\]

We focus on the fixed graph setting and leave the random graph setting
in Remark 3.2 below. Practically, the empirical version of
\(J_{i}(\theta^{*})\) can be obtained via plugging in the spectral
estimator \(\widetilde{\theta}\) , namely from (3.4),

\[
J_{i}(\widetilde{\theta}) = \frac{1}{d} \sum_{l \in \mathcal{D}} J_{il}(\widetilde{\theta}), \quad i \in [n].
\]

Let
\(\sigma_{km}^{2} = \operatorname {Var}\{J_{k}(\theta^{*}) - J_{m}(\theta^{*}) | \mathcal{G} \}\)
for each \(k \neq m\) . Then our estimator for \(\sigma_{km}^{2}\) is
defined by

\[
\widetilde{\sigma}_{km}^{2} = \frac{e^{\widetilde{\theta}_{k}}}{d^{2} \tau_{k}^{2}(\widetilde{\theta})} \sum_{l \in \mathcal{D}} \frac{1(k \in A_{l})}{f^{2}(A_{l})} \left(\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}} - e^{\widetilde{\theta}_{k}}\right) + \frac{e^{\widetilde{\theta}_{m}}}{d^{2} \tau_{m}^{2}(\widetilde{\theta})} \sum_{l \in \mathcal{D}} \frac{1(m \in A_{l})}{f^{2}(A_{l})} \left(\sum_{j \in A_{l}} e^{\widetilde{\theta}_{j}} - e^{\widetilde{\theta}_{m}}\right), \tag{3.13}
\]

where \(\tau_{k}(\widetilde{\theta})\) and
\(\tau_{m}(\widetilde{\theta})\) also plug in \(\widetilde{\theta}\) ;
see (3.5). Let
\(\omega_{1}, \ldots , \omega_{|\mathcal{D}|} \in \mathbb{R}\) be i.i.d.
\(N(0,1)\) random variables. The Gaussian multiplier bootstrap statistic
is then defined by

\[
G_{\mathcal{M}} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l} \right|. \tag{3.14}
\]

Let
\(\mathbb{P}^{*}(\cdot) = \mathbb{P}(\{|(e_{i}, A_{i})\}_{i \in \mathcal{D}})\)
denote the conditional probability. Then, for \(\alpha \in (0,1)\) , our
estimator for \(Q_{1 - \alpha}\) is defined by the \((1 - \alpha)\) th
conditional quantile of \(G_{\mathcal{M}}\) , namely

\[
\mathcal{Q}_{1 - \alpha} = \inf \{z: \mathbb{P}^{*}(G_{\mathcal{M}} \leq z) \geq 1 - \alpha \} ,
\]

which can be computed by the Monte Carlo simulation. Then, our
simultaneous confidence intervals
\(\{[\mathcal{R}_{mL}, \mathcal{R}_{mU}] \}_{m \in \mathcal{M}}\) are
given by

\[
\mathcal{R}_{mL} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right), \qquad \mathcal{R}_{mU} = n - \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} < -\widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}\right).
\]

Remark 3.1 (One- sample one- sided confidence intervals). Now we provide
details on constructing simultaneous one- sided intervals for population
ranks. For one- sided intervals, the overall procedure is similar to
constructing two- sided confidence intervals. Specifically, let

\[
G_{\mathcal{M}}^{\circ} = \max_{m \in \mathcal{M}} \max_{k \neq m} \frac{1}{d \sigma_{km}} \sum_{l \in \mathcal{D}} \{J_{kl}(\widetilde{\theta}) - J_{ml}(\widetilde{\theta})\} \omega_{l}, \tag{3.16}
\]

where \(\omega_{1}, \ldots , \omega_{|\mathcal{D}|}\) are as before
i.i.d. \(N(0,1)\) random variables. Correspondingly, let
\(\mathcal{Q}_{1 - \alpha}^{\circ}\) be its \((1 - \alpha)\) th
quantile. Then the \((1 - \alpha) \times 100\%\) simultaneous lower
confidence bounds for \(\{r_{m}\}_{m \in \mathcal{M}}\) are given by
\(\{[\mathcal{R}_{mL}^{ \circ }, n] \}_{m \in \mathcal{M}}\) , where

\[
\mathcal{R}_{mL}^{\circ} = 1 + \sum_{k \neq m} 1 \left(\widetilde{\theta}_{k} - \widetilde{\theta}_{m} > \widetilde{\sigma}_{km} \times \mathcal{Q}_{1 - \alpha}^{\circ}\right). \tag{3.17}
\]

Remark 3.2 (Ranking inference for the PL model with random comparison
graph). Section 3.2 reveals that
\(\widetilde{\theta}_{i} - \theta_{i}^{*} \approx J_{i}(\theta^{*})\)
uniformly over \(i \in [n]\) , where following (3.8),

\[
J_{i}(\theta^{*}) = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{j < s:j, s \neq i} J_{ijs\ell}(\theta^{*}).
\]

In order to carry out ranking inference for the PL model, we need to
rewrite this equation in a slightly different format. Let
\(\begin{array}{r}{\mathcal{N} = \sum_{i< j< k}\widetilde{A}_{i j k}} \end{array}\)
denote the total number of connected components on the random graph
\(\widetilde{G}\) and write \(\{(i,j,k):i< j< k\) and
\(\widetilde{A}_{i j k} = 1\} \eqqcolon \{\widetilde{A}_{q}\}_{q = 1,\ldots ,\mathcal{N}}\)
. Let \(y_{q}^{(\ell)}\) denote the \(\ell\) - th full- ranking
comparison result for \(A_{q}\) . Then we can rewrite \(P_{ij}\) as

\[
P_{ij} = \frac{1}{d} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \sum_{k \neq i, j} 1\{(i,j,k) = \widetilde{A}_{q}\} Z_{ijkq}^{(\ell)}, i \neq j,
\]

where for \(i\neq j\neq k\) and \(q\in \lfloor \mathcal{N}\rfloor\) ,
and
\(Z_{i j k q}^{(\ell)} = 1\{y_{q}^{(\ell)} = (k\cdot \gamma \cdot j\cdot \gamma \cdot i)\} /f(\{i,j\}) + (1\{y_{q}^{(\ell)} = (j\cdot \gamma \cdot i)\} /f(\{i,j,k\})\)
\(k)\} +1\{y_{q}^{(\ell)} = (j\cdot k\cdot \gamma \cdot i)\} /f(\{i,j,k\})\)
. It is straightforward to verify that this \(P_{ij}\) is exactly the
same with (3.7). Therefore, we rewrite
\(\begin{array}{r}{J_{i}(\theta^{*}) = d^{- 1}\sum_{\ell = 1}^{L}\sum_{q = 1}^{N}J_{i q\ell}^{\diamond}(\theta^{*})} \end{array}\)
, where

\[
J_{iq\ell}^{\diamond}(\theta^{*}) = \sum_{j < s:j, s \neq i} 1\{(i,j,s) = \widetilde{A}_{q}\} J_{iq\ell}^{\diamond}(\theta^{*}). \tag{3.18}
\]

As is assumed,
\(\{J_{iq\ell}^{\diamond}(\theta^{*})\}_{\ell \in [L], q \in [\mathcal{N}]}\)
are independent for each \(i \in [n]\) conditioning on the comparison
graph \(\widetilde{G}\) . Let
\(\{\omega_{q\ell}^{\diamond}\}_{q, \ell \in \mathbb{N}}\) be i.i.d.
\(N(0,1)\) random variables. Then, following (3.14), the corresponding
bootstrap test statistic is given by

\[
G_{\mathcal{M}}^{\diamond} = \max_{m \in \mathcal{M}} \max_{k \neq m} \left| \frac{1}{d \sigma_{km}^{\diamond}} \sum_{\ell = 1}^{L} \sum_{q = 1}^{N} \{J_{kq\ell}^{\diamond}(\widetilde{\theta}) - J_{mq\ell}^{\diamond}(\widetilde{\theta})\} \omega_{q\ell} \right|,
\]

where \(\{\widetilde{\sigma}_{km}^{\diamond}\}_{k \neq m}\) are as
before the sequence of positive normalization, calculated as the sum of
the variance of \(J_{k}(\theta^{*})\) and \(J_{m}(\theta^{*})\) similar
to (3.13). Consequently, the simultaneous confidence intervals for the
ranks can be similarly constructed.

\section{3.5 Ranking inference: two-sample and one-sample testing
applications}\label{ranking-inference-two-sample-and-one-sample-testing-applications}

In this section, we further illustrate how we may apply our inference
methodology to a few salient testing applications, in both one- sample
and two- sample testing.

Example 3.2 (Testing top- \(K\) placement). Let \(\mathcal{M} = \{m\}\)
for some \(m \in [n]\) and let \(K \geq 1\) be a prescribed positive
integer. Our objective is to ascertain if the item \(m\) is a member of
the top- \(K\) ranked items. Consequently, we shall examine the
following hypotheses:

\[
H_{0}:r_{m}\leq K\mathrm{~versus~}H_{1}:r_{m} > K. \tag{3.19}
\]

Based on the one- sided confidence interval
\([\mathcal{R}_{mL}^{\circ}, n]\) in (3.17), for any
\(\alpha \in (0,1)\) , a level \(\alpha\) test for (3.19) is simply
given by \(\phi_{m,K} = 1\{\mathcal{R}_{mL}^{\circ} > K\}\) . Under the
conditions of Theorem E.1, we have
\(\mathbb{P}(\phi_{m,K} = 1|H_{0}) \leq \alpha + \mathrm{o}(1)\) , that
is, the effective control of the Type- I error can be achieved below the
significant level \(\alpha\) when the null hypothesis is true.

Example 3.3 (Top- \(K\) sure screening set). Another example is on
constructing a screened candidate set that contains the top- \(K\) items
with high probability. This is particularly useful in college candidate
admission or company hiring decisions. Oftentimes, a university or a
company would like to design certain admission or hiring policy with the
high- probability guarantee of the sure screening of true top- \(K\)
candidates.

Let \(\mathcal{K} = \{r^{- 1}(1),\ldots ,r^{- 1}(K)\}\) denote the top-
\(K\) ranked items of the rank operator \(r:[n]\to [n]\) . We aim at
selecting a set of candidates \(\widehat{\mathcal{I}}_K\) which contains
the top- \(K\) candidates with a prescribed probability. Mathematically,
this requirement can be expressed as
\(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\)
, where \(\alpha \in (0,1)\) . Herein, we define \(\mathcal{M} = [n]\) ,
and let \(\{[\mathcal{R}_{mL}^{\circ},n],m\in [n]\}\) represent the set
of \((1 - \alpha)\times 100\%\) simultaneous left- sided confidence
intervals, as given in (3.17). It is easy to observe that the inequality
\(\mathcal{R}_{mL}^{\circ} > K\) infers that \(r_m > K\) . Consequently,
a selection for \(\widehat{\mathcal{I}}_K\) , that satisfies the
probability constraint
\(\mathbb{P}(\mathcal{K}\subseteq \widehat{\mathcal{I}}_K)\geq 1 - \alpha\)
, is given by

\[
\widehat{\mathcal{I}}_K = \{m\in [n]:\mathcal{R}_{mL}^{\circ}\leq K\} .
\]

Example 3.4 (Testing ranks of two samples). In many applications, we are
concerned with the question of whether the ranks of certain items using
two samples have been changed or preserved. For example, we may care
about whether

\begin{itemize}
\tightlist
\item
  Ranking allocation differs before and after a treatment or policy
  change.- Different communities such as males versus females can have
  different ranking preferences over the same set of products.- People's
  perceived preferences over the same things have changed in two time
  periods.
\end{itemize}

Suppose we observe two independent datasets \(\mathcal{D}_1\) and
\(\mathcal{D}_2\) with preference scores
\(\theta_{[1]}^{*} = (\theta_{11}^{*},\ldots ,\theta_{1n}^{*})^{\top}\)
and
\(\theta_{[2]}^{*} = (\theta_{21}^{*},\ldots ,\theta_{2n}^{*})^{\top}\)
. The associated true rankings are respectively denoted by

\[
r_{[1]} = (r_{11},\ldots ,r_{1n})^{\top} \text{and} r_{[2]} = (r_{21},\ldots ,r_{2n})^{\top}.
\]

Given any \(m\in [n]\) , we are interested in testing whether the same
rank is preserved for item \(m\) across these two samples, that is,
testing the hypotheses

\[
H_{0}:r_{1m} = r_{2m} \text{versus} H_{1}:r_{1m}\neq r_{2m} \tag{3.20}
\]

To this end, firstly we construct simultaneous confidence intervals
\([R_{1mL},R_{1mU}]\) and \([R_{2mL},R_{2mU}]\) such that

\[
\mathbb{P}(r_{1m}\in [R_{1mL},R_{1mU}]\text{and} r_{2m}\in [R_{2mL},R_{2mU}])\geq 1 - \alpha . \tag{3.21}
\]

Then our \(\alpha\) - level test for (3.20) is defined by

\[
\phi_{m} = 1\{|[R_{1mL},R_{1mU}]\cap [R_{2mL},R_{2mU}]| = 0\} .
\]

It is straightforward to verify that
\(\mathbb{P}(\phi_{m} = 1|H_{0})\geq 1 - \alpha\) .

Example 3.5 (Testing top- \(K\) sets of two samples). Besides testing
for a single or a few ranks, one may want to evaluate whether two top-
\(K\) sets are identical or not, between two groups of people, two
periods of time, or before and after a significant event or change. Let
\(\mathcal{S}_{1K} = \{r_{[1]}^{- 1}(1),\ldots ,r_{[1]}^{- 1}(K)\}\) and
\(\mathcal{S}_{2K} = \{r_{[2]}^{- 1}(1),\ldots ,r_{[2]}^{- 1}(K)\}\)
denote the sets of top- \(K\) ranked items, respectively. We consider
testing the hypotheses

\[
H_{0}:S_{1K} = S_{2K}\mathrm{~versus~}H_{1}:S_{1K}\neq S_{2K}. \tag{3.22}
\]

For \(\alpha \in (0,1)\) , we begin with constructing
\((1 - \alpha)\times 100\%\) simultaneous confidence sets
\(\widehat{\mathcal{I}}_{1K}\) and \(\widehat{\mathcal{I}}_{2K}\) for
\(S_{1K}\) and \(S_{2K}\) such that

\[
\mathbb{P}\left(S_{1K}\subset \widehat{\mathcal{I}}_{1K}\mathrm{~and~}S_{2K}\subset \widehat{\mathcal{I}}_{2K}\right)\geq 1 - \alpha . \tag{3.23}
\]

Then our \(\alpha\) - level test for (3.22) is defined by

\[
\widetilde{\phi}_{K} = 1\{|\widehat{\mathcal{I}}_{1K}\cap \widehat{\mathcal{I}}_{2K}|< K\} .
\]

Remark 3.3. Several methodologies, including the Bonferroni adjustment
(which constructs a \((1 - \alpha /2)\times 100\%\) confidence interval
for each source), and Gaussian approximation (achieved by taking the
maximum of the test statistics of each source), enable us to establish
simultaneous confidence intervals as illustrated in equations (3.21) and
(3.23). To maintain clarity and simplicity in the subsequent context, we
simply employ the Bonferroni adjustment for two samples. Moreover, the
framework outlined in Examples 3.4 and 3.5 can be extended in a
straightforward way to evaluate whether the ranks of items or sets are
identical across three or more sources.

\section{4 Theoretical Justifications}\label{theoretical-justifications}

In this section, we rigorously justify the conclusions in Section 3 and
explicitly lay out the necessary assumptions to arrive at those
conclusions. The first assumption is to make sure we are comparing
\(\theta_{i}^{*}\) 's in the same order in a meaningful way. Otherwise,
we can always group items into categories with similar qualities and
then work on each sub- group or screen some extreme items. In addition,
as we have discussed, we need an identifiability condition for
\(\theta^{*}\) .

Assumption 4.1. There exists some positive constant
\(\bar{\kappa} < \infty\) such that

\[
\max_{i\in [n]}\theta_{i}^{*} - \min_{i\in [n]}\theta_{i}^{*}\leq \bar{\kappa}.
\]

In addition, for identifiability, assume \(1^{\top}\theta^{*} = 0\) .

In Assumption 4.1, we assume \(\bar{\kappa}\) is finite, indicating we
only rank items with preference scores on the same scale. If
\(\bar{\kappa}\) is diverging, some items will be trivially more or less
favorable than others. In this case, it is typically easy in practice to
separate the items into subgroups with similar preference scores, and
then we can conduct ranking inference within each group. Although we
assume bounded \(\bar{\kappa}\) , it serves as the role of a condition
number whose effect has been made explicit in all our results for
interested readers. However, we do not claim this dependency is optimal
as our nontrivial analysis can easily encounter powers of
\(e^{\bar{\kappa}}\) , say in bounding the ratio of
\(\pi_{i}^{*} / \pi_{j}^{*}\) .

\section{4.1 Estimation accuracy and asymptotic normality with fixed
comparisons}\label{estimation-accuracy-and-asymptotic-normality-with-fixed-comparisons}

To derive the asymptotic distribution of the spectral estimator, we need
to rigorously justify the approximations (3.1) and (3.2). We first take
care of approximating (3.1) using (3.2), where all comparisons in
\(\mathcal{G}\) are assumed to be fixed. Note that

\[
P_{ij} - E[P_{ij}|\mathcal{G}] = \frac{1}{d}\sum_{l\in \mathcal{D}}1(i,j\in A_l)\left[1(c_l = j) - \frac{\pi_j^*}{\sum_{u\in A_l}\pi_u^*}\right]\frac{1}{f(A_l)}.
\]

Let \(Z_{A_l}^j = 1(c_l = j) / f(A_l)\) , which is bounded from above
and below as long as \(f\) is bounded from above and below. Furthermore,
each \(Z_{A_l}^j\) is independent. Therefore,
\(P_{ij} - E[P_{ij}|\mathcal{G}] = d^{- 1}\sum_{l\in \mathcal{D}}1(i,j\in A_l)[Z_{A_l}^j - E(Z_{A_l}^j)]\)
. By Hoeffding's inequality, conditioning on \(\mathcal{G}\) , we have
with a large probability \(1 - o(1)\) ,

\[
\max_{i\neq j}\left|P_{ij} - E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\ddagger}}.
\]

where
\(\begin{array}{r}{n^{\ddagger} = \max_{i\neq j}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})} \end{array}\)
is the maximum number of cases that each pair is compared. Similarly, we
can get the concentration bound for
\(\textstyle \sum_{j:j\neq i}P_{ij}\) . Since \(Z_{A_{l}}^{j}\) 's are
independent, another level of summation over \(j\) will lead to the
following. Again by Hoeffding's inequality, with a large probability
tending to 1, we obtain

\[
\max_{i}\left|\sum_{j:j\neq i}P_{ij} - \sum_{j:j\neq i}E[P_{ij}|\mathcal{G}]\right|\lesssim \frac{1}{d}\sqrt{(\log n)n^{\dagger}},
\]

where
\(\begin{array}{r}{n^{\dagger} = \max_{i}\sum_{l\in \mathcal{D}}1(i\in A_{l})} \end{array}\)
is the maximum number of cases that each item is compared. In addition,
we assume

\[
\sum_{j:j\neq i}E[P_{ij}|\mathcal{G}] = \tau_{i}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger},
\]

where \(\tau_{i}\) defined in (3.3) is the denominator of \(J_{i}^{*}\)
. This assumption makes sense as
\(\tau_{i}e^{- \theta_{i}^{*}}\lesssim \sum_{l\in \mathcal{D}}1(i\in A_{l}) / d\)
, and it states for each \(i\) the comparison graph cannot be too
asymmetric. Note that \(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\) can
still be widely different from \(n^{\ddagger}\) for different pair
\((i,j)\) . Since the expectation term dominates the deviation if
\(n^{\dagger}\gtrsim \log n\) , it is not hard to show that in (3.2),
changing the denominator by its expectation will only cause a small
order difference, which does not affect the asymptotic distribution.

Based on the above discussion, we impose the following assumption.

Assumption 4.2. In the case of a fixed comparison graph, we assume the
graph is connected,
\(\tau_{i}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for all
\(i\in [n]\) , \(e^{2\bar{\kappa}}\log n = o(n)\) and
\(e^{3\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^{1 / 2} = o(n^{\dagger})\)
.

The assumption is reasonable for a fixed comparison graph. If each pair
\((i,j)\) must be compared at least once, then every
\(\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\geq 1\) . If they are all in
the same order, then
\(\sum_{l\in \mathcal{D}}1(i\in A_{l}) = \sum_{j:j\neq i}\sum_{l\in \mathcal{D}}1(i,j\in A_{l})\)
should be indeed in the order of \(n^{\ddagger}n\) . Assumption 4.2
allows some pair \((i,j)\) to be never compared directly, so we need to
leverage the information from comparing \(i\)

and \(j\) to other items separately. Moreover, we also do not require
\(\sum_{l\in \mathcal{D}}1(i,j\in A_l)\) to be in the same order for any
\(i,j:i\neq j\) since we only require the maximum pairwise degree
\(n^{\ddagger}\) to satisfy Assumption 4.2. However, in the case of a
fixed graph, we do not have the randomness from the graph, and the graph
must be relatively dense to make sure we have enough information to rank
every item. This condition will be relaxed to
\(n^{\dagger}\gtrsim n^{\ddagger}\log n\) when we have a homogeneous
random comparison graph in Section 4.2. .

We need another technical condition on the structure of the comparison
graph. Define \(\Omega = \{\Omega_{ij}\}_{i\leq n,j\leq n}\) where
\(\Omega_{ij} = - P_{ji}\pi_j^*\) for \(i\neq j\) and
\(\Omega_{ii} = \sum_{j:j\neq i}P_{ij}\pi_i^*\) . Note that as we
derived above, \(E[\Omega_{ii}|\mathcal{G}]\) is in the order of
\(n^{\dagger} / (dn)\) . We hope to understand the order of its
eigenvalues. Since \(\Omega\) has the minimal eigenvalue equal to zero,
with the corresponding eigenvector \(\mathbf{1}\) , we only focus on the
space orthogonal to \(\mathbf{1}\) . Following the notation of Gao et
al.~(2021),

\[
\lambda_{\min ,\bot}(A) = \min_{\| v\| = 1,v^{\top}\mathbf{1} = 0}v^{\top}A v.
\]

Assumption 4.3. There exist \(C_1,C_2 > 0\) such that

\[
C_1e^{-\bar{\kappa}}\frac{n^\dagger}{dn}\leq \lambda_{\min ,\bot}(E[\Omega |\mathcal{G}])\leq \lambda_{\max}(E[\Omega |\mathcal{G}])\leq C_2e^{\bar{\kappa}}\frac{n^\dagger}{dn}, \tag{4.1}
\]

\[
\| \Omega -E[\Omega |\mathcal{G}]\| = o_{P}\left(\frac{n^{\dagger}}{dn}\right). \tag{4.2}
\]

When \(\bar{\kappa} = O(1)\) , Assumption 4.3 requires that all
eigenvalues (except the minimal one) of \(E[\Omega |\mathcal{G}]\) are
in the order of \(n^{\dagger} / (dn)\) and \(\Omega\) also shares this
same eigenvalue scale as \(E[\Omega |\mathcal{G}]\) . This assumption is
intuitively correct, as we have seen that
\(E[\Omega_{ij}]\lesssim n^{\ddagger} / (dn)\) for \(i\neq j\) and
\(E[\Omega_{ii}]\asymp n^{\dagger} / (dn)\) . We will also rigorously
show that this condition can be satisfied if we consider the PL model
(Theorem 4.3).

Theorem 4.1. Under Assumptions 4.1- 4.3, the spectral estimator
\(\widetilde{\theta_{i}}\) has the following uniform approximation:
\(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + \delta_{i}\) ,
uniformly for all \(i\in [n]\) , where
\(\| \delta \coloneqq (\delta_{1},\dots ,\delta_{n})\|_{\infty} = o(1 / \sqrt{n^{\dagger}})\)
with probability \(1 - o(1)\) .

To prove Theorem 4.1, we need to verify (3.1). We leave the detailed
proof in the appendix. Given Theorem 4.1, we can easily conclude the
next theorem following the properties of \(J_{i}^{*}\) , which lead to
the rate of convergence for \(\widetilde{\theta}\) as well as its
asymptotic normality.

Remark 4.1. The results of Theorem 4.1 and the following Theorems are
proved via Bernstein and Hoeffding type inequalities with union bound
over \(n\) items. Therefore, all of the high- probability terms hold
with probability \((1 - o(1))\) (similarly for \(o_{p}(\cdot)\) and
\(O_{p}(\cdot)\) ) mentioned in the main text equivalently hold with
probability in form of \(1 - O(n^{- \zeta})\) where \(\zeta \geq 2\) is
a positive integer (different choice of \(\zeta\) will only affect
constant terms in the involved concentration inequalities).

Theorem 4.2. Under Assumptions 4.1- 4.3, the spectral estimator (2.1)
satisfies that

\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\asymp \| J^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{n^{\dagger}}}, \tag{4.3}
\]

with probability \(1 - o(1)\) , where
\(J^{*} = (J_{1}^{*},\dots ,J_{n}^{*})\) with \(J_{i}^{*},i\in [n]\)
being defined in (3.4). In addition,

\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]

for all \(i\in [n]\) with

\[
\begin{array}{r}{\mathbf{\Phi}_{i}(\theta) = \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{\sum_{u\in A_{l}}e^{\theta_{u}}}\right)\frac{e^{\theta_{i}}}{f(A_{l})}\right] / \left[\sum_{l\in \mathcal{D}}1(i\in A_{l})\left(\frac{\sum_{u\in A_{l}}e^{\theta_{u}} - e^{\theta_{i}}}{f(A_{l})}\right)\frac{e^{\theta_{i}}}{f(A_{l})}\right]^{1 / 2}} \end{array}
\]

for both \(\theta = \theta^{*}\) and \(\theta =\) any consistent
estimator of \(\theta^{*}\) .

Note that Theorem 4.2 indicates that the choice of \(f(\cdot) > 0\) does
not affect the rate of convergence, but it affects the estimation
efficiency. As we argued in Section 3.1, the optimal weighting to
minimize the asymptotic variance is
\(f(A_{l})\propto \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) in the class of
spectral estimators. In practice, however, we do not know
\(\theta_{u}^{*}\) beforehand. Therefore, we could implement a two- step
procedure to improve the efficiency of the spectral estimator: in the
first step, we obtain our initial consistent estimator
\(\widehat{\theta_{u}^{(\mathrm{initial})}}\) with weighting say
\(f(A_{l}) = |A_{l}|\) , and in the second step, we estimate
\(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) by plugging
\(\widehat{\theta_{u}^{(\mathrm{initial})}}\) and run the spectral
method again with this optimal weighting to get the final asymptotically
efficient estimator \(\widehat{\theta_{u}^{(\mathrm{final})}}\) . Note
that we do not intend to prove the theoretical properties of this two-
step estimator, as the data dependency in the optional weighting of the
second step makes the uniform approximation analysis highly nontrivial
due to non- i.i.d. ranking outcomes. Nonetheless, we could circumvent
this theoretical difficulty by splitting data into a very small part
\((o(|\mathcal{D}|)\) samples) for step 1, to achieve consistency with a
worse convergence rate, and using the remaining majority
\((|\mathcal{D}| - o(|\mathcal{D}|)\) samples) for step 2, to maintain
the same asymptotic behavior. In addition, empirically, we found that
directly using the same whole data in both steps achieves decent
performance given a large sample size. We refer interested readers to
our numerical studies.

\section{4.2 Estimation accuracy and asymptotic normality for the PL
model}\label{estimation-accuracy-and-asymptotic-normality-for-the-pl-model}

In the random graph case, we have to specify the graph generation
process in order to study the theoretical properties. We consider the
commonly used PL model, where we sample each \(M\) - way comparison with
probability \(p\) and compare this set for \(L\) times. Furthermore, we
will only work with \(M = 3\) since we plan to focus on a transparent
and intuitive discussion. We can easily generalize all the discussions
to general \(M\) , but derivations and formulas can be more tedious.

The PL model with 3- way comparisons has been studied in Fan et
al.~(2022b) by using MLE, where they explicitly write down the
likelihood function. The proposed spectral method can work for any fixed
graph, including the one generated from the PL model. In this section,
we would like to compare the performance of the spectral method with
that of the MLE. To make sure the spectral method works for the PL
model, we need to prove the approximations (3.1) and (3.6).

We first take care of (3.6). Consider conditioning on
\(\widetilde{\mathcal{G}}\) , where all comparisons in
\(\widetilde{\mathcal{G}}\) are independent; each
\(\widetilde{A}_{ijk}\) is compared for \(L\) times if
\(\widetilde{A}_{ijk} = 1\) . Now \(c_{l}\) and \(A_{l}\) are induced
from \(\widetilde{\mathcal{G}}\) , and

can be dependent. In this case, we can write

\[
P_{ij} - E[P_{ij}|\widetilde{\mathcal{G}} ] = \frac{1}{d}\sum_{\ell = 1}^{L}\sum_{k:k\neq j,i}\widetilde{A}_{ijk}[Z_{ijk}^{l} - EZ_{ijk}^{l}],
\]

where
\(Z_{ijk}^{l} = 1(A_{l} = \{i,j\} ,c_{l} = j) / f(\{i,j\}) + 1(A_{l} = \{i,j,k\} ,c_{l} = j) / f(\{i,j,k\})\)
, which is again bounded from above and below and independent for any
given \(\widetilde{A}_{ijk}\) . In this case, with a little abuse of
notations, we redefine

\[
n^{\dagger} = L\max_{i\neq j}\sum_{k:k\neq j,i}A_{ijk},\quad n^{\dagger} = L\max_{i}\sum_{j< k:j,k\neq i}A_{ijk}.
\]

Similar to Section 4.1, conditional on \(\widetilde{G}\) , we have

\[
\begin{array}{r l} & {\max_{i}\bigg|\sum_{j:j\neq i}P_{i j} - \sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\dagger}\log n}),}\\ & {\max_{i\neq j}\bigg|P_{i j} - E[P_{i j}|\widetilde{\mathcal{G}} ]\bigg| = \mathcal{O}_{P}(d^{-1}\sqrt{n^{\ddagger}\log n}),}\\ & {\sum_{j:j\neq i}E[P_{i j}|\widetilde{\mathcal{G}} ] = \tau_{i}^{\diamond}e^{-\theta_{i}^{*}}\asymp \frac{1}{d} n^{\dagger} \mathrm{(assumption)}.} \end{array}
\]

We adapt Assumption 4.2 to the following assumption. Note that we have
no assumption on \(L\) , so \(L\) can be as low as 1.

Assumption 4.4. In the PL model with \(M\) - way complete comparisons,
choose \(d\asymp n^{\dagger}\) in the spectral ranking, and assume
\(\tau_{i}^{\diamond}e^{- \theta_{i}^{*}}\asymp n^{\dagger} / d\) for
all \(i\in [n]\) , \(e^{4\bar{\kappa}} = o(n)\) and
\(p\gtrsim e^{6\bar{\kappa}}\mathrm{poly}(\log n) / \binom{n- 1}{M- 1}\)

Under Assumption 4.4, we can prove

\[
n^{\dagger}\asymp \binom{n-1}{M-1}p L,\qquad\max \Big\{\binom{n-2}{M-2}p-\log n,0\Big\}L\lesssim n^{\ddagger}\lesssim\Big[\binom{n-2}{M-2}p+\log n\Big]
\]

with probability \(1 - o(1)\) . Note that in \(n^{\dagger}\) , by
Assumption 4.4, we know the dominating term is
\(\textstyle{\binom{n- 1}{M- 1}}p L\) . However, in \(n^{\ddagger}\) ,
we have the additional term \(\log n\) , which comes from the sub-
exponential tail decay in Bernstein inequality, and if \(p\) is really
small, it could happen that \(\log n\) dominates \(n^{\ddagger}\) . When
\(p\) is large, that is \(\textstyle{\binom{n- 2}{M- 2}}p\gtrsim\log n\)
, then \(n^{\ddagger}\asymp n n^{\ddagger}\) and Assumption 4.2 holds.
Therefore, we have a dense comparison graph, and the proof for this part
follows in a similar vein as Theorem 4.2. When \(p\) is small, that is,
\(\textstyle{\binom{n- 2}{M- 2}}p\lesssim\log n\) ,
\(n^{\ddagger}\lesssim\log n\) if \(L\) is bounded. In this case, we
will modify the proof of Theorem 4.2 to the random graph case in order
to show Theorem 4.4 below. In addition, since
\(\begin{array}{r}{\sum_{j:j\neq i}P_{i j} = \mathcal{O}_{P}(n^{\dagger} / d)} \end{array}\)
, it makes sense to choose \(d\asymp n^{\dagger}\) in Assumption 4.4 to
make the diagonal elements of the transition matrix a constant order.
Note that in the fixed graph case, we do not need to impose rate
assumptions on \(d\) as the comparison graph has no randomness.

Next, we verify that under the PL model, Assumption 4.3 holds with high
probability.

Theorem 4.3. Under the PL model and Assumption 4.4, with probability
\(1 - o(1)\) , Assumption 4.3 holds when we condition on
\(\widetilde{G}\) instead of \(\mathcal{G}\) .

We next hope to show that under Assumptions 4.4, the spectral estimator
\(\widehat{\theta}_{i}\) has the uniform approximation: the differences
between \(\widetilde{\theta}_{i} - \theta_{i}^{*}\) and \(J_{i}^{*}\)
for all \(i\in [n]\) are \(o_{P}(1 / \sqrt{n^{\dagger}})\) . The key
step is still the verification of (3.1) under this weaker Assumptions
4.4 for a random comparison graph.

Theorem 4.4. Under the PL model and Assumptions 4.1 and 4.4, the
spectral estimator \(\widetilde{\theta}_{i}\) has the uniform
approximation:
\(\widetilde{\theta}_{i} - \theta_{i}^{*} = J_{i}^{*} + o_{P}\big(1 / \sqrt{n^{\dagger}}\big)\)
, uniformly for all \(i\in [n]\) . Therefore, the spectral estimator
(2.1) satisfies

\[
\| \widetilde{\theta} -\theta^{*}\|_{\infty}\lesssim e^{\bar{\kappa}}\sqrt{\frac{\log n}{\binom{n - 1}{M - 1}pL}}, \tag{4.5}
\]

with probability \(1 - o(1)\) . In addition,

\[
\rho_{i}(\theta)(\widetilde{\theta}_{i} - \theta_{i}^{*})\Rightarrow N(0,1),
\]

for all \(i\in [n]\) with
\(\rho_{i}(\theta) = \mathrm{Var}(J_{i}^{*}|\widetilde{G})^{- 1 / 2}\) ,
where in the formula of \(\mathrm{Var}(J_{i}^{*}|\widetilde{G})\) we can
choose both \(\theta = \theta^{*}\) and \(\theta =\) any consistent
estimator of \(\theta^{*}\) .

Remark 4.2. The two- step estimator under optimal weight
\(f(A_{l}) = \sum_{u\in A_{l}}e^{\theta_{u}^{*}}\) (can be consistently
estimated with a small proportion of a separate dataset) achieves the
same variance as the MLE estimator, which matches the Cramer Rao lower
bound among all estimators (Fan et al., 2022a,b).

Corollary 4.1. Under the conditions of Theorem 4.4, if we have
\(\theta_{(K)}^{*} - \theta_{(K + 1)}^{*}\geq \Delta\) , with
\(\theta_{(i)}^{*}\) denoting the underlying score of the item with true
rank \(i\) for \(i\in [n]\) , and when the sample complexity satisfies

\[
e^{2\bar{\kappa}}\Delta^{-2}\cdot \log n = \mathcal{O}\bigg(\binom{n-1}{M-1}pL\bigg),
\]

we have
\(\{i\in [n],\widehat{r_{i}}\leq K\} = \{i\in [n],r_{i}^{*}\leq K\}\)
(the selected top- K set is identical to the true top- K set), where
\(\widehat{r_{i}},r_{i}^{*}\) denote the empirical rank of
\(\widehat{\theta}_{i}\) among \(\{\widehat{\theta}_{i},i\in [n]\}\) and
true rank of the i- th item, respectively.

We remark that when \(M = 2\) , and \(\bar{\kappa} = \mathcal{O}(1)\) ,
our conclusion from Corollary 4.1 reduces to the conclusion of Theorem 1
in Chen et al.~(2019).

\section{4.3 Validity Justification for Bootstrap
Procedure}\label{validity-justification-for-bootstrap-procedure}

The primary goal of this section is to justify the validity of the
proposed bootstrap procedure in Section 3.4. Recall that the targeted
quantity \(T_{\mathcal{M}}\) is the maximum modulus of the random vector

\[
\Delta_{\mathcal{M}}\coloneqq \left\{\frac{\widetilde{\theta}_{k} - \widetilde{\theta}_{m} - (\theta_{k}^{*} - \theta_{m}^{*})}{\widetilde{\sigma}_{km}}\right\}_{m\in \mathcal{M},k\neq m}.
\]

For each marginal of \(\Delta_{\mathcal{M}}\) , the asymptotic normality
can be similarly established following Theorem 4.2. However, studying
the asymptotic distribution of \(\| \Delta_{\mathcal{M}}\|_{\infty}\)
becomes quite challenging as

its dimension \((n - 1)|\mathcal{M}|\) can increase with the number of
items. In particular, the traditional multivariate central limit theorem
for \(\Delta_{\mathcal{M}}\) may no longer be valid asymptotically
(Portnoy, 1986). To handle the high dimensionality, we shall invoke the
modern Gaussian approximation theory (Chernozhukov et al., 2017, 2019)
in order to derive the asymptotic distribution of
\(\| \Delta_{\mathcal{M}}\|_{\infty}\) , shown in Theorem E.1. Moreover,
the validity of our multiplier bootstrap procedure is justified in the
following theorem.

Theorem 4.5. Assume \(e^{3\bar{\kappa}}(\log n)^2 = o(n)\) and
\(e^{5\bar{\kappa}}n^{\ddagger}n^{1 / 2}(\log n)^3 = o(n^{\dagger})\) .
Then, under the conditions of Theorem 4.1, we have

\[
|\mathbb{P}(T_{\mathcal{M}} > \mathcal{Q}_{1 - \alpha}) - \alpha |\to 0.
\]

Remark 4.3. Theorem 4.5 indicates that the estimated critical value
\(\mathcal{Q}_{1 - \alpha}\) from the Gaussian multiplier bootstrap
indeed controls the significance level of the simultaneous confidence
intervals (3.15) for \(\{r_m\}_{m\in \mathcal{M}}\) to the prespecified
level \(\alpha\) , that is,

\[
\mathbb{P}\Big(r_{m}\in [\mathcal{R}_{mU},\mathcal{R}_{mR}]\mathrm{~for~all~}m\in \mathcal{M}\Big)\geq 1 - \alpha +o(1).
\]

Recently Fan et al.~(2022b) proposed a similar approach to construct
simultaneous confidence intervals for ranks in the context of the PL
model with only the top choice observed for each comparison, which,
however, requires the number of comparisons \(L\) for each connected
item to be sufficiently large such that
\(L\gtrsim \mathrm{poly}(\log n)\) . In contrast, our procedure in
Section 3.4 works without any constraints on the number of comparisons
for each \(A_{l}\) (i.e., we even allow \(L = 1\) for all comparisons)
and is thus much more widely applicable, since in many real problems,
sets of size \(M\) can be compared at different times and sometimes only
once.

\section{5 Numerical Studies}\label{numerical-studies}

In this section, we validate the methodology and examine the theoretical
results introduced in Sections 3 and 4. We conducted comprehensive
simulation studies, but due to the page limit, we relegate the results
to the Appendix A and only briefly summarize our key findings here. We
first validate consistency and asymptotic distribution of the spectral
estimator, check the efficacy of the Gaussian bootstrap. All simulations
match with our theoretical results perfectly. We also provide examples
for constructing one- sample and two- sample confidence intervals for
ranks and carrying out hypothesis testing Examples 3.2- 3.5. Finally, we
empirically investigate the connections between the spectral method and
MLE. In particular, we found the two- step or oracle weight spectral
method behaves almost identically to MLE.

\section{6 Real Data Analysis}\label{real-data-analysis}

We present the spectral ranking inferences for two real datasets in this
section. The first one is about the ranking of statistics journals,
which is based on pairwise comparisons (Journal B citing Journal A means
A is preferred over B, which is consistent with the fact that good
papers usually

have higher citations). In particular, we can test for two periods of
time, whether the journal ranking has changed significantly. The second
application is about movie ranking, which is based on multiway
comparisons of different sizes (3 or 4 movies are given to people to
rank). The movie comparison graph shows strong heterogeneity in node
degrees. Therefore, this comparison graph should be better modeled as a
fixed graph without homogeneous sampling. In both cases, we will report
the results from the Two- Step spectral estimator and the vanilla
spectral estimator in Appendix B.

\section{6.1 Ranking of Statistics
Journals}\label{ranking-of-statistics-journals}

In this section, we study the Multi- Attribute Dataset on Statisticians
(MADStat) which contains citation information from 83,331 papers
published in 36 journals between 1975- 2015. The data set was collected
and studied by Ji et al.~(2022, 2023+).

We follow Ji et al.~(2023+)'s convention to establish our pairwise
comparison data. We will use journals' abbreviations given in the data.
We refer interested readers to the complete journal names on the data
website
https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/V7VUF0.
Firstly, we excluded three probability journals---AOP, PTRF, and AIHPP,
due to their fewer citation exchanges with other statistics
publications. Hence, our study comprises of a total of 33 journals.
Secondly, we only examine papers published between 2006- 2015. For
instance, if we treat 2010 as our reference year, we only count
comparison results indicating `Journal A is superior to Journal B' if,
and only if, a paper published in Journal B in 2010 has cited another
paper that was published in Journal A between the years 2001 and 2010.
This approach favors more recent citations, thus allowing the journal
rankings to better reflect the most current trends and information.
Finally, we chose to divide our study into two periods, 2006- 2010 and
2011- 2015, to detect the possible rank changes of journals.

Utilizing the data, we showcase the ranking inference results,
summarized in Table 1. These results include two- sided, one- sided, and
uniform one- sided confidence intervals for ranks within each of the two
time periods (2006- 2010 and 2011- 2015). We calculate these intervals
using the Two- Step Spectral method over the fixed comparison graph (the
results based on the one- step Vanilla Spectral method are presented in
Appendix B.1) and using the bootstrap method detailed in Sections 3.3 -
3.5.

From Table 1, we can easily get answers to the following questions on
ranking inference. For example, is each journal's rank maintained
unchanged across the two time periods? At a significance level of
\(\alpha = 10\%\) , we find that the ranks of the following journals in
alphabetical order demonstrate significant differences between the two
time frames (Example 3.4):

AISM, AoAS, Biost, CSTM, EJS, JMLR, JoAS, JSPI.

This aligns with real- world observations. For instance, JMLR, EJS, and
AOAS are newer journals that emerged after 2000. As a result, these
journals received fewer citations in the earlier period and got
recognized better in the more recent period.

We then turn our attention to the stability of the highest- ranked
journals. Referring to Table 1, we observe that the top four journals
(AoS, Bka, JASA, and JRSSB, known as the Big- Four

Table 1: Ranking inference results for 33 journals in 2006-2010 and
2011-2015 based on the TwoStep Spectral estimator. For each time period,
there are 6 columns. The first column \(\tilde{\theta}\) denotes the
estimated underlying scores. The second through the fifth columns denote
their relative ranks, two-sided, one-sided, and uniform one-sided
confidence intervals for ranks with coverage level \(95\%\)
respectively. The sixth column denotes the number of comparisons in
which each journal is involved.

\begin{longtable}[]{@{}lllllllllllll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\multirow{2}{*}{Journal} & \multicolumn{6}{l}{%
2006 -- 2010} & \multicolumn{6}{l@{}}{%
2011 -- 2015} \\
& θ & r & TCI & OCI & UOCI & Count & θ & r & TCI & OCI & UOCI & Count \\
JRSSB & 1.654 & 1 & {[}1,1{]} & {[}1,n{]} & {[}1,n{]} & 5282 & 1.553 & 1
& {[}1,2{]} & {[}1,n{]} & {[}1,n{]} & 5513 \\
AoS & 1.206 & 3 & {[}2,4{]} & {[}2,n{]} & {[}2,n{]} & 7674 & 1.522 & 2 &
{[}1,2{]} & {[}1,n{]} & {[}1,n{]} & 11316 \\
Bka & 1.316 & 2 & {[}2,3{]} & {[}2,n{]} & {[}2,n{]} & 5579 & 1.202 & 3 &
{[}3,3{]} & {[}3,n{]} & {[}3,n{]} & 6399 \\
JASA & 1.165 & 4 & {[}3,4{]} & {[}3,n{]} & {[}3,n{]} & 9652 & 1.064 & 4
& {[}4,4{]} & {[}4,n{]} & {[}4,n{]} & 10862 \\
JMLR & -0.053 & 20 & {[}14,25{]} & {[}15,n{]} & {[}13,n{]} & 1100 &
0.721 & 5 & {[}5,7{]} & {[}5,n{]} & {[}5,n{]} & 2551 \\
Biost & 0.288 & 13 & {[}10,18{]} & {[}10,n{]} & {[}9,n{]} & 2175 & 0.591
& 6 & {[}5,9{]} & {[}5,n{]} & {[}5,n{]} & 2727 \\
Bcs & 0.820 & 5 & {[}5,7{]} & {[}5,n{]} & {[}5,n{]} & 6614 & 0.571 & 7 &
{[}5,9{]} & {[}6,n{]} & {[}5,n{]} & 6450 \\
StSci & 0.668 & 7 & {[}5,9{]} & {[}5,n{]} & {[}5,n{]} & 1796 & 0.437 & 8
& {[}6,13{]} & {[}6,n{]} & {[}6,n{]} & 2461 \\
Sini & 0.416 & 10 & {[}9,14{]} & {[}9,n{]} & {[}8,n{]} & 3701 & 0.374 &
9 & {[}8,13{]} & {[}8,n{]} & {[}8,n{]} & 4915 \\
JRSSA & 0.239 & 14 & {[}10,20{]} & {[}10,n{]} & {[}9,n{]} & 893 & 0.370
& 10 & {[}6,13{]} & {[}8,n{]} & {[}6,n{]} & 865 \\
JCGS & 0.605 & 8 & {[}6,9{]} & {[}6,n{]} & {[}6,n{]} & 2493 & 0.338 & 11
& {[}8,13{]} & {[}8,n{]} & {[}8,n{]} & 3105 \\
Bern & 0.793 & 6 & {[}5,8{]} & {[}5,n{]} & {[}5,n{]} & 1575 & 0.336 & 12
& {[}8,13{]} & {[}8,n{]} & {[}8,n{]} & 2613 \\
ScaJS & 0.528 & 9 & {[}7,12{]} & {[}7,n{]} & {[}6,n{]} & 2442 & 0.258 &
13 & {[}8,13{]} & {[}9,n{]} & {[}8,n{]} & 2573 \\
JRSSC & 0.113 & 15 & {[}11,22{]} & {[}11,n{]} & {[}11,n{]} & 1401 &
0.020 & 14 & {[}14,19{]} & {[}14,n{]} & {[}12,n{]} & 1492 \\
AoAS & -1.463 & 30 & {[}30,33{]} & {[}30,n{]} & {[}30,n{]} & 1258 &
-0.017 & 15 & {[}14,20{]} & {[}14,n{]} & {[}14,n{]} & 3768 \\
CanJS & 0.101 & 17 & {[}11,22{]} & {[}11,n{]} & {[}11,n{]} & 1694 &
-0.033 & 16 & {[}14,20{]} & {[}14,n{]} & {[}14,n{]} & 1702 \\
JSPI & -0.327 & 26 & {[}24,26{]} & {[}24,n{]} & {[}22,n{]} & 6565 &
-0.046 & 17 & {[}14,20{]} & {[}14,n{]} & {[}14,n{]} & 6732 \\
JTSA & 0.289 & 12 & {[}9,18{]} & {[}10,n{]} & {[}8,n{]} & 751 & -0.101 &
18 & {[}14,22{]} & {[}14,n{]} & {[}14,n{]} & 1026 \\
JMVA & -0.126 & 22 & {[}17,25{]} & {[}17,n{]} & {[}15,n{]} & 5833 &
-0.148 & 19 & {[}14,22{]} & {[}15,n{]} & {[}14,n{]} & 6454 \\
SMed & -0.131 & 23 & {[}17,25{]} & {[}18,n{]} & {[}17,n{]} & 6626 &
-0.242 & 20 & {[}18,25{]} & {[}18,n{]} & {[}17,n{]} & 6857 \\
Extrem & -2.099 & 33 & {[}30,33{]} & {[}31,n{]} & {[}30,n{]} & 173 &
-0.312 & 21 & {[}16,30{]} & {[}18,n{]} & {[}14,n{]} & 487 \\
AISM & 0.317 & 11 & {[}9,18{]} & {[}10,n{]} & {[}9,n{]} & 1313 & -0.359
& 22 & {[}19,30{]} & {[}20,n{]} & {[}18,n{]} & 1605 \\
EJS & -1.717 & 32 & {[}30,33{]} & {[}30,n{]} & {[}30,n{]} & 1366 &
-0.367 & 23 & {[}20,29{]} & {[}20,n{]} & {[}19,n{]} & 4112 \\
SPLet & -0.033 & 19 & {[}15,25{]} & {[}15,n{]} & {[}13,n{]} & 3651 &
-0.384 & 24 & {[}21,29{]} & {[}21,n{]} & {[}19,n{]} & 4439 \\
CSDA & -0.975 & 29 & {[}27,30{]} & {[}27,n{]} & {[}27,n{]} & 6732 &
-0.467 & 25 & {[}21,30{]} & {[}21,n{]} & {[}21,n{]} & 8717 \\
JNS & -0.255 & 25 & {[}19,26{]} & {[}20,n{]} & {[}17,n{]} & 1286 &
-0.484 & 26 & {[}21,30{]} & {[}21,n{]} & {[}21,n{]} & 1895 \\
ISRe & 0.082 & 18 & {[}11,25{]} & {[}11,n{]} & {[}10,n{]} & 511 & -0.491
& 27 & {[}21,30{]} & {[}21,n{]} & {[}20,n{]} & 905 \\
AuNZ & 0.108 & 16 & {[}11,23{]} & {[}11,n{]} & {[}10,n{]} & 862 & -0.504
& 28 & {[}21,30{]} & {[}21,n{]} & {[}20,n{]} & 816 \\
JClas & -0.185 & 24 & {[}15,26{]} & {[}15,n{]} & {[}11,n{]} & 260 &
-0.535 & 29 & {[}18,30{]} & {[}20,n{]} & {[}14,n{]} & 224 \\
SCmp & -0.096 & 21 & {[}15,25{]} & {[}15,n{]} & {[}14,n{]} & 1309 &
-0.561 & 30 & {[}23,30{]} & {[}24,n{]} & {[}21,n{]} & 2650 \\
Bay & -1.494 & 31 & {[}30,33{]} & {[}30,n{]} & {[}27,n{]} & 279 & -1.102
& 31 & {[}31,32{]} & {[}31,n{]} & {[}30,n{]} & 842 \\
CSTM & -0.843 & 27 & {[}27,29{]} & {[}27,n{]} & {[}27,n{]} & 2975 &
-1.296 & 32 & {[}31,32{]} & {[}31,n{]} & {[}31,n{]} & 4057 \\
JoAS & -0.912 & 28 & {[}27,30{]} & {[}27,n{]} & {[}27,n{]} & 1055 &
-1.904 & 33 & {[}33,33{]} & {[}33,n{]} & {[}33,n{]} & 2780 \\
\end{longtable}

in statistics) maintain their positions strongly across different time
periods. Furthermore, with a significance level of \(\alpha = 10\%\) ,
we reject the hypothesis that the top seven ranked items remain constant
across the two time periods (Example 3.5). Specifically, for 2006- 2010,
the \(95\%\) confidence set for the top- 7 items includes:

AoS, Bern, Bcs, Bka, JASA, JUGS JRSSB, ScaJS, StSci.

And for 2011- 2015, the \(95\%\) confidence set for the top- 7 items
includes:

AoS, Bcs, Biost, Bka, JASA, JMLR, JRSSA, JRSSB, StSci.

Clearly, these sets intersect only at 6 items, smaller than 7,
reflecting a shift in the rankings over the two periods.

\section{6.2 Ranking of Movies}\label{ranking-of-movies}

In this section, we construct confidence intervals for the ranks of
movies or television series featured within the The Netflix Prize
competition (Bennett et al., 2007), which aims to enhance the precision
of the Netflix recommendation algorithm. The dataset we examine
corresponds to 100 random 3 and 4 candidate elections drawn from Data
Set 1 of Mattei et al.~(2012), which was extracted from the original The
Netflix Prize dataset, devoid of any ties. The dataset contains 196
movies in total and 163759 3- way or 4- way comparisons. For simplicity,
we only use the top ranked movie, although it is straightforward to
apply the multi- level breaking to use the complete ranking data. This
dataset can be accessed at the website:
https://www.preflib.org/dataset/00004.

We compute two- sided, one- sided, and uniform one- sided confidence
intervals employing the bootstrap method as described in Sections 3.3 -
3.5, based on the Two- Step Spectral method. The results are shown in
Table 2. Additionally, the results from the one- step Vanilla Spectral
method are detailed in Table 11 in Appendix B.2.

First note that the heterogeneity of the number of comparisons
(``Count'' column in Table 2) is more severe relative to the journal
ranking data, which leads to the adaptive length of rank confidence
intervals. From ``OCI'' column of Table 2, we can test whether each
individual movie belong to the top- 10 rated movies ( \(K = 10\) in
Example 3.2). We end up failing to reject the hypothesis for the first
12 films listed in Table 2. Furthermore, we can use the uniform one-
sided confidence interval (``UOCI'') column to build candidate
confidence set for the true top- 10 movies ( \(K = 10\) in Example 3.3).
The result suggests that except for ``Harry Potter and the Sorcerer's
Stone'', we should include the other top 15 ranked films in our top- 10
confidence set. The reason we cannot exclude the films ``High Noon'' and
``Sex and the City: Season 6: Part 2'', despite these movies rank lower
than ``Harry Potter and the Sorcerer's Stone'', is due to their fewer
number of comparisons and thus wider confidence intervals. Similarly,
the top- 5 confidence set is the first 9 movies in Table 2.

\begin{longtable}[]{@{}|l|l|l|l|l|l|l|l|@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\hline
Movie & θ & τ & TCI & OCI & UOCI & Count & \\
\hline
The Silence of the Lambs & 3.002 & 1 & {[}1, 1{]} & {[}1, n{]} & {[}1,
n{]} & 19589 & \\
\hline
The Green Mile & 2.649 & 2 & {[}2, 4{]} & {[}2, n{]} & {[}2, n{]} & 5391
& \\
\hline
Shrek (Full-screen) & 2.626 & 3 & {[}2, 4{]} & {[}2, n{]} & {[}2, n{]} &
19447 & \\
\hline
The X-Files: Season 2 & 2.524 & 4 & {[}2, 7{]} & {[}2, n{]} & {[}2, n{]}
& 1114 & \\
\hline
Ray & 2.426 & 5 & {[}4, 7{]} & {[}4, n{]} & {[}4, n{]} & 7905 & \\
\hline
The X-Files: Season 3 & 2.357 & 6 & {[}4, 10{]} & {[}4, n{]} & {[}2,
n{]} & 1442 & \\
\hline
The West Wing: Season 1 & 2.278 & 7 & {[}4, 10{]} & {[}4, n{]} & {[}4,
n{]} & 3263 & \\
\hline
National Lampoon\textquotesingle s Animal House & 2.196 & 8 & {[}6,
10{]} & {[}6, n{]} & {[}5, n{]} & 10074 & \\
\hline
Aladdin: Platinum Edition & 2.154 & 9 & {[}6, 13{]} & {[}6, n{]} & {[}5,
n{]} & 3355 & \\
\hline
Seven & 2.143 & 10 & {[}6, 11{]} & {[}7, n{]} & {[}6, n{]} & 16305 & \\
\hline
Back to the Future & 2.030 & 11 & {[}9, 15{]} & {[}9, n{]} & {[}8, n{]}
& 6428 & \\
\hline
Blade Runner & 1.968 & 12 & {[}10, 16{]} & {[}10, n{]} & {[}9, n{]} &
5597 & \\
\hline
Harry Potter and the Sorcerer\textquotesingle s Stone & 1.842 & 13 &
{[}12, 22{]} & {[}12, n{]} & {[}11, n{]} & 7976 & \\
\hline
High Noon & 1.821 & 14 & {[}11, 25{]} & {[}11, n{]} & {[}10, n{]} & 1902
& \\
\hline
Sex and the City: Season 6: Part 2 & 1.770 & 15 & {[}11, 30{]} & {[}11,
n{]} & {[}8, n{]} & 532 & \\
\hline
Jaws & 1.749 & 16 & {[}13, 25{]} & {[}13, n{]} & {[}13, n{]} & 8383 & \\
\hline
The Ten Commandments & 1.735 & 17 & {[}13, 28{]} & {[}13, n{]} & {[}12,
n{]} & 2186 & \\
\hline
Willy Wonka \&amp; the Chocolate Factory & 1.714 & 18 & {[}13, 26{]} &
{[}13, n{]} & {[}13, n{]} & 9188 & \\
\hline
Stalag & 17 & 697 & 19 & {[}12, 34{]} & {[}12, n{]} & 11, n{]} & 806 \\
\hline
Unforgiven & 1.633 & 20 & {[}14, 29{]} & {[}14, n{]} & {[}14, n{]} &
9422 & \\
\hline
\end{longtable}

Table 2: Ranking inference results for top- 20 Netflix movies or tv
series based on the Two- Step Spectral estimator. The first column
\(\widetilde{\theta}\) denotes the estimated underlying scores. The
second through the fifth columns denote their relative ranks, two-
sided, one- sided, and uniform one- sided confidence intervals for ranks
with coverage level \(95\%\) , respectively. The sixth column denotes
the number of comparisons in which each movie is involved.

\section{7 Conclusion and Discussion}\label{conclusion-and-discussion}

In this work, we studied the performance of the spectral method in
preference score estimation, quantified the asymptotic distribution of
the estimated scores, and explored one- sample and two- sample inference
on ranks. In particular, we worked with general multiway comparisons
with fixed comparison graphs, where the size of each comparison can vary
and can be as low as only one. This is much closer to real applications
than the homogeneous random sampling assumption imposed in the BTL or PL
models. The applications of journal ranking and movie ranking have
demonstrated the clear usefulness of our proposed methodologies.
Furthermore, we studied the relationship between the spectral method and
the MLE in terms of estimation efficiency and revealed that with a
carefully chosen weighting scheme, the spectral method can approximately
achieve the same efficiency as the MLE, which is also verified using
numerical simulations. Finally, to the best of our knowledge, it is the
first time that effective two- sample rank testing methods have been
proposed in the literature.

Although we have made significant improvements in relaxing conditions,
the role of general comparison graphs is still not fully understood,
especially in the setting of multiway comparisons. Questions like how to
design a better sampling regime, either online or offline, remain open.
In addition, the spectral method essentially encodes multiway
comparisons into pairwise comparisons, where the encoding will break
data independence. The best encoding or breaking method should be
further investigated. Finally, a set of recent works on ranking
inferences opens the door to many possibilities of theoretical studies
on ranking inferences and related problems such as assortment
optimization, under the setting of, say, rank time series, rank change
point detection, rank panel data, recommendation based on rank
inferences, uncertainty quantification and inference for properties of
the optimal assortment. These may find potential application in numerous
management settings.

\section{References}\label{references}

Aouad, A., Farias, V., Levi, R. and Segev, D. (2018). The
approximability of assortment optimization under ranking preferences.
\emph{Operations Research}, \textbf{66} 1661- 1669. Avery, C. N.,
Glickman, M. E., Hoxby, C. M. and Metrick, A. (2013). A revealed
preference ranking of us colleges and universities. \emph{The Quarterly
Journal of Economics}, \textbf{128} 425- 467. Azari Soufiani, H., Chen,
W., Parkes, D. C. and Xia, L. (2013). Generalized method- of- moments
for rank aggregation. \emph{Advances in Neural Information Processing
Systems}, \textbf{26. Baltrunas, L., Makcinskas, T. and Ricci, F.
(2010). Group recommendations with rank aggregation and collaborative
filtering. In \emph{Proceedings of the fourth ACM conference on
Recommender systems}.Bennett, J., Lanning, S. et al.~(2007). The Netflix
Prize. In \emph{Proceedings of KDD cup and workshop}, vol.~2007. New
York.Caron, F., Teh, Y. W. and Murphy, T. B. (2014). Bayesian
nonparametric Plackett- Luce models for the analysis of preferences for
college degree programmes. \emph{The Annals of Applied Statistics},} 8**
1145- 1181. Chen, P., Gao, C. and Zhang, A. Y. (2022). Partial recovery
for top- \(K\) ranking: Optimality of mle and suboptimality of the
spectral method. \emph{The Annals of Statistics}, \textbf{50} 1618-
1652. Chen, X., Krishnamurthy, A. and Wang, Y. (2023). Robust dynamic
assortment optimization in the presence of outlier customers.
\emph{Operations Research}.Chen, X., Wang, Y. and Zhou, Y. (2020).
Dynamic assortment optimization with changing contextual information.
\emph{The Journal of Machine Learning Research}, \textbf{21} 8918- 8961.
Chen, Y., Fan, J., Ma, C. and Wang, K. (2019). Spectral method and
regularized mle are both optimal for top- \(K\) ranking. \emph{Annals of
statistics}, \textbf{47} 2204. Chen, Y. and Suh, C. (2015). Spectral
mle: Top- \(K\) rank aggregation from pairwise comparisons. In
\emph{International Conference on Machine Learning}. PMLR.Cheng, W.,
Dembzynski, K. and Hüllermeier, E. (2010). Label ranking methods based
on the Plackett- Luce model. In \emph{ICML}.Chernozhukov, V.,
Chetverikov, D. and Kato, K. (2017). Central limit theorems and
bootstrap in high dimensions. \emph{The Annals of Probability},
\textbf{45} 2309- 2352. Chernozhukov, V., Chetverikov, D., Kato, K. and
Koike, Y. (2019). Improved central limit theorem and bootstrap
approximations in high dimensions. \emph{arXiv preprint
arXiv:1912.10529}.Davis, J. M., Gallego, G. and Topaloglu, H. (2014).
Assortment optimization under variants of the nested logit model.
\emph{Operations Research}, \textbf{62} 250- 273.

Dwork, C., Kumar, R., Naor, M. and Sivakumar, D. (2001). Rank
aggregation methods for the web. In Proceedings of the 10th
international conference on World Wide Web.Fan, J., Hou, J. and Yu, M.
(2022a). Uncertainty quantification of mle for entity ranking with
covariates. arXiv preprint arXiv:2212.09961. Fan, J., Lou, Z., Wang, W.
and Yu, M. (2022b). Ranking inferences based on the top choice of
multiway comparisons. arXiv preprint arXiv:2211.11957. Gallego, G. and
Topaloglu, H. (2014). Constrained assortment optimization for the nested
logit model. Management Science, 60 2583- 2601. Gao, C., Shen, Y. and
Zhang, A. Y. (2021). Uncertainty quantification in the Bradley- Terry-
Luce model. arXiv preprint arXiv:2110.03874. Guiver, J. and Snelson, E.
(2009). Bayesian inference for Plackett- Luce ranking models. In
proceedings of the 26th annual international conference on machine
learning.Hajek, B., Oh, S. and Xu, J. (2014). Minimax- optimal inference
from partial rankings. Advances in Neural Information Processing
Systems, 27. Han, R. and Xu, Y. (2023). A unified analysis of
likelihood- based estimators in the Plackett- Luce model. arXiv preprint
arXiv:2306.02821. Han, R., Ye, R., Tan, C. and Chen, K. (2020).
Asymptotic theory of sparse Bradley- Terry model. The Annals of Applied
Probability, 30 2491- 2515. Hunter, D. R. (2004). MM algorithms for
generalized Bradley- Terry models. The annals of statistics, 32 384-
406. Jang, M., Kim, S. and Suh, C. (2018). Top- \(K\) rank aggregation
from \(m\) - wise comparisons. IEEE Journal of Selected Topics in Signal
Processing, 12 989- 1004. Jang, M., Kim, S., Suh, C. and Oh, S. (2016).
Top- \(K\) ranking from pairwise comparisons: When spectral ranking is
optimal. arXiv preprint arXiv:1603.04153. Ji, P., Jin, J., Ke, Z. T. and
Li, W. (2022). Co- citation and co- authorship networks of
statisticians. Journal of Business \& Economic Statistics, 40 469- 485.
Ji, P., Jin, J., Ke, Z. T. and Li, W. (2023+). Meta- analysis on
citations for statisticians. To Appear.Johnson, V. E., Deaner, R. O. and
Van Schaik, C. P. (2002). Bayesian analysis of rank data with
application to primate intelligence experiments. Journal of the American
Statistical Association, 97 8- 17. Li, H., Simchi- Levi, D., Wu, M. X.
and Zhu, W. (2019). Estimating and exploiting the impact of photo
layout: A structural approach. Available at SSRN 3470877.

Li, W., Shrotriya, S. and Rinaldo, A. (2022). \(\ell_{\infty}\) - bounds
of the mle in the btl model under general comparison graphs. In
Uncertainty in Artificial Intelligence. PMLR.Liu, Y., Fang, E. X. and
Lu, J. (2022). Lagrangian inference for ranking problems. Operations
Research.Luce, R. D. (1959). Individual choice behavior: A theoretical
analysis. John Wiley \& Sons, Inc., New York; Chapman \& Hall, Ltd.,
London.Massey, K. (1997). Statistical models applied to the rating of
sports teams. Bluefield College, 1077. Mattei, N., Forshee, J. and
Goldsmith, J. (2012). An empirical study of voting rules and
manipulation with large datasets. Proceedings of COMSOC, 59. Mattei, N.
and Walsh, T. (2013). Preflib: A library for preferences
http://www.preflib.org. In International conference on algorithmic
decision theory. Springer.Maystre, L. and Grossglauser, M. (2015). Fast
and accurate inference of Plackett- Luce models. Advances in Neural
Information Processing Systems, 28. Negahban, S., Oh, S. and Shah, D.
(2012). Iterative ranking from pair- wise comparisons. Advances in
Neural Information Processing Systems, 25. Ouyang, L., Wu, J., Jiang,
X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S.,
Slama, K., Ray, A. et al.~(2022). Training language models to follow
instructions with human feedback. Advances in Neural Information
Processing Systems, 35 27730- 27744. Plackett, R. L. (1975). The
analysis of permutations. Journal of the Royal Statistical Society:
Series C (Applied Statistics), 24 193- 202. Portnoy, S. (1986). On the
central limit theorem in \(\mathbf{R}^p\) when \(p \to \infty\) .
Probab. Theory Related Fields, 73 571- 583. Rusmevichientong, P., Shen,
Z.- J. M. and Shmoys, D. B. (2010). Dynamic assortment optimization with
a multinomial logit choice model and capacity constraint. Operations
research, 58 1666- 1680. Rusmevichientong, P. and Topaloglu, H. (2012).
Robust assortment optimization in revenue management under the
multinomial logit choice model. Operations research, 60 865- 882. Shah,
N., Balakrishnan, S., Bradley, J., Parekh, A., Ramchandran, K. and
Wainwright, M. (2015). Estimation from pairwise comparisons: Sharp
minimax bounds with topology dependence. In Artificial intelligence and
statistics. PMLR.Shen, S., Chen, X., Fang, E. and Lu, J. (2023).
Combinatorial inference on the optimal assortment in multinomial logit
models. Available at SSRN 4371919.

Simons, G. and Yao, Y.- C. (1999). Asymptotics when the number of
parameters tends to infinity in the Bradley- Terry model for paired
comparisons. \emph{The Annals of Statistics}, \textbf{27} 1041--1060.
Sumida, M., Gallego, G., Rusmevichientong, P., Topaloglu, H. and Davis,
J. (2021). Revenue- utility tradeoff in assortment optimization under
the multinomial logit model with totally unimodular constraints.
\emph{Management Science}, \textbf{67} 2845--2869. Szörényi, B., Busa-
Fekete, R., Paul, A. and Hüllermeier, E. (2015). Online rank elicitation
for Plackett- Luce: A dueling bandits approach. \emph{Advances in Neural
Information Processing Systems}, \textbf{28}.Talluri, K. and Van Ryzin,
G. (2004). Revenue management under a general discrete choice model of
consumer behavior. \emph{Management Science}, \textbf{50} 15--33. Tropp,
J. A. (2012). User- friendly tail bounds for sums of random matrices.
\emph{Foundations of computational mathematics}, \textbf{12} 389--434.
Turner, H. and Firth, D. (2012). Bradley- Terry models in R: the
BradleyTerry2 package. \emph{Journal of Statistical Software},
\textbf{48} 1--21. Vulcano, G., Van Ryzin, G. and Ratliff, R. (2012).
Estimating primary demand for substitutable products from sales
transaction data. \emph{Operations Research}, \textbf{60} 313--334.
Wang, X., Bendersky, M., Metzler, D. and Najork, M. (2016). Learning to
rank with selection bias in personal search. In \emph{Proceedings of the
39th International ACM SIGIR conference on Research and Development in
Information Retrieval}.Zhang, H., Rusmevichientong, P. and Topaloglu, H.
(2020). Assortment optimization under the paired combinatorial logit
model. \emph{Operations Research}, \textbf{68} 741--761.



\end{document}
